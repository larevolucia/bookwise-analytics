{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fc4fb3",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The purpose of this notebook is to **clean, standardize, and prepare the collected datasets** for subsequent exploratory analysis and modeling tasks.\n",
    "\n",
    "The goal is to transform raw inputs from multiple book datasets into a **reliable, consistent, and mergeable analytical base**, ensuring data integrity and comparability across platforms.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "| Dataset                    | Source                     | Description                                                               | Format |\n",
    "| -------------------------- | -------------------------- | ------------------------------------------------------------------------- | ------ |\n",
    "| `bbe_books.csv`            | Zenodo – *Best Books Ever* | Book metadata including title, author, rating, genres, and description.   | CSV    |\n",
    "| `books.csv`, `ratings.csv` | GitHub – *Goodbooks-10k*   | Book metadata and user–book interaction data for recommendation modeling. | CSV    |\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks in This Notebook\n",
    "\n",
    "This notebook will execute the following cleaning and preparation steps:\n",
    "\n",
    "1. **Standardize column formats:**\n",
    "   Ensure consistent data types and naming conventions across datasets (e.g., convert `isbn` to string, align `author`, `rating`, and `title` formats).\n",
    "\n",
    "2. **Clean and normalize missing values:**\n",
    "   Replace placeholder NaNs (`9999999999999`, empty lists, or `\"None\"`) with `np.nan`, then impute or drop based on analytical importance.\n",
    "\n",
    "3. **Detect and resolve duplicates:**\n",
    "   Identify duplicate records using key identifiers (`bookId`, `isbn`, `title + author`) and retain the most complete or relevant entries.\n",
    "\n",
    "4. **Validate and align categorical values:**\n",
    "   Standardize genre labels, language codes, and rating scales to ensure comparability between datasets.\n",
    "\n",
    "5. **Merge compatible datasets:**\n",
    "   Integrate *BestBooksEver* and *Goodbooks-10k_books* into a unified schema while maintaining referential integrity with the ratings dataset.\n",
    "\n",
    "6. **Outlier and consistency checks:**\n",
    "   Review numerical and date fields (e.g., `pages`, `price`, `publishDate`) for unrealistic or extreme values and adjust as needed.\n",
    "\n",
    "7. **Feature enrichment (optional):**\n",
    "   Derive or enhance fields such as `popularity_score`, `recency`, or missing genre information using external APIs where beneficial.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* **Cleaned, schema-aligned datasets** ready for exploratory data analysis and modeling.\n",
    "* **Summary statistics** on completeness, duplicates, and outliers.\n",
    "* **Processed CSV files** saved for reproducibility in `data/processed/`.\n",
    "\n",
    "> **Note:** This notebook focuses on the *Data Cleaning and Preparation*. Further feature engineering and model-specific transformations will follow in later notebooks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383657df",
   "metadata": {},
   "source": [
    "## Navigate to the Parent Directory\n",
    "\n",
    "Before combining and saving datasets, it’s often helpful to move to a parent directory so that file operations (like loading or saving data) are easier and more organized. \n",
    "\n",
    "Before using the Python’s built-in os module to move one level up from the current working directory, it is advisable to inspect the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f3220",
   "metadata": {},
   "source": [
    "To change to parent directory (root folder), run the code below. If you are already in the root folder, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c41cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to its parent\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Changed directory to parent.')\n",
    "\n",
    "# Get the new current working directory (the parent directory)\n",
    "current_dir = os.getcwd()\n",
    "print(f'New current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1120c",
   "metadata": {},
   "source": [
    "## Load and Inspect Books Datasets\n",
    "\n",
    "In this step, we load the previously collected datasets: **Goodbooks-10k** (books) and **Best Books Ever**. We will inspect their structure one more time before starting any merging or cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# load datasets\n",
    "books_raw = pd.read_csv('data/raw/books.csv')\n",
    "bbe_raw = pd.read_csv('data/raw/bbe_books.csv')\n",
    "\n",
    "# create copies for cleaning\n",
    "books_clean = books_raw.copy()\n",
    "bbe_clean = bbe_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "interim_bbe_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "interim_gb_path = Path(\"data/interim/goodbooks\")\n",
    "interim_gb_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "version = 0\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "books_clean.to_csv(interim_gb_path / f\"books_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "display(bbe_clean.head(3))\n",
    "display(books_clean.head(3))\n",
    "\n",
    "# Check shape and missing values\n",
    "for name, df in {'BBE': bbe_clean, 'Books': books_clean,}.items():\n",
    "    print(f\"\\n{name} — Shape: {df.shape}\")\n",
    "    print(df.info())\n",
    "    print(df.isna().sum().sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b59d8",
   "metadata": {},
   "source": [
    "We will check if the datasets share common identifiers and compatible data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4382d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_only_columns = set(bbe_clean.columns) - set(books_clean.columns)\n",
    "print(f'Columns only in BBE: {bbe_only_columns}')\n",
    "\n",
    "goodbooks_only_columns = set(books_clean.columns) - set(bbe_clean.columns)\n",
    "print(f'Columns only in Goodbooks: {goodbooks_only_columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66be32",
   "metadata": {},
   "source": [
    "Based on the initial inspection, we can create a mapping table to align columns from both datasets for merging and analysis.\n",
    "\n",
    "| **BestBooksEver (BBE)** | **Goodbooks10k_books (GB10k)** | **Notes / Alignment Rationale** |\n",
    "| --------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------- |\n",
    "| `bookId` | `book_id` | Main identifier; ensure both are numeric. |\n",
    "| `bookId_num` | `goodreads_book_id` | Goodreads identifier; ensure both are numeric for joining. |\n",
    "| `title` | `title` | Direct match. Used as secondary join key. |\n",
    "| `series` | — | Only in BBE; could enrich GB10k if available via API. |\n",
    "| `author` | `authors` | Same meaning. Normalize format. |\n",
    "| `rating` | `average_rating` | Equivalent — rename to unified `average_rating`. |\n",
    "| `numRatings` | `ratings_count` | Same measure of total user ratings. |\n",
    "| `ratingsByStars` | `ratings_1` … `ratings_5` | BBE has dict, GB10k has explicit columns. Expand or aggregate accordingly. |\n",
    "| `likedPercent` | — | BBE-only; optional metric of user sentiment. |\n",
    "| `isbn` | `isbn` / `isbn13` | Common linking key; keep both (string). Use for merges when present. |\n",
    "| `language` | `language_code` | Standardize to ISO 639-1 (lowercase). |\n",
    "| `description` | — | BBE-only; valuable for NLP features. |\n",
    "| `genres` | — | BBE-only; can enrich GB10k tags later. |\n",
    "| `characters` | — | bbe_clean-only; low modeling priority, but could add narrative metadata. |\n",
    "| `bookFormat` | — | BBE-only; possible categorical feature. |\n",
    "| `edition` | — | BBE-only. |\n",
    "| `pages` | — | BBE-only; numeric, may enrich GB10k metadata. |\n",
    "| `publisher` | — | bbe_clean_clean-only; possible future feature. |\n",
    "| `publishDate` | — | bbe_clean_clean-only; can approximate from GB10k’s `original_publication_year`. |\n",
    "| `firstPublishDate` | `original_publication_year` | Equivalent (date vs year). |\n",
    "| `coverImg` | `image_url` / `small_image_url` | Same function (cover link). |\n",
    "| `bbeScore` | — | BBE-only; internal popularity score. |\n",
    "| `bbeVotes` | `work_ratings_count` | Comparable as popularity proxy. |\n",
    "| `price` | — | BBE-only; likely non-essential for satisfaction prediction. |\n",
    "| `setting` | — | BBE-only; can support content enrichment. |\n",
    "| `awards` | — | BBE-only; categorical enrichment. |\n",
    "| — | `goodreads_book_id` / `best_book_id` / `work_id` | GB10k-only identifiers; may be used for deeper Goodreads linking. |\n",
    "| — | `books_count` | GB10k-only; number of editions per work. |\n",
    "| — | `work_text_reviews_count` | GB10k-only; can complement `numRatings` as engagement metric. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5069ac1",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "### Best Books Ever\n",
    "\n",
    "- Handle identifier columns\n",
    "- Standardize key columns: `author`, `language`\n",
    "- Missing data handling strategies\n",
    "- Normalize genre and format\n",
    "- Validate for no nulls or duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e6ae8",
   "metadata": {},
   "source": [
    "#### 1. Handle identifier columns\n",
    "On the previous notebook, we created a new field `bookId_num` in the BBE dataset to align with `goodreads_book_id` in the Goodbooks10k dataset. We have also ensured that they were both converted to numeric types and that all `bookId` values generated a valid `bookId_num`. So we can skip the handle identifier columns, as it was already done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6e5f",
   "metadata": {},
   "source": [
    "#### 2. Standardize key columns\n",
    "\n",
    "**Author**\n",
    "\n",
    "We will proceed with the standardization of key columns, starting with the `author` column. The author column in the BBE dataset often contains a qualifier such as \"(Goodreads Author)\". We will remove such qualifiers to standardize the format. We will also create an additional list column to store multiple authors as a list rather than a single string. This way, its is ready to use for feature engineering later on if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_and_split_authors(name):\n",
    "    \"\"\"\n",
    "    Cleans author names and returns a list of authors.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    # Remove role descriptors\n",
    "    cleaned = re.sub(r\"\\s*\\([^)]*\\)\", \"\", name)\n",
    "    \n",
    "    # split on commas and lowercase each name\n",
    "    authors_list = [a.strip().lower() for a in cleaned.split(\",\") if a.strip()]\n",
    "        \n",
    "    return authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145894ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to BestBooksEver dataset\n",
    "bbe_clean[\"authors_list\"] = bbe_clean[\"author\"].apply(clean_and_split_authors)\n",
    "bbe_clean[\"author_clean\"] = bbe_clean[\"authors_list\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else None)\n",
    "\n",
    "# Quick check\n",
    "bbe_clean[[\"author\", \"author_clean\", \"authors_list\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 1\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim author datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a74c31",
   "metadata": {},
   "source": [
    "**Language**\n",
    "\n",
    "The `language` column in the Best Books Ever dataset used full names such as “English”, “German”, and “Arabic”.  Before transforming the values, we will check for all unique values to identify any unexpected entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect unique language values\n",
    "print(\"Unique language values in BBE dataset:\")\n",
    "bbe_clean['language'] = bbe_clean['language'].astype(str).str.strip()\n",
    "unique_languages = bbe_clean['language'].unique()\n",
    "\n",
    "print(f\"\\nTotal unique values: {len(unique_languages)}\\n\")\n",
    "print(unique_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d9853",
   "metadata": {},
   "source": [
    "We can see that there are some unexpected values such as:\n",
    "- _historical forms_ (“English, Middle (1100-1500)”, “French, Middle (ca.1400-1600)”)\n",
    "- _combined or semicolon-separated entries_ (“Filipino; Pilipino”, “Catalan; Valencian”)\n",
    "- _multi-language / uncertain cases_ (“Multiple languages”, “Undetermined”)\n",
    "- _rare or dialects_ (“Bokmål, Norwegian; Norwegian Bokmål”, “Aromanian; Arumanian; Macedo-Romanian”)\n",
    "\n",
    "We will clean the unusual entries by mapping them to the closest language present in the ISO 639-1 standard. Unrecognized values will be flagged and replaced with `\"unknown\"`. It was decided to distinguish the `\"unknown\"` from the `NaN` values to retain information about missingness versus unrecognized entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a83c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Standardize capitalization & spacing\n",
    "bbe_clean['language'] = bbe_clean['language'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Handle NaNs that became strings\n",
    "bbe_clean['language'] = bbe_clean['language'].replace({'Nan': np.nan})\n",
    "\n",
    "# Simplify and unify multi-language / dialect forms\n",
    "replace_map = {\n",
    "    'Multiple Languages': 'Multilingual',\n",
    "    'Undetermined': 'Unknown',\n",
    "    'Iranian (Other)': 'Persian',\n",
    "    'Farsi': 'Persian',\n",
    "    'Filipino; Pilipino': 'Filipino',\n",
    "    'Catalan; Valencian': 'Catalan',\n",
    "    'Panjabi; Punjabi': 'Punjabi',\n",
    "    'Bokmål, Norwegian; Norwegian Bokmål': 'Norwegian',\n",
    "    'Norwegian Nynorsk; Nynorsk, Norwegian': 'Norwegian',\n",
    "    'Greek, Modern (1453-)': 'Greek',\n",
    "    'Greek, Ancient (To 1453)': 'Greek',\n",
    "    'French, Middle (Ca.1400-1600)': 'French',\n",
    "    'English, Middle (1100-1500)': 'English',\n",
    "    'Dutch, Middle (Ca.1050-1350)': 'Dutch',\n",
    "    'Aromanian; Arumanian; Macedo-Romanian': 'Romanian',\n",
    "    'Mayan Languages': 'Mayan',\n",
    "    'Australian Languages': 'English'\n",
    "}\n",
    "\n",
    "bbe_clean['language'] = bbe_clean['language'].replace(replace_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ad13",
   "metadata": {},
   "source": [
    "After transforming the values, we apply a mapping to standardize the `language` column using **ISO 639-1 two-letter codes**.\n",
    "The mapping dictionaries are stored in the `src/cleaning/mappings/` folder to keep the notebooks cleaner and improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37289380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"src/cleaning/mappings/languages_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    languages_dict = json.load(f)\n",
    "\n",
    "# Apply dictionary\n",
    "bbe_clean['language_clean'] = bbe_clean['language'].str.lower().map(languages_dict)\n",
    "\n",
    "# Fill remaining NaNs\n",
    "bbe_clean['language_clean'] = bbe_clean['language_clean'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for unique language values\n",
    "print(\"Unique language values in BBE dataset:\")\n",
    "unique_languages = bbe_clean['language_clean'].unique()\n",
    "\n",
    "print(f\"\\nTotal unique values: {len(unique_languages)}\\n\")\n",
    "print(unique_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_breakdown = (\n",
    "    bbe_clean['language_clean']\n",
    "    .value_counts()\n",
    "    .to_frame('count')\n",
    ")\n",
    "\n",
    "language_breakdown['percentage'] = (\n",
    "    language_breakdown['count'] / len(bbe_clean) * 100\n",
    ").round(2)\n",
    "\n",
    "print(language_breakdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 2\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim language datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6b8f9",
   "metadata": {},
   "source": [
    "**Dates**\n",
    "\n",
    "BBE dataset has two publication fields: `publishDate` and `firstPublishDate`. The `firstPublishDate` represents the original publication date, while `publishDate` refers to a more recent edition or reprint date. Publishing experts assumption is that the recency of the `firstPublishDate` is more relevant for modeling book satisfaction, as it reflects when the book was first introduced to readers. Therefore, we will focus on cleaning and standardizing the `firstPublishDate` column and use `publishDate` only if `firstPublishDate` is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2685c",
   "metadata": {},
   "source": [
    "While majority of the dates follow the 'MM/DD/YY' format, after a first attemp at cleaning, we noticed some dates do not conform to this format. Therefore, we will implement a more robust date parsing strategy, focusing first on transforming textual formats into 'MM/DD/YYYY' format before attempting to parse them into datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def clean_date_string(date_str):\n",
    "    \"\"\"Remove ordinal suffixes and unwanted characters from a date string.\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return np.nan\n",
    "    # remove st, nd, rd, th (like 'April 27th 2010' → 'April 27 2010')\n",
    "    cleaned = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', str(date_str))\n",
    "    return cleaned.strip()\n",
    "\n",
    "def parse_mixed_date(date_str):\n",
    "    \"\"\"Try to parse a variety of date formats safely.\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Use dateutil to parse most human-readable formats\n",
    "        return parser.parse(date_str, fuzzy=True)\n",
    "    except Exception:\n",
    "        # Try year-only fallback (e.g. '2003')\n",
    "        match = re.match(r'^\\d{4}$', str(date_str))\n",
    "        if match:\n",
    "            return pd.to_datetime(f\"{date_str}-01-01\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7cc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to both columns\n",
    "for col in ['firstPublishDate', 'publishDate']:\n",
    "       bbe_clean[f'{col}_clean'] = (\n",
    "        bbe_clean[col]\n",
    "        .astype(str)\n",
    "        .replace({'nan': np.nan, '': np.nan})\n",
    "        .apply(clean_date_string)\n",
    "        .apply(parse_mixed_date)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0493da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine using your logic: prefer firstPublishDate, else publishDate\n",
    "bbe_clean['publication_date_clean'] = (\n",
    "    bbe_clean['firstPublishDate_clean'].combine_first(bbe_clean['publishDate_clean'])\n",
    ")\n",
    "# Reconvert to datetime safely before using .dt\n",
    "bbe_clean['publication_date_clean'] = pd.to_datetime(bbe_clean['publication_date_clean'], errors='coerce')\n",
    "\n",
    "# Format as ISO standard\n",
    "bbe_clean['publication_date_clean'] = bbe_clean['publication_date_clean'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Check a sample of remaining nulls\n",
    "bbe_clean[bbe_clean['publication_date_clean'].isna()][['title', 'firstPublishDate', 'publishDate', 'publication_date_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the unified publication date is missing\n",
    "total = len(bbe_clean)\n",
    "bbe_missing_dates = bbe_clean.loc[bbe_clean['publication_date_clean'].isna()]\n",
    "missing_count = len(bbe_missing_dates)\n",
    "\n",
    "print(f\"Missing publication dates: {missing_count} of {total} ({missing_count/total:.2%})\")\n",
    "\n",
    "# Preview key columns\n",
    "bbe_missing_dates[['title', 'author', 'firstPublishDate', 'publishDate', 'publication_date_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 3\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim dates datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f7a9c",
   "metadata": {},
   "source": [
    "**Publisher**\n",
    "\n",
    "Publisher names can vary significantly in formatting, including differences in capitalization, punctuation, and spacing. To standardize the `publisher` column, we will convert all entries to lowercase and strip any leading or trailing whitespace. This will help reduce variability and improve consistency across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample publishers:\")\n",
    "print(bbe_clean['publisher'].drop_duplicates().sample(30, random_state=42).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Strip, lowercase, remove extra spaces and punctuation\n",
    "bbe_clean['publisher'] = (\n",
    "    bbe_clean['publisher']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace('\"', '', regex=False)\n",
    "    .str.replace(\"'\", '', regex=False)\n",
    "    .str.replace(r'[.,]', '', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e51a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect unique publisher values \n",
    "bbe_clean['publisher'] = bbe_clean['publisher'].astype(str).str.strip() \n",
    "unique_publisher = bbe_clean['publisher'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique publisher values: {len(unique_publisher)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize numeric publishers names:\n",
    "def clean_numeric_publishers(x):\n",
    "    if re.match(r'^\\d+$', x.strip()):\n",
    "        return 'unknown'\n",
    "    return x\n",
    "\n",
    "bbe_clean['publisher'] = bbe_clean['publisher'].apply(clean_numeric_publishers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34928226",
   "metadata": {},
   "source": [
    "This cleaning step reduced the number of unique publisher names from **11,111 to 10,764**.\n",
    "Since **English-language books represent 81% of the catalogue**, the analysis will focus on this segment.\n",
    "We will **standardize major English-language publishing groups**, consolidating their **imprints and subsidiaries**, and apply **fuzzy matching** to unify names with **minor variations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load publishers dictionary\n",
    "with open(\"src/cleaning/mappings/publishers_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    publishers_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83945720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Get top 10000 most common publishers\n",
    "top_n = 10000\n",
    "publisher_counts = bbe_clean['publisher'].value_counts()\n",
    "top_publishers = publisher_counts.head(top_n).index.tolist()\n",
    "\n",
    "# Create a mapping for top publishers only\n",
    "standardization_map = {}\n",
    "processed = set()\n",
    "\n",
    "for pub in top_publishers:\n",
    "    if pub in processed:\n",
    "        continue\n",
    "    \n",
    "    # Find similar publishers in the top list\n",
    "    matches = process.extract(pub, top_publishers, scorer=fuzz.ratio, limit=5)\n",
    "    \n",
    "    # Group similar ones (score > 90)\n",
    "    similar = [m[0] for m in matches if m[1] > 90]\n",
    "    canonical = similar[0]  # Use first as canonical\n",
    "    \n",
    "    for similar_pub in similar:\n",
    "        standardization_map[similar_pub] = canonical\n",
    "        processed.add(similar_pub)\n",
    "\n",
    "# Apply the mapping\n",
    "bbe_clean['publisher_standardized'] = bbe_clean['publisher'].replace(standardization_map)\n",
    "\n",
    "# Then apply manual mapping\n",
    "bbe_clean['publisher_standardized'] = bbe_clean['publisher_standardized'].replace(publishers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_unique_publisher = bbe_clean['publisher_standardized'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique publisher values: {len(standardized_unique_publisher)}\\n\") \n",
    "\n",
    "print(\"Sample publishers:\")\n",
    "print(bbe_clean['publisher_standardized'].drop_duplicates().sample(30, random_state=42).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ec14d",
   "metadata": {},
   "source": [
    "The cleaning process reduced the number of unique publisher names from **11,111 to 9993**, representing a **10% decrease**.\n",
    "Given that the dataset includes books in multiple languages and many small or independent publishers, this reduction is a **satisfactory outcome**.\n",
    "\n",
    "To further evaluate the effectiveness of the cleaning, we will analyze the **proportion of titles associated with the most common publishers**.\n",
    "This will help us assess how well the standardization process **consolidated the publisher catalog** and captured the main publishing groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b78810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your core publisher groups\n",
    "major_publishers = [\n",
    "    'penguin random house', 'harpercollins', 'macmillan',\n",
    "    'simon & schuster', 'hachette', 'bloomsbury',\n",
    "    'amazon publishing', 'scholastic'\n",
    "]\n",
    "\n",
    "# Create a flag\n",
    "bbe_clean['is_major_publisher'] = bbe_clean['publisher_standardized'].isin(major_publishers)\n",
    "\n",
    "# Count results\n",
    "total_books = len(bbe_clean)\n",
    "major_books = bbe_clean['is_major_publisher'].sum()\n",
    "share_major = major_books / total_books * 100\n",
    "\n",
    "print(f\"Books from mapped major publishers: {major_books} of {total_books} ({share_major:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0672c79",
   "metadata": {},
   "source": [
    "About 17% of all titles now belong to one of the standardized major publisher groups.\n",
    "The remaining publishers represent independent, regional, or self-published works.\n",
    "Further improvements (e.g., mapping academic and international publishers) could expand this coverage to 25–30%. But we'll leave it as is for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 4\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim publisher datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd851a",
   "metadata": {},
   "source": [
    "**Book Format**\n",
    "\n",
    "This step standardizes the `bookFormat` field across multiple languages and inconsistent label variations found in the dataset.  \n",
    "The goal is to translate all format names into English and consolidate equivalent values (e.g., *“Capa dura”*, *“Gebundene Ausgabe”*, *“Hard back”*) under unified categories such as **Hardcover**, **Paperback**, **Ebook**, and **Audiobook**.\n",
    "\n",
    "This cleaning ensures that:\n",
    "- Format values are consistent for analysis and visualization.  \n",
    "- Non-English or rare variants are translated and grouped appropriately.  \n",
    "- Missing or unrecognized entries are handled under a neutral category: **Other / Unknown**.  \n",
    "\n",
    "By applying a mapping dictionary, we make the variable suitable for aggregation, comparison, and predictive modeling. After transformation, we verify the result by inspecting the number of unique standardized values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bfcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect unique format values \n",
    "bbe_clean['bookFormat'] = bbe_clean['bookFormat'].astype(str).str.strip() \n",
    "unique_format = bbe_clean['bookFormat'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique book format values: {len(unique_format)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load format dictionary\n",
    "with open(\"src/cleaning/mappings/format_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    format_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['bookFormat_clean'] = (\n",
    "    bbe_clean['bookFormat']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .replace(format_dict)\n",
    ")\n",
    "\n",
    "# Replace remaining unknowns or NaN with a unified label\n",
    "bbe_clean['bookFormat_clean'] = bbe_clean['bookFormat_clean'].replace(['nan', 'none', ''], np.nan)\n",
    "bbe_clean['bookFormat_clean'] = bbe_clean['bookFormat_clean'].fillna('Other / Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c61a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_format_clean = bbe_clean['bookFormat_clean'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique book format values: {len(unique_format_clean)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_format_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 5\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim format datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a412a95",
   "metadata": {},
   "source": [
    "After applying the standardization mapping, the number of unique book format values was reduced from **135** to **10**.  This represents a substantial improvement in data consistency and interpretability.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b535cfd",
   "metadata": {},
   "source": [
    "**ISBN and ASIN Cleaning**\n",
    "\n",
    "The BBE dataset includes a single `isbn` column, which initially contained numerous missing or invalid entries (e.g. placeholder values such as `9999999999999`).\n",
    "\n",
    "Our initial cleaning flow focused solely on standardizing **ISBN** values, but upon further inspection, we identified additional patterns such as **Amazon ASINs** (10-character alphanumeric codes) and prefixed identifiers like `10:` or `13:`.\n",
    "\n",
    "These findings led to an adjustment to the cleaning logic and the order of operations in the pipeline.\n",
    "\n",
    "The final cleaning process:\n",
    "\n",
    "- Removes punctuation and non-digit characters to standardize ISBN formatting.\n",
    "- Detects and separates ASINs (`asin` column) to preserve them for potential cross-dataset enrichment.\n",
    "- Handles prefixed identifiers (e.g., `13:9780615700`) by removing prefixes before validation.\n",
    "- Filters out placeholder or invalid entries (`999…`, `000…`) and ensures consistent string representation.\n",
    "- Creates a new `isbn_clean` column containing only valid ISBN-10 or ISBN-13 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ISBN column\n",
    "bbe_clean[['title','isbn']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing and invalid patterns\n",
    "n_missing_isbn = bbe_clean['isbn'].isna().sum()\n",
    "print(f'Number of missing ISBN entries: {n_missing_isbn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify invalid placeholders (like 9999999999999)\n",
    "n_invalid_isbn = bbe_clean[bbe_clean['isbn'].astype(str).str.contains('9999999999')].shape[0]\n",
    "print(f'Number of placeholder ISBN entries: {n_invalid_isbn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_asin(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x).strip()\n",
    "    if re.fullmatch(r'[A-Z0-9]{10}', x) and not x.isdigit():  # must have at least one letter\n",
    "        return x\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['asin'] = bbe_clean['isbn'].apply(detect_asin)\n",
    "has_asin = bbe_clean[bbe_clean['asin'].notna()] \n",
    "print(f'Books with ASINs: {len(has_asin)}')\n",
    "has_asin[['title','isbn', 'asin']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabfea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_isbn(x):\n",
    "    # handle missing\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "\n",
    "    # detect ASIN first\n",
    "    asin_val = detect_asin(x)\n",
    "    if pd.notna(asin_val):\n",
    "        # return NaN for ISBN cleaning, because it's an ASIN\n",
    "        return np.nan  \n",
    "\n",
    "    # clean numeric ISBNs\n",
    "    s = str(x).strip()\n",
    "    s = re.sub(r'^(10:|13:)', '', s)       # remove leading prefixes\n",
    "    s = re.sub(r'\\D', '', s)               # keep only digits\n",
    "\n",
    "    # handle placeholders\n",
    "    if re.fullmatch(r'(9{10}|9{13}|0{10}|0{13})', s):\n",
    "        return np.nan\n",
    "\n",
    "    # keep valid ISBN-10 or ISBN-13\n",
    "    if len(s) in [10, 13]:\n",
    "        return s\n",
    "\n",
    "    return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['isbn_clean'] = bbe_clean['isbn'].apply(clean_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b056cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ISBN columns after cleaning\n",
    "bbe_clean[['title','isbn', 'isbn_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9baf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_remaining = bbe_clean[bbe_clean['isbn_clean'].astype(str).str.fullmatch(r'(9{10}|9{13}|0{10}|0{13})', na=False)]\n",
    "print(f\"Remaining placeholder ISBNs: {len(placeholder_remaining)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where isbn_clean is NaN\n",
    "missing_isbn_clean = bbe_clean[bbe_clean['isbn_clean'].isna()]\n",
    "\n",
    "# Print the number of missing and show the first few examples\n",
    "print(f\"Missing isbn_clean: {missing_isbn_clean.shape[0]}\")\n",
    "missing_isbn_clean[['title', 'bookFormat', 'isbn', 'asin','isbn_clean']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31f098",
   "metadata": {},
   "source": [
    "To inspect if there are other cases of invalid ISBNs, we will filter the rows where the `isbn_type` is either `'wrong_length'` or `'missing'`. This will help us identify any additional issues with the ISBN data that may need to be addressed. For that a custom function `isbn_type` was created to classify the reason for invalidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isbn_type(x):\n",
    "    if pd.isna(x):\n",
    "        return 'missing'\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    # Detect ASIN (10-char alphanumeric, must have at least one letter)\n",
    "    if re.fullmatch(r'[A-Z0-9]{10}', s.upper()) and not s.isdigit():\n",
    "        return 'asin'\n",
    "\n",
    "    # Remove non-digits for numeric checks\n",
    "    x = re.sub(r'\\D', '', s)\n",
    "\n",
    "    # Placeholder patterns\n",
    "    if re.fullmatch(r'9{10}|9{13}', x):\n",
    "        return 'placeholder_9'\n",
    "    if re.fullmatch(r'0{10}|0{13}', x):\n",
    "        return 'placeholder_0'\n",
    "\n",
    "    # Length checks\n",
    "    if len(x) in [10, 13]:\n",
    "        return 'valid'\n",
    "    if len(x) > 0:\n",
    "        return 'wrong_length'\n",
    "\n",
    "    return 'missing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeec353",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['isbn_type'] = bbe_clean['isbn'].apply(isbn_type)\n",
    "bbe_clean['isbn_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25755dea",
   "metadata": {},
   "source": [
    "The `isbn_type` function accurately distinguished valid ISBNs, ASINs, and placeholders and can be used to validate the data cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['isbn_type'] = bbe_clean['isbn_clean'].apply(isbn_type)\n",
    "bbe_clean['isbn_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with type either 'wrong_length' or 'missing'\n",
    "invalid_isbn = bbe_clean[bbe_clean['isbn_type'].isin(['missing'])]\n",
    "\n",
    "# Show total count\n",
    "print(f\"Total invalid (missing): {invalid_isbn.shape[0]}\")\n",
    "\n",
    "# Preview relevant columns\n",
    "invalid_isbn[['title', 'author_clean', 'bookFormat', 'isbn', 'asin', 'isbn_type']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676aef5e",
   "metadata": {},
   "source": [
    "Out of all records, **9,078 entries (≈18%)** were identified as invalid ISBNs, leaving roughly **82%** valid.\n",
    "Invalid cases, after cleaning are limited to the `'missing'` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 6\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim ISBN/ASIN datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e35f4",
   "metadata": {},
   "source": [
    "**Ratings**\n",
    "\n",
    "In this step, we will first evaluate the quality and consistency of the `rating` field.\n",
    "We first check for missing or invalid values and calculate the percentage of available ratings to assess data completeness. Then, we use the `describe()` method to verify whether the ratings follow the expected 1–5 scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7651de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where rating is not NaN\n",
    "total_books = len(bbe_clean)\n",
    "has_ratings = bbe_clean[bbe_clean['rating'].notna()]\n",
    "has_ratings_num = has_ratings.shape[0]\n",
    "share_ratings = has_ratings_num / total_books * 100\n",
    "\n",
    "# Print the number of titles with ratings and show the first few examples\n",
    "print(f\"Books with ratings: {has_ratings_num} of {total_books} ({share_ratings:.2f}%)\")\n",
    "has_ratings[['title', 'rating', 'numRatings','ratingsByStars']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['rating'].unique()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff8e3",
   "metadata": {},
   "source": [
    "The inspection confirms that the dataset is generally clean; however, a small number of entries have a value of `0`, which represents missing evaluations. These will be replaced with `NaN` to ensure the ratings remain within the valid range (1–5). Since all valid values already follow the standard Goodreads scale, no normalization is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f90c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (bbe_clean['rating'] == 0)\n",
    "print(f'Items with value equal 0: {bbe_clean[mask].shape[0]}')\n",
    "bbe_clean[mask][['title', 'author_clean','rating','numRatings','ratingsByStars']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['rating_clean'] = bbe_clean['rating'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332efe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['rating_clean'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b3563f",
   "metadata": {},
   "source": [
    "**NumRating**\n",
    "\n",
    "Next we will handle `numRatings`. The `numRatings` feature represents the total count of user ratings per book. We seen know from the mask we created that where `ratings` equals `0`, `numRatings` tends to be `0` too. We will check if that is always the case by checking for invalid values and using the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4254c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_numRatings = bbe_clean[bbe_clean['numRatings'].isna()]\n",
    "na_numRatings_num = na_numRatings.shape[0]\n",
    "share_numRatings = na_numRatings_num / total_books * 100\n",
    "\n",
    "# Print the number of titles with ratings and show the first few examples\n",
    "print(f\"Books with no numRatings values: {na_numRatings_num} of {total_books} ({share_numRatings}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c234c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['numRatings'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3bc87b",
   "metadata": {},
   "source": [
    "Since it’s a valid count metric (0 values indicate unrated books), no replacement with NaN is required. However, because most books have relatively few ratings while a few very popular titles have millions, the distribution is heavily right-skewed. To better visualize and later analyze relationships with other variables, we apply a logarithmic transformation (`log1p`) to smooth out the long tail and reveal underlying patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.log1p(bbe_clean['numRatings']), bins=50)\n",
    "plt.title(\"Distribution of Log(Number of Ratings)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74e109",
   "metadata": {},
   "source": [
    "The log transformation reveals a near-normal distribution centered around books with moderate popularity.\n",
    "This confirms that `numRatings` is a valid and informative feature, and no normalization or imputation is needed at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the count to reduce skew\n",
    "bbe_clean['numRatings_log'] = np.log1p(bbe_clean['numRatings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee88d05",
   "metadata": {},
   "source": [
    "**ratingsByStars**\n",
    "\n",
    "In this step, we examine how complete the `ratingsByStars` field is across all books.  \n",
    "This feature represents the 1–5 star breakdown of user ratings and is essential for modelling engagement quality and satisfaction patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e520ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_ratings_stars = bbe_clean[bbe_clean['ratingsByStars'].isna()]\n",
    "na_ratings_stars_num = na_ratings_stars.shape[0]\n",
    "share_na_ratings_stars = na_ratings_stars_num / total_books * 100\n",
    "\n",
    "# Print the number of titles with ratingsByStars and show the first few examples\n",
    "print(f\"Books with ratingsByStars: {na_ratings_stars_num} of {total_books} ({share_na_ratings_stars}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff53e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['ratingsByStars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ratings_stars_mask = (bbe_clean['ratingsByStars'] == '[]')\n",
    "empty_ratings_stars = bbe_clean[empty_ratings_stars_mask].shape[0]\n",
    "print(f'Items with empty values: {empty_ratings_stars}')\n",
    "bbe_clean[empty_ratings_stars_mask][['title', 'author_clean','rating','numRatings','ratingsByStars']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6fbbc6",
   "metadata": {},
   "source": [
    "By quantifying missing or empty values, we identify potential inconsistencies between overall ratings (`rating`, `numRatings`) and their detailed distribution.\n",
    "After counting missing and empty entries, we compare these against books that *do* have `rating` and `numRatings` values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d49164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask for books with ratings\n",
    "mask_has_ratings = (bbe_clean['numRatings'] > 0) & (bbe_clean['rating'] > 0)\n",
    "# mask for books without rating distributions\n",
    "mask_no_distribution = (bbe_clean['ratingsByStars'] == '[]')\n",
    "# combine masks: have ratings but no distribution:\n",
    "mask_rated_no_distribution = mask_has_ratings & mask_no_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a51959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and inspect missing star distributions among rated books\n",
    "\n",
    "# count how many books have ratings but no ratingsByStars distribution\n",
    "num_missing_dist = mask_rated_no_distribution.sum()\n",
    "share_missing_dist = num_missing_dist / len(bbe_clean) * 100\n",
    "\n",
    "# count total books with empty or missing distributions (regardless of ratings)\n",
    "total_empty_dist = empty_ratings_stars_mask.sum()\n",
    "\n",
    "# compute what share of those empty distributions actually have valid ratings\n",
    "share_with_ratings = (num_missing_dist / total_empty_dist) * 100\n",
    "share_without_ratings = 100 - share_with_ratings\n",
    "\n",
    "# print results\n",
    "print(f\"Total books: {len(bbe_clean):,}\")\n",
    "print(f\"Books with ratings but missing distribution: {num_missing_dist:,} ({share_missing_dist:.2f}%)\")\n",
    "print(f\"  ↳ Of all empty distributions ({total_empty_dist:,} total):\")\n",
    "print(f\"      • With ratings: {share_with_ratings:.2f}%\")\n",
    "print(f\"      • Without ratings: {share_without_ratings:.2f}%\")\n",
    "\n",
    "# inspect a few examples\n",
    "bbe_clean.loc[mask_rated_no_distribution, ['title', 'author_clean', 'rating', 'numRatings', 'ratingsByStars']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb30c75",
   "metadata": {},
   "source": [
    "This highlights a critical gap: books with ratings but without a distribution breakdown.  \n",
    "\n",
    "Such gaps likely stem from export limitations or missing historical data from Goodreads, and must be addressed before feature engineering or predictive tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5d1fe",
   "metadata": {},
   "source": [
    "To handle missing `ratingsByStars` while preserving analytical completeness, we implement a probabilistic estimation function.  \n",
    "The approach assumes a normal distribution around the book’s average rating, proportionally allocating counts across 1–5 stars.  \n",
    "\n",
    "This preserves both the **total number of ratings** and the **shape of expected user sentiment**, ensuring downstream models can use these reconstructed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb063abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def estimate_star_distribution(avg_rating, num_ratings):\n",
    "    # define 1–5 star levels\n",
    "    stars = np.arange(1, 6)\n",
    "\n",
    "    # normal distribution around avg_rating\n",
    "    # - (stars - avg_rating): distance of each star value from the mean\n",
    "    # - **2: squares the distance to emphasize larger deviations\n",
    "    # - -0.5 * (...): converts distance into a negative exponent (closer = less negative)\n",
    "    # - np.exp(...): applies exponential decay, giving higher weights to values near the mean\n",
    "    # - 0.5 controls the curve’s spread (smaller = narrower, larger = wider)\n",
    "    weights = np.exp(-0.5 * ((stars - avg_rating) ** 2) / 0.5**2)\n",
    "    weights /= weights.sum()  # normalize to 1\n",
    "    \n",
    "    # Scale to total ratings\n",
    "    estimated_counts = np.round(weights * num_ratings).astype(int)\n",
    "\n",
    "    # Adjust rounding error so sum matches exactly\n",
    "    diff = num_ratings - estimated_counts.sum()\n",
    "    estimated_counts[np.argmax(weights)] += diff\n",
    "\n",
    "    return estimated_counts.tolist()\n",
    "\n",
    "# code inspiration: \n",
    "# https://www.geeksforgeeks.org/machine-learning/gaussian-distribution-in-machine-learning/\n",
    "# https://www.geeksforgeeks.org/python/python-normal-distribution-in-statistics/\n",
    "# https://www.geeksforgeeks.org/numpy/binning-data-in-python-with-scipy-numpy/\n",
    "# https://blog.quantinsti.com/gaussian-distribution/\n",
    "# https://www.freecodecamp.org/news/how-to-explain-data-using-gaussian-distribution-and-summary-statistics-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e24a4",
   "metadata": {},
   "source": [
    "The function is applied to all titles with valid ratings but missing distributions.  \n",
    "We then validate that each reconstructed list of star counts sums to its corresponding `numRatings`, ensuring internal consistency.  \n",
    "A high proportion of valid totals indicates that the imputation strategy worked as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['ratingsByStars_clean'] = bbe_clean['ratingsByStars']\n",
    "# For books missing star distributions but with valid ratings,\n",
    "# estimate a plausible 1–5 star breakdown using avg_rating and numRatings,\n",
    "# and store the result in 'ratingsByStars_clean'.\n",
    "bbe_clean.loc[mask_rated_no_distribution, 'ratingsByStars_clean'] = (\n",
    "    bbe_clean.loc[mask_rated_no_distribution]\n",
    "    .apply(lambda x: estimate_star_distribution(x['rating'], int(x['numRatings'])), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check how many were filled\n",
    "filled_count = bbe_clean.loc[mask_rated_no_distribution, 'ratingsByStars_clean'].notna().sum()\n",
    "print(f\"Filled distributions: {filled_count:,} (of {mask_rated_no_distribution.sum():,} missing)\")\n",
    "\n",
    "# preview examples\n",
    "print(\"\\nSample of estimated distributions:\")\n",
    "display(\n",
    "    bbe_clean.loc[mask_rated_no_distribution, \n",
    "                  ['title', 'author_clean', 'rating', 'numRatings', 'ratingsByStars_clean']\n",
    "                 ].head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5582ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that each estimated list sums correctly\n",
    "check_sum = bbe_clean.loc[mask_rated_no_distribution].apply(\n",
    "    lambda x: sum(x['ratingsByStars_clean']) == int(x['numRatings']), axis=1\n",
    ")\n",
    "valid_share = check_sum.mean() * 100\n",
    "print(f\"\\nDistributions matching numRatings total: {valid_share:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658b5ae",
   "metadata": {},
   "source": [
    "We extend the validation to the full dataset, verifying that all `ratingsByStars_clean` entries, both original and estimated, correctly sum to `numRatings`. This serves as a final data integrity checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def safe_sum_ratings(row):\n",
    "    val = row['ratingsByStars_clean']\n",
    "    # Convert stringified lists into Python lists\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            val = ast.literal_eval(val)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # If it's a list, make sure elements are integers\n",
    "    if isinstance(val, list):\n",
    "        try:\n",
    "            val = [int(v) for v in val]  # convert each element to int\n",
    "            return sum(val) == int(row['numRatings'])\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "# https://dev.to/mstuttgart/using-literal-eval-for-string-to-object-conversion-in-python-46i\n",
    "# https://www.educative.io/answers/what-is-astliteralevalnodeorstring-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sum_all = bbe_clean.loc[bbe_clean['ratingsByStars_clean'].notna()].apply(safe_sum_ratings, axis=1)\n",
    "valid_share_all = check_sum_all.mean() * 100\n",
    "\n",
    "print(f\"All distributions matching numRatings total: {valid_share_all:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b43433",
   "metadata": {},
   "source": [
    "As a last step, we replace remaining `'[]'` values using `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d36f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_empty_ratings_stars_mask = (bbe_clean['ratingsByStars_clean'] == '[]')\n",
    "remaining_empty_ratings_stars = bbe_clean[remaining_empty_ratings_stars_mask].shape[0]\n",
    "print(f'Remaining empty values: {remaining_empty_ratings_stars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6696a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['ratingsByStars_clean'] = bbe_clean['ratingsByStars_clean'].replace('[]', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 7\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim ratings datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4546c",
   "metadata": {},
   "source": [
    "**Genres**\n",
    "\n",
    "In memory-based recommender systems, categorical attributes such as genre serve as key features for similarity computation. In this step, we first identify and handle missing values, then parse the genre lists using `ast.literal_eval` to ensure proper data structure representation, and finally quantify the unique genres and analyze their distribution across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd91499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and handle missing genre values\n",
    "empty_genres_mask = (bbe_clean['genres'] == '[]')\n",
    "empty_genres = bbe_clean[empty_genres_mask].shape[0]\n",
    "share_missing_genres = (empty_genres / len(bbe_clean)) * 100\n",
    "print(f'Books with empty genre values: {empty_genres} ({share_missing_genres:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# GENERIC PARSING AND CLEANING FUNCTIONS\n",
    "\n",
    "def parse_list_field(val):\n",
    "    \"\"\"\n",
    "    Safely parse a stringified list (e.g. '[\"x\", \"y\"]') into a Python list.\n",
    "    Returns np.nan for missing, invalid, or empty values.\n",
    "    \"\"\"\n",
    "    if pd.isna(val) or val in ['[]', '', None]:\n",
    "        return np.nan\n",
    "    try:\n",
    "        parsed = ast.literal_eval(val)\n",
    "        if isinstance(parsed, list) and len(parsed) > 0:\n",
    "            return parsed\n",
    "        else:\n",
    "            return np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def clean_text_item(text, keep_pattern=r'[^a-z0-9\\s-]'):\n",
    "    \"\"\"\n",
    "    Lowercase and remove noise, keeping only letters, digits, hyphens and spaces.\n",
    "    Can be reused for genres, awards, etc.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(keep_pattern, '', text)  # clean unwanted chars\n",
    "    text = re.sub(r'\\s+', ' ', text)       # collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_list_field(lst, keep_pattern=r'[^a-z0-9\\s-]'):\n",
    "    \"\"\"\n",
    "    Clean and deduplicate elements from a list of strings.\n",
    "    Returns np.nan for invalid or empty lists.\n",
    "    \"\"\"\n",
    "    if not isinstance(lst, list):\n",
    "        return np.nan\n",
    "    cleaned = [clean_text_item(item, keep_pattern) for item in lst if isinstance(item, str) and item.strip()]\n",
    "    cleaned = [c for c in cleaned if c]\n",
    "    return list(set(cleaned)) if cleaned else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['genres_parsed'] = bbe_clean['genres'].apply(parse_list_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['genres_parsed'] = bbe_clean['genres_parsed'].apply(clean_list_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(bbe_clean['genres_parsed'].apply(type).value_counts())\n",
    "print(bbe_clean['genres_parsed'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_nan_genres = bbe_clean['genres_parsed'].apply(lambda x: isinstance(x, float))\n",
    "bbe_clean[mask_nan_genres][['title', 'author_clean', 'genres', 'genres_parsed']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9370b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable dictionary counts\n",
    "def count_unique_items(df, column):\n",
    "    \"\"\"\n",
    "    Count the frequency of each unique element in a list-type column.\n",
    "    Returns a dictionary {item: count}.\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    for lst in df[column].dropna():\n",
    "        if isinstance(lst, list):\n",
    "            for item in lst:\n",
    "                counts[item] = counts.get(item, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres_dict = count_unique_items(bbe_clean, 'genres_parsed')\n",
    "unique_genres_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fa8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# convert to Series for easy analysis\n",
    "genre_counts = pd.Series(unique_genres_dict).sort_values(ascending=False)\n",
    "top_n = 30\n",
    "\n",
    "#plot top N genres\n",
    "top_n = 30\n",
    "plt.figure(figsize=(10,6))\n",
    "genre_counts.head(top_n).plot(kind='bar', color='slateblue')\n",
    "plt.title(f\"Top {top_n} Genres by Frequency\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Book Count\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7ca10",
   "metadata": {},
   "source": [
    "The genre frequency plot reveals a highly skewed distribution typical of book markets, dominated by broad categories like _Fiction_ and _Romance_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean[['title','author_clean', 'genres_parsed', 'genres']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0393517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate genre-level and book-level coverage\n",
    "total_genres = genre_counts.sum()\n",
    "top10 = set(genre_counts.head(10).index)\n",
    "\n",
    "top10_share = (genre_counts.head(10).sum() / total_genres) * 100\n",
    "mask_top10 = bbe_clean['genres_parsed'].apply(\n",
    "    lambda lst: any(g in top10 for g in lst) if isinstance(lst, list) else False\n",
    ")\n",
    "book_share_top10 = (mask_top10.sum() / len(bbe_clean)) * 100\n",
    "\n",
    "print(f\"Top 10 genres account for {top10_share:.2f}% of all genre occurrences.\")\n",
    "print(f\"Books with at least one of the top 10 genres: {book_share_top10:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124fe4e2",
   "metadata": {},
   "source": [
    "Broad, mainstream genres dominate both in tag volume and book coverage. Nearly one-third of all genre tags (**30.47%**) in the dataset come from the same 10 genres, showing strong catalog concentration. Nearly nine out of ten books (**86.54%**) fall within those top categories, confirming their dominance at the book level. This distribution supports the design of **segment-based recommendation strategies** for mainstream readers while maintaining a “long-tail” of niche genres to personalize discovery.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edb942",
   "metadata": {},
   "source": [
    "Since genre tags are extremely long-tail: a few popular genres dominate while hundreds of niche labels appear rarely. Collapsing the tail into a single bucket (_other_) reduces feature sparsity, speeds up modeling, and keeps the vectors interpretable for the dashboard. This aligns with CRISP-DM Data Preparation and the assessment’s requirement to collect, arrange, and process data before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0826e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplification rules\n",
    "TOP_K = 100          # keep the 100 most frequent genres\n",
    "TAIL_LABEL = 'other' # name of the long-tail bucket\n",
    "FILL_MISSING = True  # set to False if you prefer to leave NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a58833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "valid_lists = bbe_clean['genres_parsed'].dropna()\n",
    "genre_counts = Counter(g for lst in valid_lists for g in lst)\n",
    "genre_counts = pd.Series(genre_counts).sort_values(ascending=False)\n",
    "top_genres = set(genre_counts.head(TOP_K).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc80f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_genre_list(lst, *, keep=top_genres, tail=TAIL_LABEL):\n",
    "    if not isinstance(lst, list):  # NaN / missing\n",
    "        return ['unknown'] if FILL_MISSING else pd.NA\n",
    "    kept = [g if g in keep else tail for g in lst]\n",
    "    # dedupe while preserving order\n",
    "    seen = set()\n",
    "    simplified = [x for x in kept if not (x in seen or seen.add(x))]\n",
    "    # if everything was mapped to tail and list became ['other'] it's fine; if it became empty, fill fallback\n",
    "    return simplified or (['unknown'] if FILL_MISSING else pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['genres_simplified'] = bbe_clean['genres_parsed'].apply(simplify_genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of rows simplified successfully\n",
    "ok_share = bbe_clean['genres_simplified'].notna().mean() * 100\n",
    "print(f\"Simplified rows available: {ok_share:.2f}%\")\n",
    "\n",
    "# How many rows include the tail label\n",
    "has_tail = bbe_clean['genres_simplified'].apply(lambda lst: isinstance(lst, list) and TAIL_LABEL in lst).sum()\n",
    "print(f\"Rows containing '{TAIL_LABEL}': {has_tail}\")\n",
    "\n",
    "# Coverage of the head vs tail (by occurrences)\n",
    "from collections import Counter\n",
    "simp_counts = Counter(g for lst in bbe_clean['genres_simplified'].dropna() for g in lst)\n",
    "head_occ = sum(simp_counts[g] for g in simp_counts if g in top_genres)\n",
    "tail_occ = simp_counts.get(TAIL_LABEL, 0)\n",
    "total_occ = head_occ + tail_occ\n",
    "print(f\"Head coverage: {head_occ/total_occ*100:.2f}% | Tail coverage: {tail_occ/total_occ*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(bbe_clean['genres_simplified'].apply(type).value_counts())\n",
    "print(bbe_clean['genres_simplified'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def genre_completeness_report(df, columns):\n",
    "    \"\"\"\n",
    "    Check completeness (non-empty lists) for given genre columns.\n",
    "    Returns a DataFrame with counts and percentages.\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    summary = []\n",
    "    \n",
    "    for col in columns:\n",
    "        mask_valid = df[col].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "        valid = mask_valid.sum()\n",
    "        missing = total - valid\n",
    "        summary.append({\n",
    "            \"column\": col,\n",
    "            \"total_books\": total,\n",
    "            \"valid_genres\": valid,\n",
    "            \"missing_genres\": missing,\n",
    "            \"valid_%\": round((valid / total) * 100, 2),\n",
    "            \"missing_%\": round((missing / total) * 100, 2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# completeness check\n",
    "completeness = genre_completeness_report(\n",
    "    bbe_clean, \n",
    "    ['genres_parsed', 'genres_simplified']\n",
    ")\n",
    "print(\"Genre Completeness Summary\\n\")\n",
    "display(completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 8\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim genres datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a2887",
   "metadata": {},
   "source": [
    "**Awards**\n",
    "\n",
    "In this step, we will reuse some of the functions created for Genres to process the awards. After a first analysis we can see that the data has a temporal component that adds noise and inconsistency to the feature. Since temporality is already being captured in the `firstPublicationDate` we will strip this to clean the data and, therefore, creating a clean function specific for awards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b653caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean[['title','awards']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and handle missing awards values\n",
    "empty_awards_mask = (bbe_clean['awards'] == '[]')\n",
    "empty_awards = bbe_clean[empty_awards_mask].shape[0]\n",
    "share_missing_awards = (empty_awards / len(bbe_clean)) * 100\n",
    "print(f'Books with empty genre values: {empty_awards} ({share_missing_awards:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_awards_list(lst):\n",
    "    \"\"\"\n",
    "    Clean and normalize awards list:\n",
    "    - Lowercase and remove punctuation noise\n",
    "    - Remove year patterns like (2009) or (2010)\n",
    "    - Deduplicate entries\n",
    "    \"\"\"\n",
    "    if not isinstance(lst, list):\n",
    "        return np.nan\n",
    "\n",
    "    cleaned = []\n",
    "    for a in lst:\n",
    "        if not isinstance(a, str) or not a.strip():\n",
    "            continue\n",
    "        a = a.lower().strip()\n",
    "        # remove (YYYY) patterns\n",
    "        a = re.sub(r'\\(\\s*\\d{4}\\s*\\)', '', a)\n",
    "        # remove leftover punctuation and extra spaces\n",
    "        a = re.sub(r'[^a-z0-9\\s\\-\\&\\'\"]', '', a)\n",
    "        a = re.sub(r'\\s+', ' ', a).strip()\n",
    "        cleaned.append(a)\n",
    "\n",
    "    cleaned = list(set(cleaned))\n",
    "    return cleaned if cleaned else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['awards_parsed'] = bbe_clean['awards'].apply(parse_list_field)\n",
    "bbe_clean['awards_clean'] = bbe_clean['awards_parsed'].apply(clean_awards_list)\n",
    "bbe_clean[['title','awards','awards_parsed','awards_clean']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_awards_dict = count_unique_items(bbe_clean, 'awards_clean')\n",
    "num_unique_awards = len(unique_awards_dict)\n",
    "print(f\"Number of unique awards: {num_unique_awards}\")\n",
    "\n",
    "sorted_awards = sorted(unique_awards_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_awards[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f6983",
   "metadata": {},
   "source": [
    "Analysis shows that only a small subset, around **20%** includes award data, with **5,616 unique award names**. The high number of unique labels, combined with low frequency counts per award, makes this feature extremely **sparse and fragmented**. Even the most common award (“Dorothy Canfield Fisher Children's Book Award Nominee”) appears only **324 times** in a dataset of over **52,000 books**, representing less than **1%** of the records.\n",
    "\n",
    "Such high-cardinality categorical data introduces:\n",
    "\n",
    "* **Noise:** because similar awards appear under slightly different names or languages\n",
    "* **Inefficiency:** since one-hot or text encoding would explode feature dimensions\n",
    "* **Weak signal strength:** as most awards occur too infrequently to influence model patterns\n",
    "\n",
    "By simplifying this column into a **binary indicator (`has_award`)**, we preserve the meaningful information; whether a book has received any recognition — while removing the sparsity and variability that would degrade model performance.\n",
    "This boolean variable captures the *prestige signal* without the complexity, improving both interpretability and computational efficiency for downstream tasks such as **recommendation and clustering**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean flag for books with any valid awards\n",
    "bbe_clean['has_award'] = bbe_clean['awards_clean'].apply(\n",
    "    lambda x: isinstance(x, list) and len(x) > 0\n",
    ")\n",
    "bbe_clean[['title','awards_clean','has_award']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 9\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim awards datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56168233",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "Before cleaning, we inspected several book descriptions to identify common issues such as editorial notes, missing spaces after punctuation, escaped characters, and residual metadata (e.g., “Librarian’s note”, ISBN mentions, or “(Note: this title…)”).\n",
    "These observations informed the creation of a custom regex-based cleaning function.\n",
    "\n",
    "We then implemented a `clean_description()` function to remove noise, normalize spacing, and prepare text for analysis.\n",
    "Although NLP is currently a stretch goal, we decided to clean the text field proactively to ensure it’s ready for both readability and potential future feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and handle missing awards values\n",
    "no_description_mask = (bbe_clean['description'] == ' ')\n",
    "no_description = bbe_clean[no_description_mask].shape[0]\n",
    "share_no_description = (no_description / len(bbe_clean)) * 100\n",
    "print(f'Books with no description: {no_description} ({share_no_description:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fef9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean[['title','description']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a few different descriptions for inspection of things to be cleaned\n",
    "n = 6\n",
    "bbe_clean.loc[n, 'description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def clean_description(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # add a missing period and space between sentences when a lowercase letter \n",
    "    # that is immediately followed by an uppercase letter\n",
    "    text = re.sub(r\"([a-z])([A-Z])\", r\"\\1. \\2\", text)\n",
    "\n",
    "    # remove librarian/editorial notes and metadata (Note:, Alternate cover, ISBN refs)\n",
    "    text = re.sub(r\"\\(Note:.*?\\)\", \"\", text, flags=re.IGNORECASE)    \n",
    "    text = re.sub(r\"Librarian's note:.*?(?:\\.)\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    text = re.sub(r\"Alternate cover edition of ISBN \\d+\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"edition of ISBN \\d+\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "    # fix missing space after punctuation (.,;!?) when followed by letter/number\n",
    "    text = re.sub(r'([.,;!?])(?=[A-Za-z0-9])', r'\\1 ', text)\n",
    "\n",
    "    # fix missing space after ISBN numbers (e.g., \"9780679783268Since\")\n",
    "    text = re.sub(r'(\\d)([A-Za-z])', r'\\1 \\2', text)\n",
    "\n",
    "    # normalize escaped quotes\n",
    "    text = text.replace(\"\\\\'\", \"'\").replace('\\\\\"', '\"')\n",
    "\n",
    "    # keep readable characters, include # for \"#1\"\n",
    "    text = re.sub(r\"[^A-Za-zÀ-ÖØ-öø-ÿ0-9#\\s.,;!?\\'\\\"-]\", \" \", text)\n",
    "\n",
    "    # collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220a7ea",
   "metadata": {},
   "source": [
    "Before applying the cleaning function to the full dataset, we tested it on **synthetic example** representing all major issues (missing punctuation, uppercase continuity, notes, etc.). After validation, we split the results into two versions:\n",
    "\n",
    "* `description_clean`: preserves original casing — ideal for the **Streamlit dashboard** or display.\n",
    "* `description_nlp`: lowercase version — ready for **NLP or feature engineering** if needed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on synthetic description\n",
    "raw_description = \"\"\"\n",
    "Alternate cover edition of ISBN 9780679783268Since today.\n",
    "Librarian's note: An alternate cover edition can be found hereIt was 1939.Nazi Germany.The country is holding its breath.Death has never been busier!\n",
    "By her brother's graveside,Liesel's life changes when she picks up The Gravedigger's Handbook.\n",
    "(Note: this title was not published as YA fiction)\n",
    "\"WINNING MEANS FAME AND FORTUNE.LOSING MEANS CERTAIN DEATH.\"\n",
    "Jeune astronome convaincue de l'existence d'une vie extraterrestre intelligente...\n",
    "From #1 New York Times bestselling author Brandon Sanderson, The Way of Kings, book one of The Stormlight Archive begins an incredible new saga of epic proportion.Roshar is a world of stone and storms.\n",
    "\"\"\"\n",
    "print(clean_description(raw_description))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep readable version for UI\n",
    "bbe_clean['description_clean'] = bbe_clean['description'].apply(clean_description)\n",
    "\n",
    "# Lowercase version for NLP\n",
    "bbe_clean['description_nlp'] = bbe_clean['description_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c92777",
   "metadata": {},
   "source": [
    "Finally, we verified both `description_clean` and `description_nlp` for completeness and formatting consistency to confirm that the cleaning pipeline performed as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean[['title','description_clean','description_nlp']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 10\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim description datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a3e56",
   "metadata": {},
   "source": [
    "**Title**\n",
    "\n",
    "To ensure consistent and reproducible page-count retrieval from the Google Books API, we cleaned the `title` column into a new feature: `title_clean`.\n",
    "\n",
    "Cleaning steps applied:\n",
    "- Removed any parenthetical or bracketed information (e.g., \"(Box Set)\", \"[Hardcover Edition]\")  \n",
    "- Removed format indicators such as “Edition”, “Collection”, or “Book #”  \n",
    "- Normalized punctuation and spacing  \n",
    "- Lowercased all titles for consistent querying  \n",
    "\n",
    "This feature (`title_clean`) will be used as input for API-based data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean[['title']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b51e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_title(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean book titles for Google Books API queries.\n",
    "    \n",
    "    Steps:\n",
    "    - Remove bracketed or parenthetical notes (e.g. '(Box Set)', '[Hardcover]')\n",
    "    - Remove common edition/format words\n",
    "    - Remove ellipsis or truncated markers\n",
    "    - Normalize spaces and lowercase\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str):\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "    text = title.strip()\n",
    "    \n",
    "    # remove bracketed or parenthetical content\n",
    "    text = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    \n",
    "    # remove common edition/format terms\n",
    "    text = re.sub(r\"\\b(box set|collection|illustrated|edition|volume|vol\\.|book\\s*\\d+)\\b\", \"\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # remove ellipsis or truncation markers\n",
    "    text = text.replace(\"...\", \"\")\n",
    "    \n",
    "    # remove extra punctuation and multiple spaces\n",
    "    text = re.sub(r\"[^\\w\\s'\\-]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lowercase for API consistency\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['title_clean'] = bbe_clean['title'].apply(clean_title)\n",
    "bbe_clean['title_clean'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29b465",
   "metadata": {},
   "source": [
    "After cleaning the title field into `title_clean`, we focused on ensuring consistency in the dataset by filtering only English-language books. This decision was based on majority of English language books in the dataset and on maintaining data homogeneity for downstream analysis.\n",
    "\n",
    "We also chose to keep only one version of each title per author, prioritizing the record with the highest `numRatings`. This ensures that the retained record represents the most widely rated (and therefore most validated) version of the book, avoiding redundancy while preserving author attribution. By checking both `title_clean` and `author_clean`, we safeguard against incorrectly dropping books with similar titles but different authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicated raw titles (case-insensitive)\n",
    "dup_raw = bbe_clean[bbe_clean.duplicated(subset='title_clean', keep=False)]\n",
    "\n",
    "# sort and preview a few\n",
    "dup_raw.sort_values('title_clean').head(20)[['title_clean', 'author_clean', 'language_clean', 'rating_clean', 'numRatings',]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae18f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_en = bbe_clean[bbe_clean['language_clean'] == 'en'].copy()\n",
    "print(f\"Books before filtering: {len(bbe_clean)}\")\n",
    "print(f\"Books after filtering English only: {len(bbe_en)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1174603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_en = bbe_en[bbe_en.duplicated(subset=['title_clean', 'author_clean'], keep=False)]\n",
    "dup_en.sort_values(['title_clean', 'author_clean']).head(10)[\n",
    "    ['title_clean', 'author_clean', 'rating_clean', 'numRatings']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask for missing titles\n",
    "mask_no_title = dup_en['title'].isna() | (dup_en['title'] == \"\")\n",
    "\n",
    "# filter those rows\n",
    "no_title_books = dup_en[mask_no_title]\n",
    "\n",
    "# display summary\n",
    "print(f\"Books without title: {no_title_books.shape[0]}\")\n",
    "\n",
    "# inspect identifier columns if they exist\n",
    "identifier_cols = ['isbn', 'asin', 'bookId'] \n",
    "print(\"\\nAvailable identifiers for missing-title rows:\")\n",
    "print(no_title_books[identifier_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep highest numRatings version per (title_clean, author_clean)\n",
    "bbe_en_unique = (\n",
    "    bbe_en.sort_values('numRatings', ascending=False)\n",
    "          .drop_duplicates(subset=['title_clean', 'author_clean'], keep='first')\n",
    "          .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Books after deduplication: {len(bbe_en_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: ensure unique title-author combinations\n",
    "duplicates_check = bbe_en_unique[bbe_en_unique.duplicated(subset=['title_clean', 'author_clean'], keep=False)]\n",
    "\n",
    "if duplicates_check.empty:\n",
    "    print(\"Sanity check passed: No duplicate (title_clean, author_clean) pairs remain.\")\n",
    "else:\n",
    "    print(\"Warning: Duplicates still exist — review these cases:\")\n",
    "    display(duplicates_check[['title_clean', 'author_clean', 'numRatings']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765527c",
   "metadata": {},
   "source": [
    "At this stage, the dataset has been standardized, language-filtered, and deduplicated, producing a clean and reproducible foundation for subsequent tasks such as page count retrieval, feature engineering, and recommendation modeling.\n",
    "This cleaned version (`bbe_en_unique`) represents the highest-quality English entries suitable for integration with the Google Books API and further predictive analytics workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a889d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 11 \n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "interim_bbe_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bbe_en_unique.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(f\"Interim English-only deduplicated dataset saved successfully as bbe_clean_v{version}.csv in data/interim/bbe/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a2078",
   "metadata": {},
   "source": [
    "**Series**\n",
    "\n",
    "In this step, I reused the existing `clean_title()` function logic and adapted it into a new `clean_series()` function to clean the `series` feature. The function focuses on improving text consistency by removing unnecessary elements while keeping the core series name intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# retrieve the latest file\n",
    "bbe_clean = pd.read_csv('data/interim/bbe/bbe_clean_v11.csv', low_memory=False)\n",
    "\n",
    "bbe_clean[['title_clean','series']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5560836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_series(series: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean book series names for consistency.\n",
    "\n",
    "    Steps:\n",
    "    - Remove bracketed or parenthetical notes (e.g. '(Book 3)', '[Series]')\n",
    "    - Remove numeric indicators (#1, Book 2) while preserving base name\n",
    "    - Normalize spaces and lowercase\n",
    "    \"\"\"\n",
    "    if not isinstance(series, str) or series.strip() == \"\":\n",
    "        return np.nan\n",
    "    \n",
    "    text = series.strip()\n",
    "    \n",
    "    # remove bracketed or parenthetical content\n",
    "    text = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    \n",
    "    # remove series order markers (e.g. \"#1\", \"Book 2\", \"Vol. 3\")\n",
    "    text = re.sub(r\"(#\\d+|book\\s*\\d+|volume\\s*\\d+|vol\\.\\s*\\d+)\", \"\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # clean punctuation and normalize spacing\n",
    "    text = re.sub(r\"[^\\w\\s'\\-]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f698099",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['series_clean'] = bbe_clean['series'].apply(clean_series)\n",
    "bbe_clean[['title_clean','series_clean']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ddb9d",
   "metadata": {},
   "source": [
    "After cleaning, I validated the completeness of the feature. The analysis shows that **approximately 50% of the books belong to a series**, indicating that the `series` field carries significant information that should be retained for downstream modeling and recommendation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask for missing titles\n",
    "total_books = len(bbe_clean)\n",
    "mask_no_series = bbe_clean['series_clean'].isna() | (bbe_clean['series_clean'] == \"\")\n",
    "# filter those rows\n",
    "no_series_books = bbe_clean[mask_no_series]\n",
    "share_no_series = ( no_series_books.shape[0] / total_books) * 100\n",
    "\n",
    "# display summary\n",
    "print(f\"Books without series: {no_series_books.shape[0]} ({share_no_series:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834cfb9f",
   "metadata": {},
   "source": [
    "**Pages**\n",
    "\n",
    "Cleaning the title field reduced missing page data from **2.3K** to **1.5K**.\n",
    "Since book length often correlates with **reader engagement** and **retention**, improving this feature strengthens the reliability of our recommendation inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689963c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean[['title_clean','pages']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['pages'].value_counts(dropna=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eafd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-numeric characters and convert\n",
    "bbe_clean['pages_clean'] = (\n",
    "    bbe_clean['pages']\n",
    "    .astype(str)\n",
    "    .str.extract(r'(\\d+)')  # raw string to avoid escape warnings\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# replace unrealistic values with NaN\n",
    "bbe_clean.loc[\n",
    "    (bbe_clean['pages_clean'] < 10) | (bbe_clean['pages_clean'] > 3000),\n",
    "    'pages_clean'\n",
    "] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404178f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_missing = bbe_clean['pages_clean'].isna().sum()\n",
    "print(f\"Remaining missing pages: {new_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e49239",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min:\", bbe_clean['pages_clean'].min())\n",
    "print(\"Max:\", bbe_clean['pages_clean'].max())\n",
    "\n",
    "# quick quantile check\n",
    "print(bbe_clean['pages_clean'].quantile([0.01, 0.25, 0.5, 0.75, 0.99]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c25874",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_books = bbe_clean[bbe_clean['pages_clean'] < 100]\n",
    "short_books[['title_clean', 'author_clean', 'pages_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bbe_clean[bbe_clean['pages_clean'] < 500]['pages_clean'].hist(bins=50)\n",
    "plt.axvline(100, color='red', linestyle='--', label='100 pages')\n",
    "plt.title('Distribution of Book Lengths (up to 500 pages)')\n",
    "plt.xlabel('Pages')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_books['author_clean'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_books['genres_parsed'].explode().value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d042e5ef",
   "metadata": {},
   "source": [
    "Books with fewer than **100 pages** were inspected to ensure data validity.\n",
    "Titles like *The Little Prince*, *The Giving Tree*, and *The Old Man and the Sea* confirm that short works are genuine entries rather than data errors.\n",
    "The most frequent authors include **Dr. Seuss**, **Walt Disney Company**, and **Francine Pascal**, while dominant genres such as *Children’s*, *Poetry*, and *Picture Books* further validate these as authentic short-format books.\n",
    "Therefore, page counts below 100 are **considered valid** and retained for subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31887a0",
   "metadata": {},
   "source": [
    "**Edition**\n",
    "\n",
    "To evaluate whether the `edition` column added value to the dataset, we performed a simple descriptive analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_books = bbe_clean.shape[0]\n",
    "num_unique_editions = len(bbe_clean['edition'].unique())\n",
    "num_with_editions = bbe_clean['edition'].notna().sum()\n",
    "share_with_edition = (num_with_editions / total_books) * 100\n",
    "print(f'Books with Edition info: {num_with_editions} ({share_with_edition:.2f}%)')\n",
    "print(f'Edition values: {num_unique_editions}')\n",
    "bbe_clean['edition'].unique()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0b327",
   "metadata": {},
   "source": [
    "Findings:\n",
    "\n",
    "* Only **9.03%** of books contained edition information (`3,846` out of all records).\n",
    "* There were **1,204 unique edition values**, many describing print or regional variations (e.g., *“First Edition”*, *“US/CAN Edition”*, *“25th Anniversary Edition”*).\n",
    "* These labels were highly inconsistent and offered **little predictive or business relevance** for engagement or recommendation tasks.\n",
    "\n",
    "**Decision:**\n",
    "Given the low completeness, high cardinality, and weak relationship to the business problem (member engagement and retention), the column will be dropped at the end steps of the cleaning process. Removing `edition` simplified the dataset without losing meaningful information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5df342",
   "metadata": {},
   "source": [
    "**bbeVotes / bbeScore**\n",
    "\n",
    "Both `bbeVotes` and `bbeScore` were fully complete (100%) but required validation to confirm numeric consistency and detect potential anomalies.\n",
    "We will remove any formatting (commas, string types) and convert both columns to integers for accurate statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "368c93ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>rating_clean</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harry potter and the sorcerer's stone</td>\n",
       "      <td>7348</td>\n",
       "      <td>691430</td>\n",
       "      <td>4.47</td>\n",
       "      <td>7048471</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the hunger games</td>\n",
       "      <td>30516</td>\n",
       "      <td>2993816</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6376780</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twilight</td>\n",
       "      <td>14874</td>\n",
       "      <td>1459448</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4964519</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>23328</td>\n",
       "      <td>2269402</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4501075</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the great gatsby</td>\n",
       "      <td>8142</td>\n",
       "      <td>755074</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3775504</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title_clean  bbeVotes  bbeScore  rating_clean  \\\n",
       "0  harry potter and the sorcerer's stone      7348    691430          4.47   \n",
       "1                       the hunger games     30516   2993816          4.33   \n",
       "2                               twilight     14874   1459448          3.60   \n",
       "3                  to kill a mockingbird     23328   2269402          4.28   \n",
       "4                       the great gatsby      8142    755074          3.92   \n",
       "\n",
       "   numRatings  likedPercent  \n",
       "0     7048471          96.0  \n",
       "1     6376780          96.0  \n",
       "2     4964519          78.0  \n",
       "3     4501075          95.0  \n",
       "4     3775504          90.0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe_clean[['title_clean', 'bbeVotes', 'bbeScore', 'rating_clean', 'numRatings', 'likedPercent']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "464f14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove formatting and convert to integers\n",
    "bbe_clean['bbeVotes'] = (\n",
    "    bbe_clean['bbeVotes'].astype(str).str.replace(',', '').astype(int)\n",
    ")\n",
    "bbe_clean['bbeScore'] = (\n",
    "    bbe_clean['bbeScore'].astype(str).str.replace(',', '').astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ab426",
   "metadata": {},
   "source": [
    "Next, we will verify if the data follows a long-tailed distribution typical of popularity metrics (few books accumulate thousands of votes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6120d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bbeVotes      bbeScore\n",
      "count  42585.000000  4.258500e+04\n",
      "mean      27.232406  2.399671e+03\n",
      "std      409.581702  3.900573e+04\n",
      "min       -4.000000  0.000000e+00\n",
      "25%        1.000000  8.400000e+01\n",
      "50%        1.000000  9.800000e+01\n",
      "75%        3.000000  1.970000e+02\n",
      "max    30516.000000  2.993816e+06\n"
     ]
    }
   ],
   "source": [
    "print(bbe_clean[['bbeVotes', 'bbeScore']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b966d1",
   "metadata": {},
   "source": [
    " We identified one data quality issue: negative minimum in `bbeVotes` (likely an entry error). Marked for correction (`abs()` or `NaN` replacement depending on context). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2e838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count negative values\n",
    "bbe_clean[bbe_clean['bbeVotes'] < 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e984839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>bbeScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>men explain things to me</td>\n",
       "      <td>-4</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>secrets of a charmed life</td>\n",
       "      <td>-3</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>give and take a revolutionary approach to success</td>\n",
       "      <td>-3</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>leaving</td>\n",
       "      <td>-1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9677</th>\n",
       "      <td>mad dogs</td>\n",
       "      <td>-1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>nerd do well</td>\n",
       "      <td>-2</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13376</th>\n",
       "      <td>cane</td>\n",
       "      <td>-1</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>jet</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15032</th>\n",
       "      <td>the divorce papers</td>\n",
       "      <td>-2</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16431</th>\n",
       "      <td>arena one slaverunners</td>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16456</th>\n",
       "      <td>breaking even</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>how right you are jeeves</td>\n",
       "      <td>-1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17276</th>\n",
       "      <td>dragon ball z vol 1 the world's greatest team</td>\n",
       "      <td>-3</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17625</th>\n",
       "      <td>yotsuba vol 2</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17776</th>\n",
       "      <td>the malloreon vol 1 guardians of the west king...</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18760</th>\n",
       "      <td>yotsuba vol 03</td>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19767</th>\n",
       "      <td>ring for jeeves</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20259</th>\n",
       "      <td>toms river a story of science and salvation</td>\n",
       "      <td>-3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21168</th>\n",
       "      <td>battle angel alita 02 tears of an angel</td>\n",
       "      <td>-1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22391</th>\n",
       "      <td>battle angel alita 03 killing angel</td>\n",
       "      <td>-1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23428</th>\n",
       "      <td>james joyce</td>\n",
       "      <td>-2</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24188</th>\n",
       "      <td>battle angel alita 04 angel of victory</td>\n",
       "      <td>-1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24908</th>\n",
       "      <td>angel of redemption</td>\n",
       "      <td>-1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26549</th>\n",
       "      <td>adventures of a psychic the fascinating and in...</td>\n",
       "      <td>-1</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26569</th>\n",
       "      <td>mist of midnight</td>\n",
       "      <td>-4</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27178</th>\n",
       "      <td>canticle</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27271</th>\n",
       "      <td>the predicteds</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27469</th>\n",
       "      <td>homegrown democrat a few plain thoughts from t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28053</th>\n",
       "      <td>kindle fire owner's manual the ultimate kindle...</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28793</th>\n",
       "      <td>rurouni kenshin vol 1 1-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30156</th>\n",
       "      <td>still waters</td>\n",
       "      <td>-2</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31039</th>\n",
       "      <td>the royal family</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31374</th>\n",
       "      <td>camille claudel</td>\n",
       "      <td>-2</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32167</th>\n",
       "      <td>10 sexy stories thank you our readers erotica ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32191</th>\n",
       "      <td>little black a pony</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33923</th>\n",
       "      <td>healing grief reclaiming life after any loss</td>\n",
       "      <td>-3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35781</th>\n",
       "      <td>crimson cipher</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>mexican eskimo exmikan</td>\n",
       "      <td>-2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39411</th>\n",
       "      <td>frontier fury</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39931</th>\n",
       "      <td>hell night</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40271</th>\n",
       "      <td>hazard zone</td>\n",
       "      <td>-1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_clean  bbeVotes  bbeScore\n",
       "3116                            men explain things to me        -4        96\n",
       "3598                           secrets of a charmed life        -3        79\n",
       "6394   give and take a revolutionary approach to success        -3        99\n",
       "8322                                             leaving        -1        78\n",
       "9677                                            mad dogs        -1        84\n",
       "12196                                       nerd do well        -2        98\n",
       "13376                                               cane        -1       193\n",
       "15000                                                jet        -1       100\n",
       "15032                                 the divorce papers        -2        98\n",
       "16431                             arena one slaverunners        -1        95\n",
       "16456                                      breaking even        -1        97\n",
       "16964                           how right you are jeeves        -1        99\n",
       "17276      dragon ball z vol 1 the world's greatest team        -3        80\n",
       "17625                                      yotsuba vol 2        -1        96\n",
       "17776  the malloreon vol 1 guardians of the west king...        -1       100\n",
       "18760                                     yotsuba vol 03        -1        95\n",
       "19767                                    ring for jeeves        -1        97\n",
       "20259        toms river a story of science and salvation        -3        81\n",
       "21168            battle angel alita 02 tears of an angel        -1        84\n",
       "22391                battle angel alita 03 killing angel        -1        83\n",
       "23428                                        james joyce        -2       160\n",
       "24188             battle angel alita 04 angel of victory        -1        82\n",
       "24908                                angel of redemption        -1        81\n",
       "26549  adventures of a psychic the fascinating and in...        -1       162\n",
       "26569                                   mist of midnight        -4        96\n",
       "27178                                           canticle        -1        97\n",
       "27271                                     the predicteds        -1        98\n",
       "27469  homegrown democrat a few plain thoughts from t...        -1        99\n",
       "28053  kindle fire owner's manual the ultimate kindle...        -1       100\n",
       "28793                          rurouni kenshin vol 1 1-3        -2        96\n",
       "30156                                       still waters        -2        97\n",
       "31039                                   the royal family        -1        96\n",
       "31374                                    camille claudel        -2        99\n",
       "32167  10 sexy stories thank you our readers erotica ...        -1        95\n",
       "32191                                little black a pony        -1       100\n",
       "33923       healing grief reclaiming life after any loss        -3        86\n",
       "35781                                     crimson cipher        -1        98\n",
       "38944                             mexican eskimo exmikan        -2        96\n",
       "39411                                      frontier fury        -1        97\n",
       "39931                                         hell night        -1        98\n",
       "40271                                        hazard zone        -1        99"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect negative values\n",
    "bbe_clean[bbe_clean['bbeVotes'] < 0][['title_clean', 'bbeVotes', 'bbeScore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89509ad",
   "metadata": {},
   "source": [
    "Detected 41 invalid negative vote counts across valid book entries.\n",
    "Given that magnitudes ranged from –1 to –4 and titles were legitimate (e.g., _Men Explain Things to Me_, _Battle Angel Alita_), these were treated as sign errors. The correction applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the absolute value correction.\n",
    "bbe_clean['bbeVotes'] = bbe_clean['bbeVotes'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f6ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count negative values again to validate transformation\n",
    "bbe_clean[bbe_clean['bbeVotes'] < 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55079b7",
   "metadata": {},
   "source": [
    "Next, we will use boxplotting to inspect for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "24de6554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bbeVotes       Axes(0.125,0.11;0.352273x0.77)\n",
       "bbeScore    Axes(0.547727,0.11;0.352273x0.77)\n",
       "dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bbe_clean[['bbeVotes', 'bbeScore']].plot(kind='box', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b268a7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>bbeScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the hunger games</td>\n",
       "      <td>30516</td>\n",
       "      <td>2993816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>harry potter and the order of the phoenix</td>\n",
       "      <td>26923</td>\n",
       "      <td>2632233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>23328</td>\n",
       "      <td>2269402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pride and prejudice</td>\n",
       "      <td>20452</td>\n",
       "      <td>1983116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twilight</td>\n",
       "      <td>14874</td>\n",
       "      <td>1459448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>the book thief</td>\n",
       "      <td>14168</td>\n",
       "      <td>1372809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>animal farm</td>\n",
       "      <td>13264</td>\n",
       "      <td>1276599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>the chronicles of narnia</td>\n",
       "      <td>12949</td>\n",
       "      <td>1238556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>jrr tolkien 4-book boxed set the hobbit and th...</td>\n",
       "      <td>12111</td>\n",
       "      <td>1159802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the fault in our stars</td>\n",
       "      <td>11287</td>\n",
       "      <td>1087056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_clean  bbeVotes  bbeScore\n",
       "1                                      the hunger games     30516   2993816\n",
       "20            harry potter and the order of the phoenix     26923   2632233\n",
       "3                                 to kill a mockingbird     23328   2269402\n",
       "7                                   pride and prejudice     20452   1983116\n",
       "2                                              twilight     14874   1459448\n",
       "38                                       the book thief     14168   1372809\n",
       "13                                          animal farm     13264   1276599\n",
       "226                            the chronicles of narnia     12949   1238556\n",
       "1361  jrr tolkien 4-book boxed set the hobbit and th...     12111   1159802\n",
       "5                                the fault in our stars     11287   1087056"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = bbe_clean.nlargest(10, 'bbeVotes')[['title_clean', 'bbeVotes', 'bbeScore']]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53eec3",
   "metadata": {},
   "source": [
    " Boxplots reveal extreme but valid outliers for high-performing books (e.g. *The Hunger Games*, *Harry Potter*). Outliers were retained since they represent meaningful popularity signals rather than noise.\n",
    "\n",
    " After cleaning and validating, both variables are ready for downstream analysis (correlation, scaling, or feature engineering). No transformation beyond this stage is required during the cleaning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "296925e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim bbeVotes and bbeScore datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 12\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim bbeVotes and bbeScore datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12081e8e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
