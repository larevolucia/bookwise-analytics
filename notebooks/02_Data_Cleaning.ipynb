{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fc4fb3",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The purpose of this notebook is to **clean, standardize, and prepare the collected datasets** for subsequent exploratory analysis and modeling tasks.\n",
    "\n",
    "The goal is to transform raw inputs from multiple book datasets into a **reliable, consistent, and mergeable analytical base**, ensuring data integrity and comparability across platforms.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "| Dataset                    | Source                     | Description                                                               | Format |\n",
    "| -------------------------- | -------------------------- | ------------------------------------------------------------------------- | ------ |\n",
    "| `bbe_books.csv`            | Zenodo – *Best Books Ever* | Book metadata including title, author, rating, genres, and description.   | CSV    |\n",
    "| `books.csv`, `ratings.csv` | GitHub – *Goodbooks-10k*   | Book metadata and user–book interaction data for recommendation modeling. | CSV    |\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks in This Notebook\n",
    "\n",
    "This notebook will execute the following cleaning and preparation steps:\n",
    "\n",
    "1. **Standardize column formats:**\n",
    "   Ensure consistent data types and naming conventions across datasets (e.g., convert `isbn` to string, align `author`, `rating`, and `title` formats).\n",
    "\n",
    "2. **Clean and normalize missing values:**\n",
    "   Replace placeholder NaNs (`9999999999999`, empty lists, or `\"None\"`) with `np.nan`, then impute or drop based on analytical importance.\n",
    "\n",
    "3. **Detect and resolve duplicates:**\n",
    "   Identify duplicate records using key identifiers (`bookId`, `isbn`, `title + author`) and retain the most complete or relevant entries.\n",
    "\n",
    "4. **Validate and align categorical values:**\n",
    "   Standardize genre labels, language codes, and rating scales to ensure comparability between datasets.\n",
    "\n",
    "5. **Merge compatible datasets:**\n",
    "   Integrate *BestBooksEver* and *Goodbooks-10k_books* into a unified schema while maintaining referential integrity with the ratings dataset.\n",
    "\n",
    "6. **Outlier and consistency checks:**\n",
    "   Review numerical and date fields (e.g., `pages`, `price`, `publishDate`) for unrealistic or extreme values and adjust as needed.\n",
    "\n",
    "7. **Feature enrichment (optional):**\n",
    "   Derive or enhance fields such as `popularity_score`, `recency`, or missing genre information using external APIs where beneficial.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* **Cleaned, schema-aligned datasets** ready for exploratory data analysis and modeling.\n",
    "* **Summary statistics** on completeness, duplicates, and outliers.\n",
    "* **Processed CSV files** saved for reproducibility in `data/processed/`.\n",
    "\n",
    "> **Note:** This notebook focuses on the *Data Cleaning and Preparation*. Further feature engineering and model-specific transformations will follow in later notebooks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383657df",
   "metadata": {},
   "source": [
    "## Navigate to the Parent Directory\n",
    "\n",
    "Before combining and saving datasets, it’s often helpful to move to a parent directory so that file operations (like loading or saving data) are easier and more organized. \n",
    "\n",
    "Before using the Python’s built-in os module to move one level up from the current working directory, it is advisable to inspect the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc6e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f3220",
   "metadata": {},
   "source": [
    "To change to parent directory (root folder), run the code below. If you are already in the root folder, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c41cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to parent.\n",
      "New current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to its parent\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Changed directory to parent.')\n",
    "\n",
    "# Get the new current working directory (the parent directory)\n",
    "current_dir = os.getcwd()\n",
    "print(f'New current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1120c",
   "metadata": {},
   "source": [
    "## Load and Inspect Books Datasets\n",
    "\n",
    "In this step, we load the previously collected datasets: **Goodbooks-10k** (books) and **Best Books Ever**. We will inspect their structure one more time before starting any merging or cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f7670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# load datasets\n",
    "books_raw = pd.read_csv('data/raw/books.csv')\n",
    "bbe_raw = pd.read_csv('data/raw/bbe_books.csv')\n",
    "\n",
    "# create copies for cleaning\n",
    "books_clean = books_raw.copy()\n",
    "bbe_clean = bbe_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "interim_bbe_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "interim_gb_path = Path(\"data/interim/goodbooks\")\n",
    "interim_gb_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "version = 0\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "books_clean.to_csv(interim_gb_path / f\"books_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5230208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>isbn</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>...</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>bookId_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052-the-hunger-games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2993816</td>\n",
       "      <td>30516</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2767052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>4.50</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98.0</td>\n",
       "      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2632233</td>\n",
       "      <td>26923</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>['Maycomb, Alabama (United States)']</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2269402</td>\n",
       "      <td>23328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2657.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        bookId  \\\n",
       "0                     2767052-the-hunger-games   \n",
       "1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n",
       "2                   2657.To_Kill_a_Mockingbird   \n",
       "\n",
       "                                       title                 series  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "\n",
       "                                      author  rating  \\\n",
       "0                            Suzanne Collins    4.33   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)    4.50   \n",
       "2                                 Harper Lee    4.28   \n",
       "\n",
       "                                         description language           isbn  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...  English  9780439023481   \n",
       "1  There is a door at the end of a silent corrido...  English  9780439358071   \n",
       "2  The unforgettable novel of a childhood in a sl...  English  9999999999999   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n",
       "2  ['Classics', 'Fiction', 'Historical Fiction', ...   \n",
       "\n",
       "                                          characters  ...  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  ...   \n",
       "1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  ...   \n",
       "2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  ...   \n",
       "\n",
       "                                              awards numRatings  \\\n",
       "0  ['Locus Award Nominee for Best Young Adult Boo...    6376780   \n",
       "1  ['Bram Stoker Award for Works for Young Reader...    2507623   \n",
       "2  ['Pulitzer Prize for Fiction (1961)', 'Audie A...    4501075   \n",
       "\n",
       "                                      ratingsByStars likedPercent  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...         96.0   \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']         98.0   \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...         95.0   \n",
       "\n",
       "                                             setting  \\\n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...   \n",
       "1  ['Hogwarts School of Witchcraft and Wizardry (...   \n",
       "2               ['Maycomb, Alabama (United States)']   \n",
       "\n",
       "                                            coverImg bbeScore  bbeVotes price  \\\n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...  2993816     30516  5.09   \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...  2632233     26923  7.38   \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...  2269402     23328   NaN   \n",
       "\n",
       "   bookId_num  \n",
       "0   2767052.0  \n",
       "1         2.0  \n",
       "2      2657.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052.0</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865.0</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1          2767052.0       2767052  2792775          272  439023483   \n",
       "1        2                3.0             3  4640799          491  439554934   \n",
       "2        3            41865.0         41865  3212258          226  316015849   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BBE — Shape: (52478, 26)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bookId            52478 non-null  object \n",
      " 1   title             52478 non-null  object \n",
      " 2   series            23470 non-null  object \n",
      " 3   author            52478 non-null  object \n",
      " 4   rating            52478 non-null  float64\n",
      " 5   description       51140 non-null  object \n",
      " 6   language          48672 non-null  object \n",
      " 7   isbn              52478 non-null  object \n",
      " 8   genres            52478 non-null  object \n",
      " 9   characters        52478 non-null  object \n",
      " 10  bookFormat        51005 non-null  object \n",
      " 11  edition           4955 non-null   object \n",
      " 12  pages             50131 non-null  object \n",
      " 13  publisher         48782 non-null  object \n",
      " 14  publishDate       51598 non-null  object \n",
      " 15  firstPublishDate  31152 non-null  object \n",
      " 16  awards            52478 non-null  object \n",
      " 17  numRatings        52478 non-null  int64  \n",
      " 18  ratingsByStars    52478 non-null  object \n",
      " 19  likedPercent      51856 non-null  float64\n",
      " 20  setting           52478 non-null  object \n",
      " 21  coverImg          51873 non-null  object \n",
      " 22  bbeScore          52478 non-null  int64  \n",
      " 23  bbeVotes          52478 non-null  int64  \n",
      " 24  price             38113 non-null  object \n",
      " 25  bookId_num        52478 non-null  float64\n",
      "dtypes: float64(3), int64(3), object(20)\n",
      "memory usage: 10.4+ MB\n",
      "None\n",
      "edition             47523\n",
      "series              29008\n",
      "firstPublishDate    21326\n",
      "price               14365\n",
      "language             3806\n",
      "dtype: int64\n",
      "\n",
      "Books — Shape: (10000, 23)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   book_id                    10000 non-null  int64  \n",
      " 1   goodreads_book_id          10000 non-null  float64\n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(4), int64(12), object(7)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "language_code                1084\n",
      "isbn                          700\n",
      "isbn13                        585\n",
      "original_title                585\n",
      "original_publication_year      21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preview data\n",
    "display(bbe_clean.head(3))\n",
    "display(books_clean.head(3))\n",
    "\n",
    "# Check shape and missing values\n",
    "for name, df in {'BBE': bbe_clean, 'Books': books_clean,}.items():\n",
    "    print(f\"\\n{name} — Shape: {df.shape}\")\n",
    "    print(df.info())\n",
    "    print(df.isna().sum().sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b59d8",
   "metadata": {},
   "source": [
    "We will check if the datasets share common identifiers and compatible data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4382d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in BBE: {'awards', 'bbeVotes', 'price', 'description', 'genres', 'bookFormat', 'numRatings', 'publishDate', 'likedPercent', 'author', 'rating', 'bbeScore', 'pages', 'setting', 'language', 'coverImg', 'publisher', 'ratingsByStars', 'bookId_num', 'series', 'bookId', 'edition', 'firstPublishDate', 'characters'}\n",
      "Columns only in Goodbooks: {'goodreads_book_id', 'isbn13', 'work_text_reviews_count', 'ratings_3', 'ratings_5', 'books_count', 'average_rating', 'book_id', 'ratings_count', 'ratings_2', 'original_publication_year', 'language_code', 'authors', 'image_url', 'work_ratings_count', 'best_book_id', 'original_title', 'ratings_1', 'work_id', 'small_image_url', 'ratings_4'}\n"
     ]
    }
   ],
   "source": [
    "bbe_only_columns = set(bbe_clean.columns) - set(books_clean.columns)\n",
    "print(f'Columns only in BBE: {bbe_only_columns}')\n",
    "\n",
    "goodbooks_only_columns = set(books_clean.columns) - set(bbe_clean.columns)\n",
    "print(f'Columns only in Goodbooks: {goodbooks_only_columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66be32",
   "metadata": {},
   "source": [
    "Based on the initial inspection, we can create a mapping table to align columns from both datasets for merging and analysis.\n",
    "\n",
    "| **BestBooksEver (BBE)** | **Goodbooks10k_books (GB10k)** | **Notes / Alignment Rationale** |\n",
    "| --------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------- |\n",
    "| `bookId` | `book_id` | Main identifier; ensure both are numeric. |\n",
    "| `bookId_num` | `goodreads_book_id` | Goodreads identifier; ensure both are numeric for joining. |\n",
    "| `title` | `title` | Direct match. Used as secondary join key. |\n",
    "| `series` | — | Only in BBE; could enrich GB10k if available via API. |\n",
    "| `author` | `authors` | Same meaning. Normalize format. |\n",
    "| `rating` | `average_rating` | Equivalent — rename to unified `average_rating`. |\n",
    "| `numRatings` | `ratings_count` | Same measure of total user ratings. |\n",
    "| `ratingsByStars` | `ratings_1` … `ratings_5` | BBE has dict, GB10k has explicit columns. Expand or aggregate accordingly. |\n",
    "| `likedPercent` | — | BBE-only; optional metric of user sentiment. |\n",
    "| `isbn` | `isbn` / `isbn13` | Common linking key; keep both (string). Use for merges when present. |\n",
    "| `language` | `language_code` | Standardize to ISO 639-1 (lowercase). |\n",
    "| `description` | — | BBE-only; valuable for NLP features. |\n",
    "| `genres` | — | BBE-only; can enrich GB10k tags later. |\n",
    "| `characters` | — | bbe_clean-only; low modeling priority, but could add narrative metadata. |\n",
    "| `bookFormat` | — | BBE-only; possible categorical feature. |\n",
    "| `edition` | — | BBE-only. |\n",
    "| `pages` | — | BBE-only; numeric, may enrich GB10k metadata. |\n",
    "| `publisher` | — | bbe_clean_clean-only; possible future feature. |\n",
    "| `publishDate` | — | bbe_clean_clean-only; can approximate from GB10k’s `original_publication_year`. |\n",
    "| `firstPublishDate` | `original_publication_year` | Equivalent (date vs year). |\n",
    "| `coverImg` | `image_url` / `small_image_url` | Same function (cover link). |\n",
    "| `bbeScore` | — | BBE-only; internal popularity score. |\n",
    "| `bbeVotes` | `work_ratings_count` | Comparable as popularity proxy. |\n",
    "| `price` | — | BBE-only; likely non-essential for satisfaction prediction. |\n",
    "| `setting` | — | BBE-only; can support content enrichment. |\n",
    "| `awards` | — | BBE-only; categorical enrichment. |\n",
    "| — | `goodreads_book_id` / `best_book_id` / `work_id` | GB10k-only identifiers; may be used for deeper Goodreads linking. |\n",
    "| — | `books_count` | GB10k-only; number of editions per work. |\n",
    "| — | `work_text_reviews_count` | GB10k-only; can complement `numRatings` as engagement metric. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5069ac1",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "### Best Books Ever\n",
    "\n",
    "- Handle identifier columns\n",
    "- Standardize key columns: `author`, `language`\n",
    "- Missing data handling strategies\n",
    "- Normalize genre and format\n",
    "- Validate for no nulls or duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e6ae8",
   "metadata": {},
   "source": [
    "#### 1. Handle identifier columns\n",
    "On the previous notebook, we created a new field `bookId_num` in the BBE dataset to align with `goodreads_book_id` in the Goodbooks10k dataset. We have also ensured that they were both converted to numeric types and that all `bookId` values generated a valid `bookId_num`. So we can skip the handle identifier columns, as it was already done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6e5f",
   "metadata": {},
   "source": [
    "#### 2. Standardize key columns\n",
    "\n",
    "**Author**\n",
    "\n",
    "We will proceed with the standardization of key columns, starting with the `author` column. The author column in the BBE dataset often contains a qualifier such as \"(Goodreads Author)\". We will remove such qualifiers to standardize the format. We will also create an additional list column to store multiple authors as a list rather than a single string. This way, its is ready to use for feature engineering later on if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c0d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_and_split_authors(name):\n",
    "    \"\"\"\n",
    "    Cleans author names and returns a list of authors.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    # Remove role descriptors\n",
    "    cleaned = re.sub(r\"\\s*\\([^)]*\\)\", \"\", name)\n",
    "    \n",
    "    # Split into list if multiple authors exist\n",
    "    authors_list = [a.strip() for a in cleaned.split(\",\") if a.strip()]\n",
    "    \n",
    "    return authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145894ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>authors_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>[Suzanne Collins]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>[J.K. Rowling, Mary GrandPré]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>[Harper Lee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen, Anna Quindlen (Introduction)</td>\n",
       "      <td>Jane Austen, Anna Quindlen</td>\n",
       "      <td>[Jane Austen, Anna Quindlen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>[Stephenie Meyer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      author                 author_clean  \\\n",
       "0                            Suzanne Collins              Suzanne Collins   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)  J.K. Rowling, Mary GrandPré   \n",
       "2                                 Harper Lee                   Harper Lee   \n",
       "3  Jane Austen, Anna Quindlen (Introduction)   Jane Austen, Anna Quindlen   \n",
       "4                            Stephenie Meyer              Stephenie Meyer   \n",
       "\n",
       "                    authors_list  \n",
       "0              [Suzanne Collins]  \n",
       "1  [J.K. Rowling, Mary GrandPré]  \n",
       "2                   [Harper Lee]  \n",
       "3   [Jane Austen, Anna Quindlen]  \n",
       "4              [Stephenie Meyer]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to BestBooksEver dataset\n",
    "bbe_clean[\"authors_list\"] = bbe_clean[\"author\"].apply(clean_and_split_authors)\n",
    "bbe_clean[\"author_clean\"] = bbe_clean[\"authors_list\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else None)\n",
    "\n",
    "# Quick check\n",
    "bbe_clean[[\"author\", \"author_clean\", \"authors_list\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6990455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim author datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 1\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim author datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a74c31",
   "metadata": {},
   "source": [
    "**Language**\n",
    "\n",
    "The `language` column in the Best Books Ever dataset used full names such as “English”, “German”, and “Arabic”.  Before transforming the values, we will check for all unique values to identify any unexpected entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f122d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique language values in BBE dataset:\n",
      "\n",
      "Total unique values: 82\n",
      "\n",
      "['English' 'French' 'German' 'Persian' 'Arabic' 'nan' 'Spanish'\n",
      " 'Multiple languages' 'Portuguese' 'Indonesian' 'Turkish' 'Polish'\n",
      " 'Bulgarian' 'Tamil' 'Japanese' 'Romanian' 'Italian'\n",
      " 'French, Middle (ca.1400-1600)' 'Norwegian' 'Urdu' 'Dutch' 'Finnish'\n",
      " 'Marathi' 'Chinese' 'Swedish' 'Icelandic' 'Malayalam' 'Croatian'\n",
      " 'Estonian' 'Greek, Modern (1453-)' 'Russian' 'Kurdish' 'Danish' 'Hindi'\n",
      " 'Filipino; Pilipino' 'Serbian' 'Bengali' 'Malay' 'Catalan; Valencian'\n",
      " 'Czech' 'Vietnamese' 'Armenian' 'Georgian' 'Kannada' 'Korean' 'Nepali'\n",
      " 'Slovak' 'Telugu' 'Hungarian' 'English, Middle (1100-1500)' 'Azerbaijani'\n",
      " 'Farsi' 'Lithuanian' 'Ukrainian' 'Bokmål, Norwegian; Norwegian Bokmål'\n",
      " 'Iranian (Other)' 'Faroese' 'Basque' 'Macedonian' 'Maltese' 'Gujarati'\n",
      " 'Amharic' 'Aromanian; Arumanian; Macedo-Romanian' 'Assamese'\n",
      " 'Panjabi; Punjabi' 'Albanian' 'Latvian' 'Bosnian' 'Afrikaans' 'Thai'\n",
      " 'Dutch, Middle (ca.1050-1350)' 'Mongolian' 'Tagalog' 'Galician' 'Aleut'\n",
      " 'Slovenian' 'Undetermined' 'Greek, Ancient (to 1453)' 'Mayan languages'\n",
      " 'Duala' 'Australian languages' 'Norwegian Nynorsk; Nynorsk, Norwegian']\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique language values\n",
    "print(\"Unique language values in BBE dataset:\")\n",
    "bbe_clean['language'] = bbe_clean['language'].astype(str).str.strip()\n",
    "unique_languages = bbe_clean['language'].unique()\n",
    "\n",
    "print(f\"\\nTotal unique values: {len(unique_languages)}\\n\")\n",
    "print(unique_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d9853",
   "metadata": {},
   "source": [
    "We can see that there are some unexpected values such as:\n",
    "- _historical forms_ (“English, Middle (1100-1500)”, “French, Middle (ca.1400-1600)”)\n",
    "- _combined or semicolon-separated entries_ (“Filipino; Pilipino”, “Catalan; Valencian”)\n",
    "- _multi-language / uncertain cases_ (“Multiple languages”, “Undetermined”)\n",
    "- _rare or dialects_ (“Bokmål, Norwegian; Norwegian Bokmål”, “Aromanian; Arumanian; Macedo-Romanian”)\n",
    "\n",
    "We will clean the unusual entries by mapping them to the closest language present in the ISO 639-1 standard. Unrecognized values will be flagged and replaced with `\"unknown\"`. It was decided to distinguish the `\"unknown\"` from the `NaN` values to retain information about missingness versus unrecognized entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a83c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Standardize capitalization & spacing\n",
    "bbe_clean['language'] = bbe_clean['language'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Handle NaNs that became strings\n",
    "bbe_clean['language'] = bbe_clean['language'].replace({'Nan': np.nan})\n",
    "\n",
    "# Simplify and unify multi-language / dialect forms\n",
    "replace_map = {\n",
    "    'Multiple Languages': 'Multilingual',\n",
    "    'Undetermined': 'Unknown',\n",
    "    'Iranian (Other)': 'Persian',\n",
    "    'Farsi': 'Persian',\n",
    "    'Filipino; Pilipino': 'Filipino',\n",
    "    'Catalan; Valencian': 'Catalan',\n",
    "    'Panjabi; Punjabi': 'Punjabi',\n",
    "    'Bokmål, Norwegian; Norwegian Bokmål': 'Norwegian',\n",
    "    'Norwegian Nynorsk; Nynorsk, Norwegian': 'Norwegian',\n",
    "    'Greek, Modern (1453-)': 'Greek',\n",
    "    'Greek, Ancient (To 1453)': 'Greek',\n",
    "    'French, Middle (Ca.1400-1600)': 'French',\n",
    "    'English, Middle (1100-1500)': 'English',\n",
    "    'Dutch, Middle (Ca.1050-1350)': 'Dutch',\n",
    "    'Aromanian; Arumanian; Macedo-Romanian': 'Romanian',\n",
    "    'Mayan Languages': 'Mayan',\n",
    "    'Australian Languages': 'English'\n",
    "}\n",
    "\n",
    "bbe_clean['language'] = bbe_clean['language'].replace(replace_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ad13",
   "metadata": {},
   "source": [
    "After transforming the values, we apply a mapping to standardize the `language` column using **ISO 639-1 two-letter codes**.\n",
    "The mapping dictionaries are stored in the `src/cleaning/mappings/` folder to keep the notebooks cleaner and improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37289380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"src/cleaning/mappings/languages_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    languages_dict = json.load(f)\n",
    "\n",
    "# Apply dictionary\n",
    "bbe_clean['language_clean'] = bbe_clean['language'].str.lower().map(languages_dict)\n",
    "\n",
    "# Fill remaining NaNs\n",
    "bbe_clean['language_clean'] = bbe_clean['language_clean'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "736c49f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique language values in BBE dataset:\n",
      "\n",
      "Total unique values: 62\n",
      "\n",
      "['en' 'fr' 'de' 'fa' 'ar' 'unknown' 'es' 'multi' 'pt' 'id' 'tr' 'pl' 'bg'\n",
      " 'ta' 'ja' 'ro' 'it' 'no' 'ur' 'nl' 'fi' 'mr' 'zh' 'sv' 'is' 'ml' 'hr'\n",
      " 'et' 'el' 'ru' 'da' 'hi' 'fil' 'cs' 'vi' 'hy' 'ka' 'kn' 'ko' 'ne' 'sk'\n",
      " 'te' 'hu' 'az' 'lt' 'uk' 'fo' 'eu' 'mk' 'mt' 'gu' 'am' 'pa' 'sq' 'lv'\n",
      " 'bs' 'th' 'mn' 'tl' 'gl' 'sl' 'myn']\n"
     ]
    }
   ],
   "source": [
    "# check again for unique language values\n",
    "print(\"Unique language values in BBE dataset:\")\n",
    "unique_languages = bbe_clean['language_clean'].unique()\n",
    "\n",
    "print(f\"\\nTotal unique values: {len(unique_languages)}\\n\")\n",
    "print(unique_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2cc856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count  percentage\n",
      "language                    \n",
      "English    42663       81.30\n",
      "Arabic      1038        1.98\n",
      "Spanish      687        1.31\n",
      "French       580        1.11\n",
      "German       528        1.01\n",
      "...          ...         ...\n",
      "Mongolian      1        0.00\n",
      "Aleut          1        0.00\n",
      "Unknown        1        0.00\n",
      "Mayan          1        0.00\n",
      "Duala          1        0.00\n",
      "\n",
      "[71 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "language_breakdown = (\n",
    "    bbe_clean['language']\n",
    "    .value_counts()\n",
    "    .to_frame('count')\n",
    ")\n",
    "\n",
    "language_breakdown['percentage'] = (\n",
    "    language_breakdown['count'] / len(bbe_clean) * 100\n",
    ").round(2)\n",
    "\n",
    "print(language_breakdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0039be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim language datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 2\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim language datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6b8f9",
   "metadata": {},
   "source": [
    "**Dates**\n",
    "\n",
    "BBE dataset has two publication fields: `publishDate` and `firstPublishDate`. The `firstPublishDate` represents the original publication date, while `publishDate` refers to a more recent edition or reprint date. Publishing experts assumption is that the recency of the `firstPublishDate` is more relevant for modeling book satisfaction, as it reflects when the book was first introduced to readers. Therefore, we will focus on cleaning and standardizing the `firstPublishDate` column and use `publishDate` only if `firstPublishDate` is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2685c",
   "metadata": {},
   "source": [
    "While majority of the dates follow the 'MM/DD/YY' format, after a first attemp at cleaning, we noticed some dates do not conform to this format. Therefore, we will implement a more robust date parsing strategy, focusing first on transforming textual formats into 'MM/DD/YYYY' format before attempting to parse them into datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db6d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def clean_date_string(date_str):\n",
    "    \"\"\"Remove ordinal suffixes and unwanted characters from a date string.\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return np.nan\n",
    "    # remove st, nd, rd, th (like 'April 27th 2010' → 'April 27 2010')\n",
    "    cleaned = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', str(date_str))\n",
    "    return cleaned.strip()\n",
    "\n",
    "def parse_mixed_date(date_str):\n",
    "    \"\"\"Try to parse a variety of date formats safely.\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Use dateutil to parse most human-readable formats\n",
    "        return parser.parse(date_str, fuzzy=True)\n",
    "    except Exception:\n",
    "        # Try year-only fallback (e.g. '2003')\n",
    "        match = re.match(r'^\\d{4}$', str(date_str))\n",
    "        if match:\n",
    "            return pd.to_datetime(f\"{date_str}-01-01\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a7cc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to both columns\n",
    "for col in ['firstPublishDate', 'publishDate']:\n",
    "       bbe_clean[f'{col}_clean'] = (\n",
    "        bbe_clean[col]\n",
    "        .astype(str)\n",
    "        .replace({'nan': np.nan, '': np.nan})\n",
    "        .apply(clean_date_string)\n",
    "        .apply(parse_mixed_date)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0493da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>publication_date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>To Dream the Blackbane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>Betrayal In Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Books to Read When the Snow Is Falling\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Stepping Beyond Intention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>The Fyfield Plantation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>Angles - Part I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>لوحات ناجي العلي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>Mayfair Witches Collection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Horror Novels\\n\\n1,773 books — 5,396 vote...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>Night That Jimi Died</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50 Books That Changed Me\\n\\n319 books — 259 vo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>الشيخ زعرب وآخرون</td>\n",
       "      <td>NaN</td>\n",
       "      <td>أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11231</th>\n",
       "      <td>World Peace: The Voice of a Mountain Bird</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 9th 214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title firstPublishDate  \\\n",
       "2271                      To Dream the Blackbane              NaN   \n",
       "2989                           Betrayal In Black              NaN   \n",
       "3138                   Stepping Beyond Intention              NaN   \n",
       "3160                      The Fyfield Plantation              NaN   \n",
       "4359                             Angles - Part I              NaN   \n",
       "4508                            لوحات ناجي العلي              NaN   \n",
       "7869                  Mayfair Witches Collection              NaN   \n",
       "8409                        Night That Jimi Died              NaN   \n",
       "9054                           الشيخ زعرب وآخرون              NaN   \n",
       "11231  World Peace: The Voice of a Mountain Bird              NaN   \n",
       "\n",
       "                                             publishDate  \\\n",
       "2271                                           Published   \n",
       "2989   Best Books to Read When the Snow Is Falling\\n\\...   \n",
       "3138                                                 NaN   \n",
       "3160                                                 NaN   \n",
       "4359                                                 NaN   \n",
       "4508   في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...   \n",
       "7869   Best Horror Novels\\n\\n1,773 books — 5,396 vote...   \n",
       "8409   50 Books That Changed Me\\n\\n319 books — 259 vo...   \n",
       "9054   أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...   \n",
       "11231                                  September 9th 214   \n",
       "\n",
       "      publication_date_clean  \n",
       "2271                     NaN  \n",
       "2989                     NaN  \n",
       "3138                     NaN  \n",
       "3160                     NaN  \n",
       "4359                     NaN  \n",
       "4508                     NaN  \n",
       "7869                     NaN  \n",
       "8409                     NaN  \n",
       "9054                     NaN  \n",
       "11231                    NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine using your logic: prefer firstPublishDate, else publishDate\n",
    "bbe_clean['publication_date_clean'] = (\n",
    "    bbe_clean['firstPublishDate_clean'].combine_first(bbe_clean['publishDate_clean'])\n",
    ")\n",
    "# Reconvert to datetime safely before using .dt\n",
    "bbe_clean['publication_date_clean'] = pd.to_datetime(bbe_clean['publication_date_clean'], errors='coerce')\n",
    "\n",
    "# Format as ISO standard\n",
    "bbe_clean['publication_date_clean'] = bbe_clean['publication_date_clean'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Check a sample of remaining nulls\n",
    "bbe_clean[bbe_clean['publication_date_clean'].isna()][['title', 'firstPublishDate', 'publishDate', 'publication_date_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8186db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing publication dates: 588 of 52478 (1.12%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>publication_date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>To Dream the Blackbane</td>\n",
       "      <td>Richard J. O'Brien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>Betrayal In Black</td>\n",
       "      <td>Mark M. Bello (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Books to Read When the Snow Is Falling\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Stepping Beyond Intention</td>\n",
       "      <td>Daniel Mangena (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>The Fyfield Plantation</td>\n",
       "      <td>Andrew R. Williams (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>Angles - Part I</td>\n",
       "      <td>Erin Lockwood (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>لوحات ناجي العلي</td>\n",
       "      <td>ناجي العلي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>Mayfair Witches Collection</td>\n",
       "      <td>Anne Rice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Horror Novels\\n\\n1,773 books — 5,396 vote...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>Night That Jimi Died</td>\n",
       "      <td>Darragh J Brady</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50 Books That Changed Me\\n\\n319 books — 259 vo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>الشيخ زعرب وآخرون</td>\n",
       "      <td>يوسف السباعي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11231</th>\n",
       "      <td>World Peace: The Voice of a Mountain Bird</td>\n",
       "      <td>Amit Ray, Banani Ray (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 9th 214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "2271                      To Dream the Blackbane   \n",
       "2989                           Betrayal In Black   \n",
       "3138                   Stepping Beyond Intention   \n",
       "3160                      The Fyfield Plantation   \n",
       "4359                             Angles - Part I   \n",
       "4508                            لوحات ناجي العلي   \n",
       "7869                  Mayfair Witches Collection   \n",
       "8409                        Night That Jimi Died   \n",
       "9054                           الشيخ زعرب وآخرون   \n",
       "11231  World Peace: The Voice of a Mountain Bird   \n",
       "\n",
       "                                        author firstPublishDate  \\\n",
       "2271                        Richard J. O'Brien              NaN   \n",
       "2989          Mark M. Bello (Goodreads Author)              NaN   \n",
       "3138         Daniel Mangena (Goodreads Author)              NaN   \n",
       "3160     Andrew R. Williams (Goodreads Author)              NaN   \n",
       "4359          Erin Lockwood (Goodreads Author)              NaN   \n",
       "4508                                ناجي العلي              NaN   \n",
       "7869                                 Anne Rice              NaN   \n",
       "8409                           Darragh J Brady              NaN   \n",
       "9054                              يوسف السباعي              NaN   \n",
       "11231  Amit Ray, Banani Ray (Goodreads Author)              NaN   \n",
       "\n",
       "                                             publishDate  \\\n",
       "2271                                           Published   \n",
       "2989   Best Books to Read When the Snow Is Falling\\n\\...   \n",
       "3138                                                 NaN   \n",
       "3160                                                 NaN   \n",
       "4359                                                 NaN   \n",
       "4508   في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...   \n",
       "7869   Best Horror Novels\\n\\n1,773 books — 5,396 vote...   \n",
       "8409   50 Books That Changed Me\\n\\n319 books — 259 vo...   \n",
       "9054   أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...   \n",
       "11231                                  September 9th 214   \n",
       "\n",
       "      publication_date_clean  \n",
       "2271                     NaN  \n",
       "2989                     NaN  \n",
       "3138                     NaN  \n",
       "3160                     NaN  \n",
       "4359                     NaN  \n",
       "4508                     NaN  \n",
       "7869                     NaN  \n",
       "8409                     NaN  \n",
       "9054                     NaN  \n",
       "11231                    NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where the unified publication date is missing\n",
    "total = len(bbe_clean)\n",
    "bbe_missing_dates = bbe_clean.loc[bbe_clean['publication_date_clean'].isna()]\n",
    "missing_count = len(bbe_missing_dates)\n",
    "\n",
    "print(f\"Missing publication dates: {missing_count} of {total} ({missing_count/total:.2%})\")\n",
    "\n",
    "# Preview key columns\n",
    "bbe_missing_dates[['title', 'author', 'firstPublishDate', 'publishDate', 'publication_date_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ad7b40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim dates datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 3\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim dates datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f7a9c",
   "metadata": {},
   "source": [
    "**Publisher**\n",
    "\n",
    "Publisher names can vary significantly in formatting, including differences in capitalization, punctuation, and spacing. To standardize the `publisher` column, we will convert all entries to lowercase and strip any leading or trailing whitespace. This will help reduce variability and improve consistency across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e8f538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample publishers:\n",
      "['Igniter' 'Grace Press' 'A New Reality Publishing' 'Geração Editorial'\n",
      " 'Linear B Editora' 'Addison-Wesley' 'Penguin Group(CA)'\n",
      " 'Northern Lights ATP' 'Random House Vintage' 'World Castle Publishing'\n",
      " 'Monica Schaumann' 'Weber Books' 'Editori Riuniti' 'Jugoslavija'\n",
      " 'Laurann Dohner' 'Pendo' 'Gardners Books' '47North' 'منشورات القاسمي'\n",
      " 'Elle Casey' 'Dial Press Trade Paperback' 'Atheneum Books'\n",
      " 'Quinta Essência' 'Chatter Creek Publishing' 'Sparkplug Books'\n",
      " 'Wahlström & Widstrand' 'HarperCollins Canada' 'Backwoods'\n",
      " 'DMP / Dark Horse' 'La línea del horizonte']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample publishers:\")\n",
    "print(bbe_clean['publisher'].drop_duplicates().sample(30, random_state=42).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd2d0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Strip, lowercase, remove extra spaces and punctuation\n",
    "bbe_clean['publisher'] = (\n",
    "    bbe_clean['publisher']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace('\"', '', regex=False)\n",
    "    .str.replace(\"'\", '', regex=False)\n",
    "    .str.replace(r'[.,]', '', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e51a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique publisher values: 10741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique publisher values \n",
    "bbe_clean['publisher'] = bbe_clean['publisher'].astype(str).str.strip() \n",
    "unique_publisher = bbe_clean['publisher'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique publisher values: {len(unique_publisher)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "491b1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize numeric publishers names:\n",
    "def clean_numeric_publishers(x):\n",
    "    if re.match(r'^\\d+$', x.strip()):\n",
    "        return 'unknown'\n",
    "    return x\n",
    "\n",
    "bbe_clean['publisher'] = bbe_clean['publisher'].apply(clean_numeric_publishers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34928226",
   "metadata": {},
   "source": [
    "This cleaning step reduced the number of unique publisher names from **11,111 to 10,764**.\n",
    "Since **English-language books represent 81% of the catalogue**, the analysis will focus on this segment.\n",
    "We will **standardize major English-language publishing groups**, consolidating their **imprints and subsidiaries**, and apply **fuzzy matching** to unify names with **minor variations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "842f3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load publishers dictionary\n",
    "with open(\"src/cleaning/mappings/publishers_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    publishers_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83945720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Get top 10000 most common publishers\n",
    "top_n = 10000\n",
    "publisher_counts = bbe_clean['publisher'].value_counts()\n",
    "top_publishers = publisher_counts.head(top_n).index.tolist()\n",
    "\n",
    "# Create a mapping for top publishers only\n",
    "standardization_map = {}\n",
    "processed = set()\n",
    "\n",
    "for pub in top_publishers:\n",
    "    if pub in processed:\n",
    "        continue\n",
    "    \n",
    "    # Find similar publishers in the top list\n",
    "    matches = process.extract(pub, top_publishers, scorer=fuzz.ratio, limit=5)\n",
    "    \n",
    "    # Group similar ones (score > 90)\n",
    "    similar = [m[0] for m in matches if m[1] > 90]\n",
    "    canonical = similar[0]  # Use first as canonical\n",
    "    \n",
    "    for similar_pub in similar:\n",
    "        standardization_map[similar_pub] = canonical\n",
    "        processed.add(similar_pub)\n",
    "\n",
    "# Apply the mapping\n",
    "bbe_clean['publisher_standardized'] = bbe_clean['publisher'].replace(standardization_map)\n",
    "\n",
    "# Then apply manual mapping\n",
    "bbe_clean['publisher_standardized'] = bbe_clean['publisher_standardized'].replace(publishers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1c7a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique publisher values: 9993\n",
      "\n",
      "Sample publishers:\n",
      "['polirom' 'central avenue publishing' 'siglo xxi ediciones'\n",
      " 'oxford university press' 'harvard business review press'\n",
      " 'دار البشائر الاسلامية' 'pedro sajini publishing'\n",
      " 'nantier beall minoustchine publishing' 'flux' 'dark blade publishing'\n",
      " 'm evans and company' 'granta uk' 'tutku yayınevi' 'دار الفكر المعاصر'\n",
      " 'replica books' 'mayandree michel' 'obuolys' 'dva' 'audiogo ltd'\n",
      " 'willow lane publishing' 'zeppelin publishing company' 'lulu press'\n",
      " 'cavalier press' 'النور للإنتاج الإعلامى والتوزيع' 'endeavour compass'\n",
      " 'feiwel & friends' 'charming gal publications' 'diamond pocket books'\n",
      " 'j s sanders and company' 'el leon literary arts']\n"
     ]
    }
   ],
   "source": [
    "standardized_unique_publisher = bbe_clean['publisher_standardized'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique publisher values: {len(standardized_unique_publisher)}\\n\") \n",
    "\n",
    "print(\"Sample publishers:\")\n",
    "print(bbe_clean['publisher_standardized'].drop_duplicates().sample(30, random_state=42).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ec14d",
   "metadata": {},
   "source": [
    "The cleaning process reduced the number of unique publisher names from **11,111 to 9993**, representing a **10% decrease**.\n",
    "Given that the dataset includes books in multiple languages and many small or independent publishers, this reduction is a **satisfactory outcome**.\n",
    "\n",
    "To further evaluate the effectiveness of the cleaning, we will analyze the **proportion of titles associated with the most common publishers**.\n",
    "This will help us assess how well the standardization process **consolidated the publisher catalog** and captured the main publishing groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5b78810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books from mapped major publishers: 9301 of 52478 (17.72%)\n"
     ]
    }
   ],
   "source": [
    "# Define your core publisher groups\n",
    "major_publishers = [\n",
    "    'penguin random house', 'harpercollins', 'macmillan',\n",
    "    'simon & schuster', 'hachette', 'bloomsbury',\n",
    "    'amazon publishing', 'scholastic'\n",
    "]\n",
    "\n",
    "# Create a flag\n",
    "bbe_clean['is_major_publisher'] = bbe_clean['publisher_standardized'].isin(major_publishers)\n",
    "\n",
    "# Count results\n",
    "total_books = len(bbe_clean)\n",
    "major_books = bbe_clean['is_major_publisher'].sum()\n",
    "share_major = major_books / total_books * 100\n",
    "\n",
    "print(f\"Books from mapped major publishers: {major_books} of {total_books} ({share_major:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0672c79",
   "metadata": {},
   "source": [
    "About 17% of all titles now belong to one of the standardized major publisher groups.\n",
    "The remaining publishers represent independent, regional, or self-published works.\n",
    "Further improvements (e.g., mapping academic and international publishers) could expand this coverage to 25–30%. But we'll leave it as is for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8014be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim publisher datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 4\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim publisher datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd851a",
   "metadata": {},
   "source": [
    "**Book Format**\n",
    "\n",
    "This step standardizes the `bookFormat` field across multiple languages and inconsistent label variations found in the dataset.  \n",
    "The goal is to translate all format names into English and consolidate equivalent values (e.g., *“Capa dura”*, *“Gebundene Ausgabe”*, *“Hard back”*) under unified categories such as **Hardcover**, **Paperback**, **Ebook**, and **Audiobook**.\n",
    "\n",
    "This cleaning ensures that:\n",
    "- Format values are consistent for analysis and visualization.  \n",
    "- Non-English or rare variants are translated and grouped appropriately.  \n",
    "- Missing or unrecognized entries are handled under a neutral category: **Other / Unknown**.  \n",
    "\n",
    "By applying a mapping dictionary, we make the variable suitable for aggregation, comparison, and predictive modeling. After transformation, we verify the result by inspecting the number of unique standardized values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67bfcd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique book format values: 135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique format values \n",
    "bbe_clean['bookFormat'] = bbe_clean['bookFormat'].astype(str).str.strip() \n",
    "unique_format = bbe_clean['bookFormat'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique book format values: {len(unique_format)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0953a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hardcover' 'Paperback' 'Mass Market Paperback' 'Kindle Edition'\n",
      " 'Audiobook' 'ebook' 'nan' 'Board book' 'Boxed Set' 'Leather Bound'\n",
      " 'Capa dura' 'Trade Paperback' 'Box Set' 'Board Book' 'Nook'\n",
      " 'Library Binding' 'Capa comum' 'Pasta blanda' 'Audio Cassette'\n",
      " 'Unknown Binding' 'Audio CD' 'Slipcased Hardcover' 'Broschiert'\n",
      " 'Brochura' 'MP3 CD' 'Audible Audio' 'hardcover' 'cloth' 'Pasta dura'\n",
      " 'Paperback/Kindle' 'paper' 'Hard Cover' 'Perfect Paperback' 'Poche'\n",
      " 'Comics' 'Hardcover Slipcased' 'Unbound' 'Taschenbuch' 'Paper back'\n",
      " 'Paperback, Kindle, Ebook, Audio' 'CD-ROM' 'Paperback and Kindle'\n",
      " 'Hardcover im Schuber' 'paperback' 'Graphic Novels' 'Broché'\n",
      " 'Science Fiction Book Club Omnibus' 'Newsprint' 'Spiral-bound'\n",
      " 'Mass Market' 'Hardcover Boxed Set' 'Hardback' 'Audio' 'Novel'\n",
      " 'Gebundene Ausgabe' 'softcover' 'گالینگور-وزیری' 'hardbound'\n",
      " 'Hard cover, Soft cover, e-book' 'Kindle' 'Paperback/Ebook'\n",
      " 'Online Fiction' 'Interactive ebook' 'Paperback mit Klappen'\n",
      " 'eBook Kindle' 'ebook and paperback' 'Webnovel' 'Wattpad'\n",
      " 'online fiction' 'Bonded Leather' 'paper book' 'Paperback, eBook'\n",
      " 'Box-Set' 'capa mole' 'Rústica' 'Bìa mềm' 'School & Library Binding'\n",
      " 'Klappenbroschur' '文庫' 'Fiction' 'Trade Paper'\n",
      " 'Capa mole - 15,5 x 23 x 2cm' 'Trade paperback'\n",
      " 'Bolsillo con sobrecubierta' '軟精裝' 'Audio Play' 'コミック' 'Digital Comic'\n",
      " 'Hardcover, Paper Dust Jacket' 'revised edition' 'mass_market' 'islamy'\n",
      " 'Webtoon' 'Softcover' 'Hardcover Chapbook' 'text' 'Album' 'webtoon'\n",
      " 'hardback' 'Capa Mole' 'Comic' 'Pocket' 'PDF' 'Newsletter Serial' 'web'\n",
      " 'Capa mole' 'kindle_edition' 'Softcover, free ebook' 'Innbundet' 'Diary'\n",
      " 'Kovakantinen' 'Online' 'Book Set' 'Digital' 'Online Fiction - Complete'\n",
      " '単行本' 'Board' \"author's website\" 'Paper Back' 'Pamphlet' 'Big Book'\n",
      " 'Audio Book' 'Paperback (عربي-English)' 'audio cassette' 'Novelty Book'\n",
      " 'Other Format' 'Podiobook' 'Tankobon Hardcover' 'Turtleback' 'Audio Cd'\n",
      " 'Casebound' 'audiobook' 'Bantam New Fiction' 'Gebunden' 'pamphlet']\n"
     ]
    }
   ],
   "source": [
    "print(unique_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee67f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load format dictionary\n",
    "with open(\"src/cleaning/mappings/format_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    format_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "631890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['bookFormat_clean'] = (\n",
    "    bbe_clean['bookFormat']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .replace(format_dict)\n",
    ")\n",
    "\n",
    "# Replace remaining unknowns or NaN with a unified label\n",
    "bbe_clean['bookFormat_clean'] = bbe_clean['bookFormat_clean'].replace(['nan', 'none', ''], np.nan)\n",
    "bbe_clean['bookFormat_clean'] = bbe_clean['bookFormat_clean'].fillna('Other / Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2c61a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique book format values: 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_format_clean = bbe_clean['bookFormat_clean'].unique() \n",
    "\n",
    "print(f\"\\nTotal unique book format values: {len(unique_format_clean)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3adabd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hardcover', 'Paperback', 'Ebook', 'Audiobook', 'Other / Unknown',\n",
       "       'Board Book', 'Boxed Set', 'Leather Bound', 'Library Binding',\n",
       "       'Comics / Graphic Novel', \"author's website\"], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_format_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20ee3b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim format datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 5\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim format datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a412a95",
   "metadata": {},
   "source": [
    "After applying the standardization mapping, the number of unique book format values was reduced from **135** to **10**.  This represents a substantial improvement in data consistency and interpretability.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b535cfd",
   "metadata": {},
   "source": [
    "**ISBN and ASIN Cleaning**\n",
    "\n",
    "The BBE dataset includes a single `isbn` column, which initially contained numerous missing or invalid entries (e.g. placeholder values such as `9999999999999`).\n",
    "\n",
    "Our initial cleaning flow focused solely on standardizing **ISBN** values, but upon further inspection, we identified additional patterns such as **Amazon ASINs** (10-character alphanumeric codes) and prefixed identifiers like `10:` or `13:`.\n",
    "\n",
    "These findings led to an adjustment to the cleaning logic and the order of operations in the pipeline.\n",
    "\n",
    "The final cleaning process:\n",
    "\n",
    "- Removes punctuation and non-digit characters to standardize ISBN formatting.\n",
    "- Detects and separates ASINs (`asin` column) to preserve them for potential cross-dataset enrichment.\n",
    "- Handles prefixed identifiers (e.g., `13:9780615700`) by removing prefixes before validation.\n",
    "- Filters out placeholder or invalid entries (`999…`, `000…`) and ensures consistent string representation.\n",
    "- Creates a new `isbn_clean` column containing only valid ISBN-10 or ISBN-13 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36afe4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>isbn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>9780439023481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>9780439358071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>9999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>9999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>9780316015844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>9780375831003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>9780451526342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Chronicles of Narnia</td>\n",
       "      <td>9999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>9780345538376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>9780446675536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           isbn\n",
       "0                                   The Hunger Games  9780439023481\n",
       "1          Harry Potter and the Order of the Phoenix  9780439358071\n",
       "2                              To Kill a Mockingbird  9999999999999\n",
       "3                                Pride and Prejudice  9999999999999\n",
       "4                                           Twilight  9780316015844\n",
       "5                                     The Book Thief  9780375831003\n",
       "6                                        Animal Farm  9780451526342\n",
       "7                           The Chronicles of Narnia  9999999999999\n",
       "8  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...  9780345538376\n",
       "9                                 Gone with the Wind  9780446675536"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect ISBN column\n",
    "bbe_clean[['title','isbn']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d757133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing ISBN entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Check missing and invalid patterns\n",
    "n_missing_isbn = bbe_clean['isbn'].isna().sum()\n",
    "print(f'Number of missing ISBN entries: {n_missing_isbn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "950d17e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of placeholder ISBN entries: 4354\n"
     ]
    }
   ],
   "source": [
    "# Identify invalid placeholders (like 9999999999999)\n",
    "n_invalid_isbn = bbe_clean[bbe_clean['isbn'].astype(str).str.contains('9999999999')].shape[0]\n",
    "print(f'Number of placeholder ISBN entries: {n_invalid_isbn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a71ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_asin(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x).strip()\n",
    "    if re.fullmatch(r'[A-Z0-9]{10}', x) and not x.isdigit():  # must have at least one letter\n",
    "        return x\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd6e2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with ASINs: 4692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>isbn</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fahrenheit 451</td>\n",
       "      <td>B0064CPN7I</td>\n",
       "      <td>B0064CPN7I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Lolita</td>\n",
       "      <td>B00IIAQY3Q</td>\n",
       "      <td>B00IIAQY3Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1984</td>\n",
       "      <td>B003JTHWKU</td>\n",
       "      <td>B003JTHWKU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Notebook</td>\n",
       "      <td>B000Q67J66</td>\n",
       "      <td>B000Q67J66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>The Mists of Avalon</td>\n",
       "      <td>B000FC1JCQ</td>\n",
       "      <td>B000FC1JCQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Bridge to Terabithia</td>\n",
       "      <td>B001UFP6JY</td>\n",
       "      <td>B001UFP6JY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>The Clan of the Cave Bear</td>\n",
       "      <td>B00466HQ2Y</td>\n",
       "      <td>B00466HQ2Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>B007UH4D3G</td>\n",
       "      <td>B007UH4D3G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>The Screwtape Letters</td>\n",
       "      <td>B002BD2V2Y</td>\n",
       "      <td>B002BD2V2Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Blindness</td>\n",
       "      <td>B003T0GBOM</td>\n",
       "      <td>B003T0GBOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title        isbn        asin\n",
       "20              Fahrenheit 451  B0064CPN7I  B0064CPN7I\n",
       "56                      Lolita  B00IIAQY3Q  B00IIAQY3Q\n",
       "80                        1984  B003JTHWKU  B003JTHWKU\n",
       "95                The Notebook  B000Q67J66  B000Q67J66\n",
       "174        The Mists of Avalon  B000FC1JCQ  B000FC1JCQ\n",
       "183       Bridge to Terabithia  B001UFP6JY  B001UFP6JY\n",
       "193  The Clan of the Cave Bear  B00466HQ2Y  B00466HQ2Y\n",
       "209              Jurassic Park  B007UH4D3G  B007UH4D3G\n",
       "231      The Screwtape Letters  B002BD2V2Y  B002BD2V2Y\n",
       "247                  Blindness  B003T0GBOM  B003T0GBOM"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe_clean['asin'] = bbe_clean['isbn'].apply(detect_asin)\n",
    "has_asin = bbe_clean[bbe_clean['asin'].notna()] \n",
    "print(f'Books with ASINs: {len(has_asin)}')\n",
    "has_asin[['title','isbn', 'asin']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fabfea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_isbn(x):\n",
    "    # handle missing\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "\n",
    "    # detect ASIN first\n",
    "    asin_val = detect_asin(x)\n",
    "    if pd.notna(asin_val):\n",
    "        # return NaN for ISBN cleaning, because it's an ASIN\n",
    "        return np.nan  \n",
    "\n",
    "    # clean numeric ISBNs\n",
    "    s = str(x).strip()\n",
    "    s = re.sub(r'^(10:|13:)', '', s)       # remove leading prefixes\n",
    "    s = re.sub(r'\\D', '', s)               # keep only digits\n",
    "\n",
    "    # handle placeholders\n",
    "    if re.fullmatch(r'(9{10}|9{13}|0{10}|0{13})', s):\n",
    "        return np.nan\n",
    "\n",
    "    # keep valid ISBN-10 or ISBN-13\n",
    "    if len(s) in [10, 13]:\n",
    "        return s\n",
    "\n",
    "    return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cffc1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['isbn_clean'] = bbe_clean['isbn'].apply(clean_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10b056cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>9780439023481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>9780439358071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>9780316015844</td>\n",
       "      <td>9780316015844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>9780375831003</td>\n",
       "      <td>9780375831003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>9780451526342</td>\n",
       "      <td>9780451526342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Chronicles of Narnia</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>9780345538376</td>\n",
       "      <td>9780345538376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>9780446675536</td>\n",
       "      <td>9780446675536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           isbn  \\\n",
       "0                                   The Hunger Games  9780439023481   \n",
       "1          Harry Potter and the Order of the Phoenix  9780439358071   \n",
       "2                              To Kill a Mockingbird  9999999999999   \n",
       "3                                Pride and Prejudice  9999999999999   \n",
       "4                                           Twilight  9780316015844   \n",
       "5                                     The Book Thief  9780375831003   \n",
       "6                                        Animal Farm  9780451526342   \n",
       "7                           The Chronicles of Narnia  9999999999999   \n",
       "8  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...  9780345538376   \n",
       "9                                 Gone with the Wind  9780446675536   \n",
       "\n",
       "      isbn_clean  \n",
       "0  9780439023481  \n",
       "1  9780439358071  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4  9780316015844  \n",
       "5  9780375831003  \n",
       "6  9780451526342  \n",
       "7            NaN  \n",
       "8  9780345538376  \n",
       "9  9780446675536  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect ISBN columns after cleaning\n",
    "bbe_clean[['title','isbn', 'isbn_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9baf8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining placeholder ISBNs: 0\n"
     ]
    }
   ],
   "source": [
    "placeholder_remaining = bbe_clean[bbe_clean['isbn_clean'].astype(str).str.fullmatch(r'(9{10}|9{13}|0{10}|0{13})', na=False)]\n",
    "print(f\"Remaining placeholder ISBNs: {len(placeholder_remaining)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ebb8275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing isbn_clean: 9078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>isbn</th>\n",
       "      <th>asin</th>\n",
       "      <th>isbn_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Chronicles of Narnia</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Hitchhiker's Guide to the Galaxy</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Da Vinci Code</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Picture of Dorian Gray</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Les Misérables</td>\n",
       "      <td>Mass Market Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fahrenheit 451</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>B0064CPN7I</td>\n",
       "      <td>B0064CPN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Perks of Being a Wallflower</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title             bookFormat  \\\n",
       "2                  To Kill a Mockingbird              Paperback   \n",
       "3                    Pride and Prejudice              Paperback   \n",
       "7               The Chronicles of Narnia              Paperback   \n",
       "10                The Fault in Our Stars              Hardcover   \n",
       "11  The Hitchhiker's Guide to the Galaxy              Paperback   \n",
       "14                     The Da Vinci Code              Paperback   \n",
       "16            The Picture of Dorian Gray              Paperback   \n",
       "19                        Les Misérables  Mass Market Paperback   \n",
       "20                        Fahrenheit 451         Kindle Edition   \n",
       "26       The Perks of Being a Wallflower              Paperback   \n",
       "\n",
       "             isbn        asin isbn_clean  \n",
       "2   9999999999999         NaN        NaN  \n",
       "3   9999999999999         NaN        NaN  \n",
       "7   9999999999999         NaN        NaN  \n",
       "10  9999999999999         NaN        NaN  \n",
       "11  9999999999999         NaN        NaN  \n",
       "14  9999999999999         NaN        NaN  \n",
       "16  9999999999999         NaN        NaN  \n",
       "19  9999999999999         NaN        NaN  \n",
       "20     B0064CPN7I  B0064CPN7I        NaN  \n",
       "26  9999999999999         NaN        NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the rows where isbn_clean is NaN\n",
    "missing_isbn_clean = bbe_clean[bbe_clean['isbn_clean'].isna()]\n",
    "\n",
    "# Print the number of missing and show the first few examples\n",
    "print(f\"Missing isbn_clean: {missing_isbn_clean.shape[0]}\")\n",
    "missing_isbn_clean[['title', 'bookFormat', 'isbn', 'asin','isbn_clean']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31f098",
   "metadata": {},
   "source": [
    "To inspect if there are other cases of invalid ISBNs, we will filter the rows where the `isbn_type` is either `'wrong_length'` or `'missing'`. This will help us identify any additional issues with the ISBN data that may need to be addressed. For that a custom function `isbn_type` was created to classify the reason for invalidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a13a49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isbn_type(x):\n",
    "    if pd.isna(x):\n",
    "        return 'missing'\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    # Detect ASIN (10-char alphanumeric, must have at least one letter)\n",
    "    if re.fullmatch(r'[A-Z0-9]{10}', s.upper()) and not s.isdigit():\n",
    "        return 'asin'\n",
    "\n",
    "    # Remove non-digits for numeric checks\n",
    "    x = re.sub(r'\\D', '', s)\n",
    "\n",
    "    # Placeholder patterns\n",
    "    if re.fullmatch(r'9{10}|9{13}', x):\n",
    "        return 'placeholder_9'\n",
    "    if re.fullmatch(r'0{10}|0{13}', x):\n",
    "        return 'placeholder_0'\n",
    "\n",
    "    # Length checks\n",
    "    if len(x) in [10, 13]:\n",
    "        return 'valid'\n",
    "    if len(x) > 0:\n",
    "        return 'wrong_length'\n",
    "\n",
    "    return 'missing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbeec353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn_type\n",
       "valid            43397\n",
       "asin              4692\n",
       "placeholder_9     4354\n",
       "wrong_length        34\n",
       "missing              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe_clean['isbn_type'] = bbe_clean['isbn'].apply(isbn_type)\n",
    "bbe_clean['isbn_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfee82bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total invalid (wrong_length + missing): 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>isbn</th>\n",
       "      <th>asin</th>\n",
       "      <th>isbn_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>Ice in My Veins</td>\n",
       "      <td>Kelli Sullivan</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>978145208533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14276</th>\n",
       "      <td>Changing the Game</td>\n",
       "      <td>Jaci Burton</td>\n",
       "      <td>Trade Paperback</td>\n",
       "      <td>978042524240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16178</th>\n",
       "      <td>The Reluctant Vampire</td>\n",
       "      <td>Lynsay Sands</td>\n",
       "      <td>Mass Market Paperback</td>\n",
       "      <td>978006189459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16368</th>\n",
       "      <td>Awful Auntie</td>\n",
       "      <td>David Walliams</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>978000794445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>Clipped</td>\n",
       "      <td>Samantha Potts</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>978145633431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18506</th>\n",
       "      <td>The Gaze</td>\n",
       "      <td>Javier A. Robayo</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>978147505066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18697</th>\n",
       "      <td>The Vine Keeper . . . messages in Poetry and P...</td>\n",
       "      <td>William S. Peters Sr.</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>13:9780615700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19101</th>\n",
       "      <td>نهضة أمة</td>\n",
       "      <td>هشام مصطفى عبد العزيز</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>978977623807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19212</th>\n",
       "      <td>Venom</td>\n",
       "      <td>Fiona Paul</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>978039925725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>Scarback: There Is So Much More to Fishing Tha...</td>\n",
       "      <td>Roger Corea</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>10:1496102266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wrong_length</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "3670                                     Ice in My Veins   \n",
       "14276                                  Changing the Game   \n",
       "16178                              The Reluctant Vampire   \n",
       "16368                                       Awful Auntie   \n",
       "18081                                            Clipped   \n",
       "18506                                           The Gaze   \n",
       "18697  The Vine Keeper . . . messages in Poetry and P...   \n",
       "19101                                           نهضة أمة   \n",
       "19212                                              Venom   \n",
       "19304  Scarback: There Is So Much More to Fishing Tha...   \n",
       "\n",
       "                author_clean             bookFormat           isbn asin  \\\n",
       "3670          Kelli Sullivan              Paperback   978145208533  NaN   \n",
       "14276            Jaci Burton        Trade Paperback   978042524240  NaN   \n",
       "16178           Lynsay Sands  Mass Market Paperback   978006189459  NaN   \n",
       "16368         David Walliams              Hardcover   978000794445  NaN   \n",
       "18081         Samantha Potts              Paperback   978145633431  NaN   \n",
       "18506       Javier A. Robayo         Kindle Edition   978147505066  NaN   \n",
       "18697  William S. Peters Sr.              Paperback  13:9780615700  NaN   \n",
       "19101  هشام مصطفى عبد العزيز              Paperback   978977623807  NaN   \n",
       "19212             Fiona Paul              Hardcover   978039925725  NaN   \n",
       "19304            Roger Corea              Paperback  10:1496102266  NaN   \n",
       "\n",
       "          isbn_type  \n",
       "3670   wrong_length  \n",
       "14276  wrong_length  \n",
       "16178  wrong_length  \n",
       "16368  wrong_length  \n",
       "18081  wrong_length  \n",
       "18506  wrong_length  \n",
       "18697  wrong_length  \n",
       "19101  wrong_length  \n",
       "19212  wrong_length  \n",
       "19304  wrong_length  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with type either 'wrong_length' or 'missing'\n",
    "invalid_isbn = bbe_clean[bbe_clean['isbn_type'].isin(['wrong_length', 'missing'])]\n",
    "\n",
    "# Show total count\n",
    "print(f\"Total invalid (wrong_length + missing): {invalid_isbn.shape[0]}\")\n",
    "\n",
    "# Preview relevant columns\n",
    "invalid_isbn[['title', 'author_clean', 'bookFormat', 'isbn', 'asin', 'isbn_type']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676aef5e",
   "metadata": {},
   "source": [
    "Out of all records, **9,081 entries (≈18%)** were identified as invalid ISBNs, leaving roughly **82%** valid.\n",
    "Only **34** cases were tagged as `'wrong_length'` and **1** as `'missing'`.\n",
    "These mostly represent truncated or prefixed identifiers, while the `isbn_type` function accurately distinguished valid ISBNs, ASINs, and placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54b9bba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim ISBN/ASIN datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 6\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim ISBN/ASIN datasets saved successfully in data/interim/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e35f4",
   "metadata": {},
   "source": [
    "**Ratings**\n",
    "\n",
    "In this step, we evaluate the quality and consistency of the `rating` field.\n",
    "We first check for missing or invalid values and calculate the percentage of available ratings to assess data completeness. Then, we use the `describe()` method to verify whether the ratings follow the expected 1–5 scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7651de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with ratings: 52478 of 52478 (100.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>4.26</td>\n",
       "      <td>2998241</td>\n",
       "      <td>['1617567', '816659', '373311', '113934', '767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4964519</td>\n",
       "      <td>['1751460', '1113682', '1008686', '542017', '5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1834276</td>\n",
       "      <td>['1048230', '524674', '186297', '48864', '26211']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2740713</td>\n",
       "      <td>['986764', '958699', '545475', '165093', '84682']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Chronicles of Narnia</td>\n",
       "      <td>4.26</td>\n",
       "      <td>517740</td>\n",
       "      <td>['254964', '167572', '74362', '15423', '5419']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>110146</td>\n",
       "      <td>['78217', '22857', '6628', '1477', '967']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1074620</td>\n",
       "      <td>['602138', '275517', '133535', '39008', '24422']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  rating  numRatings  \\\n",
       "0                                   The Hunger Games    4.33     6376780   \n",
       "1          Harry Potter and the Order of the Phoenix    4.50     2507623   \n",
       "2                              To Kill a Mockingbird    4.28     4501075   \n",
       "3                                Pride and Prejudice    4.26     2998241   \n",
       "4                                           Twilight    3.60     4964519   \n",
       "5                                     The Book Thief    4.37     1834276   \n",
       "6                                        Animal Farm    3.95     2740713   \n",
       "7                           The Chronicles of Narnia    4.26      517740   \n",
       "8  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...    4.60      110146   \n",
       "9                                 Gone with the Wind    4.30     1074620   \n",
       "\n",
       "                                      ratingsByStars  \n",
       "0  ['3444695', '1921313', '745221', '171994', '93...  \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']  \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...  \n",
       "3  ['1617567', '816659', '373311', '113934', '767...  \n",
       "4  ['1751460', '1113682', '1008686', '542017', '5...  \n",
       "5  ['1048230', '524674', '186297', '48864', '26211']  \n",
       "6  ['986764', '958699', '545475', '165093', '84682']  \n",
       "7     ['254964', '167572', '74362', '15423', '5419']  \n",
       "8          ['78217', '22857', '6628', '1477', '967']  \n",
       "9   ['602138', '275517', '133535', '39008', '24422']  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the rows where rating is not NaN\n",
    "total_books = len(bbe_clean)\n",
    "has_ratings = bbe_clean[bbe_clean['rating'].notna()]\n",
    "has_ratings_num = has_ratings.shape[0]\n",
    "share_ratings = has_ratings_num / total_books * 100\n",
    "\n",
    "# Print the number of titles with ratings and show the first few examples\n",
    "print(f\"Books with ratings: {has_ratings_num} of {total_books} ({share_ratings:.2f}%)\")\n",
    "has_ratings[['title', 'rating', 'numRatings','ratingsByStars']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ac5fe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    52478.000000\n",
       "mean         4.021878\n",
       "std          0.367146\n",
       "min          0.000000\n",
       "25%          3.820000\n",
       "50%          4.030000\n",
       "75%          4.230000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe_clean['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a79952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33, 4.5 , 4.28, 4.26, 3.6 , 4.37, 3.95, 4.6 , 4.3 , 4.21, 4.22,\n",
       "       3.86, 4.12, 4.08, 4.06, 4.13, 4.18, 3.99, 4.19, 3.69])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe_clean['rating'].unique()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff8e3",
   "metadata": {},
   "source": [
    "The inspection confirms that the dataset is generally clean; however, a small number of entries have a value of `0`, which represents missing evaluations. These will be replaced with `NaN` to ensure the ratings remain within the valid range (1–5). Since all valid values already follow the standard Goodreads scale, no normalization is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99f90c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items with value equal 0: 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>rating</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>Her Beauty</td>\n",
       "      <td>M.R. Desmond</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17834</th>\n",
       "      <td>Mach Deine Träume Wahrverwirkliche Deine Ziele...</td>\n",
       "      <td>Roeland Suylen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>Mindtronics! And Inquiry Alive!</td>\n",
       "      <td>William C. Bruce</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18197</th>\n",
       "      <td>Moon Secrets</td>\n",
       "      <td>J.J. Gregory</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18618</th>\n",
       "      <td>Aphrodisiac Concupiscence Deluxe</td>\n",
       "      <td>Yolanda Williams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      author_clean  \\\n",
       "8321                                          Her Beauty      M.R. Desmond   \n",
       "17834  Mach Deine Träume Wahrverwirkliche Deine Ziele...    Roeland Suylen   \n",
       "17907                    Mindtronics! And Inquiry Alive!  William C. Bruce   \n",
       "18197                                       Moon Secrets      J.J. Gregory   \n",
       "18618                   Aphrodisiac Concupiscence Deluxe  Yolanda Williams   \n",
       "\n",
       "       rating  numRatings ratingsByStars  \n",
       "8321      0.0           0             []  \n",
       "17834     0.0           0             []  \n",
       "17907     0.0           0             []  \n",
       "18197     0.0           0             []  \n",
       "18618     0.0           0             []  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (bbe_clean['rating'] == 0)\n",
    "print(f'Items with value equal 0: {bbe_clean[mask].shape[0]}')\n",
    "bbe_clean[mask][['title', 'author_clean','rating','numRatings','ratingsByStars']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "968c1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_clean['rating_clean'] = bbe_clean['rating'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "332efe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    52407.000000\n",
       "mean         4.027327\n",
       "std          0.336206\n",
       "min          1.000000\n",
       "25%          3.820000\n",
       "50%          4.030000\n",
       "75%          4.230000\n",
       "max          5.000000\n",
       "Name: rating_clean, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe_clean['rating_clean'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "224fd29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim ratings datasets saved successfully in data/interim/ directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "version = 7\n",
    "\n",
    "interim_bbe_path = Path(\"data/interim/bbe\")\n",
    "\n",
    "bbe_clean.to_csv(interim_bbe_path / f\"bbe_clean_v{version}.csv\", index=False)\n",
    "\n",
    "print(\"Interim ratings datasets saved successfully in data/interim/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
