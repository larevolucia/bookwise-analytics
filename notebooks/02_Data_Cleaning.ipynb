{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fc4fb3",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The purpose of this notebook is to **clean, standardize, and prepare the collected datasets** for subsequent exploratory analysis and modeling tasks.\n",
    "\n",
    "The goal is to transform raw inputs from multiple book datasets into a **reliable, consistent, and mergeable analytical base**, ensuring data integrity and comparability across platforms.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "| Dataset                    | Source                     | Description                                                               | Format |\n",
    "| -------------------------- | -------------------------- | ------------------------------------------------------------------------- | ------ |\n",
    "| `bbe_books.csv`            | Zenodo – *Best Books Ever* | Book metadata including title, author, rating, genres, and description.   | CSV    |\n",
    "| `books.csv`, `ratings.csv` | GitHub – *Goodbooks-10k*   | Book metadata and user–book interaction data for recommendation modeling. | CSV    |\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks in This Notebook\n",
    "\n",
    "This notebook will execute the following cleaning and preparation steps:\n",
    "\n",
    "1. **Standardize column formats:**\n",
    "   Ensure consistent data types and naming conventions across datasets (e.g., convert `isbn` to string, align `author`, `rating`, and `title` formats).\n",
    "\n",
    "2. **Clean and normalize missing values:**\n",
    "   Replace placeholder NaNs (`9999999999999`, empty lists, or `\"None\"`) with `np.nan`, then impute or drop based on analytical importance.\n",
    "\n",
    "3. **Detect and resolve duplicates:**\n",
    "   Identify duplicate records using key identifiers (`bookId`, `isbn`, `title + author`) and retain the most complete or relevant entries.\n",
    "\n",
    "4. **Validate and align categorical values:**\n",
    "   Standardize genre labels, language codes, and rating scales to ensure comparability between datasets.\n",
    "\n",
    "5. **Merge compatible datasets:**\n",
    "   Integrate *BestBooksEver* and *Goodbooks-10k_books* into a unified schema while maintaining referential integrity with the ratings dataset.\n",
    "\n",
    "6. **Outlier and consistency checks:**\n",
    "   Review numerical and date fields (e.g., `pages`, `price`, `publishDate`) for unrealistic or extreme values and adjust as needed.\n",
    "\n",
    "7. **Feature enrichment (optional):**\n",
    "   Derive or enhance fields such as `popularity_score`, `recency`, or missing genre information using external APIs where beneficial.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* **Cleaned, schema-aligned datasets** ready for exploratory data analysis and modeling.\n",
    "* **Summary statistics** on completeness, duplicates, and outliers.\n",
    "* **Processed CSV files** saved for reproducibility in `data/processed/`.\n",
    "\n",
    "> **Note:** This notebook focuses on the *Data Cleaning and Preparation*. Further feature engineering and model-specific transformations will follow in later notebooks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383657df",
   "metadata": {},
   "source": [
    "## Navigate to the Parent Directory\n",
    "\n",
    "Before combining and saving datasets, it’s often helpful to move to a parent directory so that file operations (like loading or saving data) are easier and more organized. \n",
    "\n",
    "Before using the Python’s built-in os module to move one level up from the current working directory, it is advisable to inspect the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc6e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f3220",
   "metadata": {},
   "source": [
    "To change to parent directory (root folder), run the code below. If you are already in the root folder, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c41cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to parent.\n",
      "New current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to its parent\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Changed directory to parent.')\n",
    "\n",
    "# Get the new current working directory (the parent directory)\n",
    "current_dir = os.getcwd()\n",
    "print(f'New current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1120c",
   "metadata": {},
   "source": [
    "## Load and Inspect Books Datasets\n",
    "\n",
    "In this step, we load the previously collected datasets: **Goodbooks-10k** (books) and **Best Books Ever**. We will inspect their structure one more time before starting any merging or cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f7670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# load datasets\n",
    "books = pd.read_csv('data/raw/books.csv')\n",
    "bbe = pd.read_csv('data/raw/bbe_books.csv')\n",
    "\n",
    "# create copies for cleaning\n",
    "books_clean = books.copy()\n",
    "bbe_clean = bbe.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5230208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>isbn</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>...</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>bookId_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052-the-hunger-games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2993816</td>\n",
       "      <td>30516</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2767052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>4.50</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98.0</td>\n",
       "      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2632233</td>\n",
       "      <td>26923</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>['Maycomb, Alabama (United States)']</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2269402</td>\n",
       "      <td>23328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2657.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        bookId  \\\n",
       "0                     2767052-the-hunger-games   \n",
       "1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n",
       "2                   2657.To_Kill_a_Mockingbird   \n",
       "\n",
       "                                       title                 series  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "\n",
       "                                      author  rating  \\\n",
       "0                            Suzanne Collins    4.33   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)    4.50   \n",
       "2                                 Harper Lee    4.28   \n",
       "\n",
       "                                         description language           isbn  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...  English  9780439023481   \n",
       "1  There is a door at the end of a silent corrido...  English  9780439358071   \n",
       "2  The unforgettable novel of a childhood in a sl...  English  9999999999999   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n",
       "2  ['Classics', 'Fiction', 'Historical Fiction', ...   \n",
       "\n",
       "                                          characters  ...  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  ...   \n",
       "1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  ...   \n",
       "2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  ...   \n",
       "\n",
       "                                              awards numRatings  \\\n",
       "0  ['Locus Award Nominee for Best Young Adult Boo...    6376780   \n",
       "1  ['Bram Stoker Award for Works for Young Reader...    2507623   \n",
       "2  ['Pulitzer Prize for Fiction (1961)', 'Audie A...    4501075   \n",
       "\n",
       "                                      ratingsByStars likedPercent  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...         96.0   \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']         98.0   \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...         95.0   \n",
       "\n",
       "                                             setting  \\\n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...   \n",
       "1  ['Hogwarts School of Witchcraft and Wizardry (...   \n",
       "2               ['Maycomb, Alabama (United States)']   \n",
       "\n",
       "                                            coverImg bbeScore  bbeVotes price  \\\n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...  2993816     30516  5.09   \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...  2632233     26923  7.38   \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...  2269402     23328   NaN   \n",
       "\n",
       "   bookId_num  \n",
       "0   2767052.0  \n",
       "1         2.0  \n",
       "2      2657.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052.0</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865.0</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1          2767052.0       2767052  2792775          272  439023483   \n",
       "1        2                3.0             3  4640799          491  439554934   \n",
       "2        3            41865.0         41865  3212258          226  316015849   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BBE — Shape: (52478, 26)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bookId            52478 non-null  object \n",
      " 1   title             52478 non-null  object \n",
      " 2   series            23470 non-null  object \n",
      " 3   author            52478 non-null  object \n",
      " 4   rating            52478 non-null  float64\n",
      " 5   description       51140 non-null  object \n",
      " 6   language          48672 non-null  object \n",
      " 7   isbn              52478 non-null  object \n",
      " 8   genres            52478 non-null  object \n",
      " 9   characters        52478 non-null  object \n",
      " 10  bookFormat        51005 non-null  object \n",
      " 11  edition           4955 non-null   object \n",
      " 12  pages             50131 non-null  object \n",
      " 13  publisher         48782 non-null  object \n",
      " 14  publishDate       51598 non-null  object \n",
      " 15  firstPublishDate  31152 non-null  object \n",
      " 16  awards            52478 non-null  object \n",
      " 17  numRatings        52478 non-null  int64  \n",
      " 18  ratingsByStars    52478 non-null  object \n",
      " 19  likedPercent      51856 non-null  float64\n",
      " 20  setting           52478 non-null  object \n",
      " 21  coverImg          51873 non-null  object \n",
      " 22  bbeScore          52478 non-null  int64  \n",
      " 23  bbeVotes          52478 non-null  int64  \n",
      " 24  price             38113 non-null  object \n",
      " 25  bookId_num        52478 non-null  float64\n",
      "dtypes: float64(3), int64(3), object(20)\n",
      "memory usage: 10.4+ MB\n",
      "None\n",
      "edition             47523\n",
      "series              29008\n",
      "firstPublishDate    21326\n",
      "price               14365\n",
      "language             3806\n",
      "publisher            3696\n",
      "pages                2347\n",
      "bookFormat           1473\n",
      "description          1338\n",
      "publishDate           880\n",
      "dtype: int64\n",
      "\n",
      "Books — Shape: (10000, 23)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   book_id                    10000 non-null  int64  \n",
      " 1   goodreads_book_id          10000 non-null  float64\n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(4), int64(12), object(7)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "language_code                1084\n",
      "isbn                          700\n",
      "isbn13                        585\n",
      "original_title                585\n",
      "original_publication_year      21\n",
      "best_book_id                    0\n",
      "book_id                         0\n",
      "work_id                         0\n",
      "books_count                     0\n",
      "goodreads_book_id               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preview data\n",
    "display(bbe_clean.head(3))\n",
    "display(books_clean.head(3))\n",
    "\n",
    "# Check shape and missing values\n",
    "for name, df in {'BBE': bbe_clean, 'Books': books_clean,}.items():\n",
    "    print(f\"\\n{name} — Shape: {df.shape}\")\n",
    "    print(df.info())\n",
    "    print(df.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b59d8",
   "metadata": {},
   "source": [
    "We will check if the datasets share common identifiers and compatible data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4382d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in BBE: {'numRatings', 'bookFormat', 'bbeScore', 'bbeVotes', 'firstPublishDate', 'author', 'genres', 'rating', 'ratingsByStars', 'bookId', 'characters', 'bookId_num', 'coverImg', 'pages', 'price', 'series', 'publisher', 'setting', 'awards', 'publishDate', 'language', 'likedPercent', 'description', 'edition'}\n",
      "Columns only in Goodbooks: {'ratings_2', 'books_count', 'book_id', 'ratings_3', 'authors', 'original_title', 'ratings_5', 'ratings_1', 'ratings_4', 'best_book_id', 'average_rating', 'original_publication_year', 'isbn13', 'work_ratings_count', 'small_image_url', 'ratings_count', 'image_url', 'work_text_reviews_count', 'work_id', 'goodreads_book_id', 'language_code'}\n"
     ]
    }
   ],
   "source": [
    "bbe_only_columns = set(bbe_clean.columns) - set(books_clean.columns)\n",
    "print(f'Columns only in BBE: {bbe_only_columns}')\n",
    "\n",
    "goodbooks_only_columns = set(books_clean.columns) - set(bbe_clean.columns)\n",
    "print(f'Columns only in Goodbooks: {goodbooks_only_columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66be32",
   "metadata": {},
   "source": [
    "Based on the initial inspection, we can create a mapping table to align columns from both datasets for merging and analysis.\n",
    "\n",
    "| **BestBooksEver (BBE)**           | **Goodbooks10k_books (GB10k)**                   | **Notes / Alignment Rationale**                                            |\n",
    "| --------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------- |\n",
    "| `bookId`           | `book_id`                                                      | Main identifier; ensure both are numeric.                      |\n",
    "| `bookId_num`           | `goodreads_book_id`                                        | Goodreads identifier; ensure both are numeric for joining.                      |\n",
    "| `title`                           | `title`                                          | Direct match. Used as secondary join key.                                  |\n",
    "| `series`                          | —                                                | Only in BBE; could enrich GB10k if available via API.                      |\n",
    "| `author`                          | `authors`                                        | Same meaning. Normalize format.      |\n",
    "| `rating`                          | `average_rating`                                 | Equivalent — rename to unified `average_rating`.                           |\n",
    "| `numRatings`                      | `ratings_count`                                  | Same measure of total user ratings.                                        |\n",
    "| `ratingsByStars`                  | `ratings_1` … `ratings_5`                        | BBE has dict, GB10k has explicit columns. Expand or aggregate accordingly. |\n",
    "| `likePercent` (or `likedPercent`) | —                                                | BBE-only; optional metric of user sentiment.                               |\n",
    "| `isbn`                            | `isbn` / `isbn13`                                | Common linking key; keep both (string). Use for merges when present.       |\n",
    "| `language`                        | `language_code`                                  | Standardize to ISO 639-1 (lowercase).                                      |\n",
    "| `description`                     | —                                                | BBE-only; valuable for NLP features.                                       |\n",
    "| `genres`                          | —                                                | BBE-only; can enrich GB10k tags later.                                     |\n",
    "| `characters`                      | —                                                | BBE-only; low modeling priority, but could add narrative metadata.         |\n",
    "| `bookFormat`                      | —                                                | BBE-only; possible categorical feature.                                    |\n",
    "| `edition`                         | —                                                | BBE-only.                                                                  |\n",
    "| `pages`                           | —                                                | BBE-only; numeric, may enrich GB10k metadata.                              |\n",
    "| `publisher`                       | —                                                | BBE-only; possible future feature.                                         |\n",
    "| `publishDate`                     | —                                                | BBE-only; can approximate from GB10k’s `original_publication_year`.        |\n",
    "| `firstPublishDate`                | `original_publication_year`                      | Equivalent (date vs year).                                                 |\n",
    "| `coverImg`                        | `image_url` / `small_image_url`                  | Same function (cover link).                                                |\n",
    "| `bbeScore`                        | —                                                | BBE-only; internal popularity score.                                       |\n",
    "| `bbeVotes`                        | `work_ratings_count`                             | Comparable as popularity proxy.                                            |\n",
    "| `price`                           | —                                                | BBE-only; likely non-essential for satisfaction prediction.                |\n",
    "| `setting`                         | —                                                | BBE-only; can support content enrichment.                                  |\n",
    "| `awards`                          | —                                                | BBE-only; categorical enrichment.                                          |\n",
    "| —                                 | `goodreads_book_id` / `best_book_id` / `work_id` | GB10k-only identifiers; may be used for deeper Goodreads linking.          |\n",
    "| —                                 | `books_count`                                    | GB10k-only; number of editions per work.                                   |\n",
    "| —                                 | `work_text_reviews_count`                        | GB10k-only; can complement `numRatings` as engagement metric.              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5069ac1",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "### Best Books Ever\n",
    "\n",
    "- Handle identifier columns\n",
    "- Standardize key columns: `author`, `language`\n",
    "- Missing data handling strategies\n",
    "- Normalize genre and format\n",
    "- Validate for no nulls or duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e6ae8",
   "metadata": {},
   "source": [
    "#### 1. Handle identifier columns\n",
    "On the previous notebook, we created a new field `bookId_num` in the BBE dataset to align with `goodreads_book_id` in the Goodbooks10k dataset. We have also ensured that they were both converted to numeric types and that all `bookId` values generated a valid `bookId_num`. So we can skip the handle identifier columns, as it was already done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6e5f",
   "metadata": {},
   "source": [
    "#### 2. Standardize key columns\n",
    "\n",
    "**Author Column**\n",
    "\n",
    "We will proceed with the standardization of key columns, starting with the `author` column. The author column in the BBE dataset often contains a qualifier such as \"(Goodreads Author)\". We will remove such qualifiers to standardize the format. We will also create an additional list column to store multiple authors as a list rather than a single string. This way, its is ready to use for feature engineering later on if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c0d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_and_split_authors(name):\n",
    "    \"\"\"\n",
    "    Cleans author names and returns a list of authors.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    # Remove role descriptors\n",
    "    cleaned = re.sub(r\"\\s*\\([^)]*\\)\", \"\", name)\n",
    "    \n",
    "    # Split into list if multiple authors exist\n",
    "    authors_list = [a.strip() for a in cleaned.split(\",\") if a.strip()]\n",
    "    \n",
    "    return authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145894ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>authors_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>[Suzanne Collins]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>[J.K. Rowling, Mary GrandPré]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>[Harper Lee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen, Anna Quindlen (Introduction)</td>\n",
       "      <td>Jane Austen, Anna Quindlen</td>\n",
       "      <td>[Jane Austen, Anna Quindlen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>[Stephenie Meyer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      author                 author_clean  \\\n",
       "0                            Suzanne Collins              Suzanne Collins   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)  J.K. Rowling, Mary GrandPré   \n",
       "2                                 Harper Lee                   Harper Lee   \n",
       "3  Jane Austen, Anna Quindlen (Introduction)   Jane Austen, Anna Quindlen   \n",
       "4                            Stephenie Meyer              Stephenie Meyer   \n",
       "\n",
       "                    authors_list  \n",
       "0              [Suzanne Collins]  \n",
       "1  [J.K. Rowling, Mary GrandPré]  \n",
       "2                   [Harper Lee]  \n",
       "3   [Jane Austen, Anna Quindlen]  \n",
       "4              [Stephenie Meyer]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to BestBooksEver dataset\n",
    "bbe_clean[\"authors_list\"] = bbe_clean[\"author\"].apply(clean_and_split_authors)\n",
    "bbe_clean[\"author_clean\"] = bbe_clean[\"authors_list\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else None)\n",
    "\n",
    "# Quick check\n",
    "bbe_clean[[\"author\", \"author_clean\", \"authors_list\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a74c31",
   "metadata": {},
   "source": [
    "**Language Column**\n",
    "\n",
    "The `language` column in the Best Books Ever dataset used full names such as “English”, “German”, and “Arabic”.  Before transforming the values, we will check for all unique values to identify any unexpected entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f122d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique language values in BBE dataset:\n",
      "\n",
      "Total unique values: 82\n",
      "\n",
      "['English' 'French' 'German' 'Persian' 'Arabic' 'nan' 'Spanish'\n",
      " 'Multiple languages' 'Portuguese' 'Indonesian' 'Turkish' 'Polish'\n",
      " 'Bulgarian' 'Tamil' 'Japanese' 'Romanian' 'Italian'\n",
      " 'French, Middle (ca.1400-1600)' 'Norwegian' 'Urdu' 'Dutch' 'Finnish'\n",
      " 'Marathi' 'Chinese' 'Swedish' 'Icelandic' 'Malayalam' 'Croatian'\n",
      " 'Estonian' 'Greek, Modern (1453-)' 'Russian' 'Kurdish' 'Danish' 'Hindi'\n",
      " 'Filipino; Pilipino' 'Serbian' 'Bengali' 'Malay' 'Catalan; Valencian'\n",
      " 'Czech' 'Vietnamese' 'Armenian' 'Georgian' 'Kannada' 'Korean' 'Nepali'\n",
      " 'Slovak' 'Telugu' 'Hungarian' 'English, Middle (1100-1500)' 'Azerbaijani'\n",
      " 'Farsi' 'Lithuanian' 'Ukrainian' 'Bokmål, Norwegian; Norwegian Bokmål'\n",
      " 'Iranian (Other)' 'Faroese' 'Basque' 'Macedonian' 'Maltese' 'Gujarati'\n",
      " 'Amharic' 'Aromanian; Arumanian; Macedo-Romanian' 'Assamese'\n",
      " 'Panjabi; Punjabi' 'Albanian' 'Latvian' 'Bosnian' 'Afrikaans' 'Thai'\n",
      " 'Dutch, Middle (ca.1050-1350)' 'Mongolian' 'Tagalog' 'Galician' 'Aleut'\n",
      " 'Slovenian' 'Undetermined' 'Greek, Ancient (to 1453)' 'Mayan languages'\n",
      " 'Duala' 'Australian languages' 'Norwegian Nynorsk; Nynorsk, Norwegian']\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique language values\n",
    "print(\"Unique language values in BBE dataset:\")\n",
    "bbe_clean['language'] = bbe_clean['language'].astype(str).str.strip()\n",
    "unique_languages = bbe_clean['language'].unique()\n",
    "\n",
    "print(f\"\\nTotal unique values: {len(unique_languages)}\\n\")\n",
    "print(unique_languages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d9853",
   "metadata": {},
   "source": [
    "We can see that there are some unexpected values such as:\n",
    "- _historical forms_ (“English, Middle (1100-1500)”, “French, Middle (ca.1400-1600)”)\n",
    "- _combined or semicolon-separated entries_ (“Filipino; Pilipino”, “Catalan; Valencian”)\n",
    "- _multi-language / uncertain cases_ (“Multiple languages”, “Undetermined”)\n",
    "- _rare or dialects_ (“Bokmål, Norwegian; Norwegian Bokmål”, “Aromanian; Arumanian; Macedo-Romanian”)\n",
    "\n",
    "We will clean the unusual entries by mapping them to the closest language present in the ISO 639-1 standard. Unrecognized values will be flagged and replaced with `\"unknown\"`. It was decided to distinguish the `\"unknown\"` from the `NaN` values to retain information about missingness versus unrecognized entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20a83c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Standardize capitalization & spacing\n",
    "bbe_clean['language'] = bbe_clean['language'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Handle NaNs that became strings\n",
    "bbe_clean['language'] = bbe_clean['language'].replace({'Nan': np.nan})\n",
    "\n",
    "# Simplify and unify multi-language / dialect forms\n",
    "replace_map = {\n",
    "    'Multiple Languages': 'Multilingual',\n",
    "    'Undetermined': 'Unknown',\n",
    "    'Iranian (Other)': 'Persian',\n",
    "    'Farsi': 'Persian',\n",
    "    'Filipino; Pilipino': 'Filipino',\n",
    "    'Catalan; Valencian': 'Catalan',\n",
    "    'Panjabi; Punjabi': 'Punjabi',\n",
    "    'Bokmål, Norwegian; Norwegian Bokmål': 'Norwegian',\n",
    "    'Norwegian Nynorsk; Nynorsk, Norwegian': 'Norwegian',\n",
    "    'Greek, Modern (1453-)': 'Greek',\n",
    "    'Greek, Ancient (To 1453)': 'Greek',\n",
    "    'French, Middle (Ca.1400-1600)': 'French',\n",
    "    'English, Middle (1100-1500)': 'English',\n",
    "    'Dutch, Middle (Ca.1050-1350)': 'Dutch',\n",
    "    'Aromanian; Arumanian; Macedo-Romanian': 'Romanian',\n",
    "    'Mayan Languages': 'Mayan',\n",
    "    'Australian Languages': 'English'\n",
    "}\n",
    "\n",
    "bbe_clean['language'] = bbe_clean['language'].replace(replace_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ad13",
   "metadata": {},
   "source": [
    "After transforming the values, we will apply the mapping to standardize the `language` column to ISO 639-1 two-letter codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37289380",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dict = {\n",
    "    \"english\": \"en\", \"german\": \"de\", \"french\": \"fr\", \"arabic\": \"ar\",\n",
    "    \"spanish\": \"es\", \"italian\": \"it\", \"portuguese\": \"pt\", \"russian\": \"ru\",\n",
    "    \"chinese\": \"zh\", \"japanese\": \"ja\", \"hindi\": \"hi\", \"dutch\": \"nl\",\n",
    "    \"swedish\": \"sv\", \"norwegian\": \"no\", \"polish\": \"pl\", \"turkish\": \"tr\",\n",
    "    \"korean\": \"ko\", \"danish\": \"da\", \"finnish\": \"fi\", \"hebrew\": \"he\",\n",
    "    \"greek\": \"el\", \"czech\": \"cs\", \"romanian\": \"ro\", \"indonesian\": \"id\",\n",
    "    \"thai\": \"th\", \"hungarian\": \"hu\", \"vietnamese\": \"vi\", \"persian\": \"fa\",\n",
    "    \"icelandic\": \"is\", \"latin\": \"la\", \"swahili\": \"sw\", \"bulgarian\": \"bg\",\n",
    "    \"croatian\": \"hr\", \"estonian\": \"et\", \"tamil\": \"ta\", \"urdu\": \"ur\",\n",
    "    \"malayalam\": \"ml\", \"slovak\": \"sk\", \"telugu\": \"te\", \"azerbaijani\": \"az\",\n",
    "    \"lithuanian\": \"lt\", \"ukrainian\": \"uk\", \"faroese\": \"fo\", \"basque\": \"eu\",\n",
    "    \"macedonian\": \"mk\", \"maltese\": \"mt\", \"gujarati\": \"gu\", \"amharic\": \"am\",\n",
    "    \"albanian\": \"sq\", \"latvian\": \"lv\", \"bosnian\": \"bs\", \"afrikaan\": \"af\",\n",
    "    \"mongolian\": \"mn\", \"tagalog\": \"tl\", \"galician\": \"gl\", \"slovenian\": \"sl\",\n",
    "    \"armenian\": \"hy\", \"georgian\": \"ka\", \"kannada\": \"kn\", \"marathi\": \"mr\",\n",
    "    \"nepali\": \"ne\", \"punjabi\": \"pa\", \"filipino\": \"fil\", \"mayan\": \"myn\",\n",
    "    \"unknown\": \"unknown\", \"multilingual\": \"multi\"\n",
    "}\n",
    "\n",
    "# Apply dictionary\n",
    "bbe_clean['language'] = bbe_clean['language'].str.lower().map(language_dict)\n",
    "\n",
    "# Fill remaining NaNs\n",
    "bbe['language'] = bbe['language'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736c49f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique language values in BBE dataset:\n",
      "\n",
      "Total unique values: 63\n",
      "\n",
      "['en' 'fr' 'de' 'fa' 'ar' nan 'es' 'multi' 'pt' 'id' 'tr' 'pl' 'bg' 'ta'\n",
      " 'ja' 'ro' 'it' 'no' 'ur' 'nl' 'fi' 'mr' 'zh' 'sv' 'is' 'ml' 'hr' 'et'\n",
      " 'el' 'ru' 'da' 'hi' 'fil' 'cs' 'vi' 'hy' 'ka' 'kn' 'ko' 'ne' 'sk' 'te'\n",
      " 'hu' 'az' 'lt' 'uk' 'fo' 'eu' 'mk' 'mt' 'gu' 'am' 'pa' 'sq' 'lv' 'bs'\n",
      " 'th' 'mn' 'tl' 'gl' 'sl' 'unknown' 'myn']\n"
     ]
    }
   ],
   "source": [
    "# check again for unique language values\n",
    "print(\"Unique language values in BBE dataset:\")\n",
    "unique_languages = bbe_clean['language'].unique()\n",
    "\n",
    "print(f\"\\nTotal unique values: {len(unique_languages)}\\n\")\n",
    "print(unique_languages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6b8f9",
   "metadata": {},
   "source": [
    "**Date Columns**\n",
    "\n",
    "BBE dataset has two publication fields: `publishDate` and `firstPublishDate`. The `firstPublishDate` represents the original publication date, while `publishDate` refers to a more recent edition or reprint date. Publishing experts assumption is that the recency of the `firstPublishDate` is more relevant for modeling book satisfaction, as it reflects when the book was first introduced to readers. Therefore, we will focus on cleaning and standardizing the `firstPublishDate` column and use `publishDate` only if `firstPublishDate` is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2685c",
   "metadata": {},
   "source": [
    "While majority of the dates follow the 'MM/DD/YY' format, after a first attemp at cleaning, we noticed some dates do not conform to this format. Therefore, we will implement a more robust date parsing strategy, focusing first on transforming textual formats into 'MM/DD/YYYY' format before attempting to parse them into datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def clean_date_string(date_str):\n",
    "    \"\"\"Remove ordinal suffixes and unwanted characters from a date string.\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return np.nan\n",
    "    # remove st, nd, rd, th (like 'April 27th 2010' → 'April 27 2010')\n",
    "    cleaned = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', str(date_str))\n",
    "    return cleaned.strip()\n",
    "\n",
    "def parse_mixed_date(date_str):\n",
    "    \"\"\"Try to parse a variety of date formats safely.\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Use dateutil to parse most human-readable formats\n",
    "        return parser.parse(date_str, fuzzy=True)\n",
    "    except Exception:\n",
    "        # Try year-only fallback (e.g. '2003')\n",
    "        match = re.match(r'^\\d{4}$', str(date_str))\n",
    "        if match:\n",
    "            return pd.to_datetime(f\"{date_str}-01-01\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a7cc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to both columns\n",
    "for col in ['firstPublishDate', 'publishDate']:\n",
    "    bbe[f'{col}_clean'] = (\n",
    "        bbe[col]\n",
    "        .astype(str)\n",
    "        .replace({'nan': np.nan, '': np.nan})\n",
    "        .apply(clean_date_string)\n",
    "        .apply(parse_mixed_date)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0493da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>publication_date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>To Dream the Blackbane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>Betrayal In Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Books to Read When the Snow Is Falling\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Stepping Beyond Intention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>The Fyfield Plantation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>Angles - Part I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>لوحات ناجي العلي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>Mayfair Witches Collection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Horror Novels\\n\\n1,773 books — 5,396 vote...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>Night That Jimi Died</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50 Books That Changed Me\\n\\n319 books — 259 vo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>الشيخ زعرب وآخرون</td>\n",
       "      <td>NaN</td>\n",
       "      <td>أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11231</th>\n",
       "      <td>World Peace: The Voice of a Mountain Bird</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 9th 214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11417</th>\n",
       "      <td>Harakiri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11699</th>\n",
       "      <td>Wuthering Heights by Emily Brontë</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12189</th>\n",
       "      <td>The Mafia And His Angel: Part 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brotherhood/Dark Alpha Romance\\n\\n66 books — 3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12208</th>\n",
       "      <td>حروب دولة الرسول</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>Effortless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harper Impulse Books\\n\\n177 books — 107 voters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title firstPublishDate  \\\n",
       "2271                      To Dream the Blackbane              NaN   \n",
       "2989                           Betrayal In Black              NaN   \n",
       "3138                   Stepping Beyond Intention              NaN   \n",
       "3160                      The Fyfield Plantation              NaN   \n",
       "4359                             Angles - Part I              NaN   \n",
       "4508                            لوحات ناجي العلي              NaN   \n",
       "7869                  Mayfair Witches Collection              NaN   \n",
       "8409                        Night That Jimi Died              NaN   \n",
       "9054                           الشيخ زعرب وآخرون              NaN   \n",
       "11231  World Peace: The Voice of a Mountain Bird              NaN   \n",
       "11417                                   Harakiri              NaN   \n",
       "11699          Wuthering Heights by Emily Brontë              NaN   \n",
       "12189            The Mafia And His Angel: Part 3              NaN   \n",
       "12208                           حروب دولة الرسول              NaN   \n",
       "12487                                 Effortless              NaN   \n",
       "\n",
       "                                             publishDate  \\\n",
       "2271                                           Published   \n",
       "2989   Best Books to Read When the Snow Is Falling\\n\\...   \n",
       "3138                                                 NaN   \n",
       "3160                                                 NaN   \n",
       "4359                                                 NaN   \n",
       "4508   في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...   \n",
       "7869   Best Horror Novels\\n\\n1,773 books — 5,396 vote...   \n",
       "8409   50 Books That Changed Me\\n\\n319 books — 259 vo...   \n",
       "9054   أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...   \n",
       "11231                                  September 9th 214   \n",
       "11417                                          Published   \n",
       "11699                                          Published   \n",
       "12189  Brotherhood/Dark Alpha Romance\\n\\n66 books — 3...   \n",
       "12208                                          Published   \n",
       "12487     Harper Impulse Books\\n\\n177 books — 107 voters   \n",
       "\n",
       "      publication_date_clean  \n",
       "2271                     NaN  \n",
       "2989                     NaN  \n",
       "3138                     NaN  \n",
       "3160                     NaN  \n",
       "4359                     NaN  \n",
       "4508                     NaN  \n",
       "7869                     NaN  \n",
       "8409                     NaN  \n",
       "9054                     NaN  \n",
       "11231                    NaN  \n",
       "11417                    NaN  \n",
       "11699                    NaN  \n",
       "12189                    NaN  \n",
       "12208                    NaN  \n",
       "12487                    NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine using your logic: prefer firstPublishDate, else publishDate\n",
    "bbe['publication_date_clean'] = (\n",
    "    bbe['firstPublishDate_clean'].combine_first(bbe['publishDate_clean'])\n",
    ")\n",
    "# Reconvert to datetime safely before using .dt\n",
    "bbe['publication_date_clean'] = pd.to_datetime(bbe['publication_date_clean'], errors='coerce')\n",
    "\n",
    "# Format as ISO standard\n",
    "bbe['publication_date_clean'] = bbe['publication_date_clean'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Check a sample of remaining nulls\n",
    "bbe[bbe['publication_date_clean'].isna()][['title', 'firstPublishDate', 'publishDate', 'publication_date_clean']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8186db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing publication dates: 588 of 52478 (1.12%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>publication_date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>To Dream the Blackbane</td>\n",
       "      <td>Richard J. O'Brien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Published</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>Betrayal In Black</td>\n",
       "      <td>Mark M. Bello (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Books to Read When the Snow Is Falling\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Stepping Beyond Intention</td>\n",
       "      <td>Daniel Mangena (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>The Fyfield Plantation</td>\n",
       "      <td>Andrew R. Williams (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>Angles - Part I</td>\n",
       "      <td>Erin Lockwood (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>لوحات ناجي العلي</td>\n",
       "      <td>ناجي العلي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>Mayfair Witches Collection</td>\n",
       "      <td>Anne Rice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Horror Novels\\n\\n1,773 books — 5,396 vote...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>Night That Jimi Died</td>\n",
       "      <td>Darragh J Brady</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50 Books That Changed Me\\n\\n319 books — 259 vo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>الشيخ زعرب وآخرون</td>\n",
       "      <td>يوسف السباعي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11231</th>\n",
       "      <td>World Peace: The Voice of a Mountain Bird</td>\n",
       "      <td>Amit Ray, Banani Ray (Goodreads Author)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 9th 214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "2271                      To Dream the Blackbane   \n",
       "2989                           Betrayal In Black   \n",
       "3138                   Stepping Beyond Intention   \n",
       "3160                      The Fyfield Plantation   \n",
       "4359                             Angles - Part I   \n",
       "4508                            لوحات ناجي العلي   \n",
       "7869                  Mayfair Witches Collection   \n",
       "8409                        Night That Jimi Died   \n",
       "9054                           الشيخ زعرب وآخرون   \n",
       "11231  World Peace: The Voice of a Mountain Bird   \n",
       "\n",
       "                                        author firstPublishDate  \\\n",
       "2271                        Richard J. O'Brien              NaN   \n",
       "2989          Mark M. Bello (Goodreads Author)              NaN   \n",
       "3138         Daniel Mangena (Goodreads Author)              NaN   \n",
       "3160     Andrew R. Williams (Goodreads Author)              NaN   \n",
       "4359          Erin Lockwood (Goodreads Author)              NaN   \n",
       "4508                                ناجي العلي              NaN   \n",
       "7869                                 Anne Rice              NaN   \n",
       "8409                           Darragh J Brady              NaN   \n",
       "9054                              يوسف السباعي              NaN   \n",
       "11231  Amit Ray, Banani Ray (Goodreads Author)              NaN   \n",
       "\n",
       "                                             publishDate  \\\n",
       "2271                                           Published   \n",
       "2989   Best Books to Read When the Snow Is Falling\\n\\...   \n",
       "3138                                                 NaN   \n",
       "3160                                                 NaN   \n",
       "4359                                                 NaN   \n",
       "4508   في أحضان الكتب - الجزء الثاني\\n\\n111 books — 2...   \n",
       "7869   Best Horror Novels\\n\\n1,773 books — 5,396 vote...   \n",
       "8409   50 Books That Changed Me\\n\\n319 books — 259 vo...   \n",
       "9054   أفضل مجموعة قصصية عربية\\n\\n1,069 books — 401 v...   \n",
       "11231                                  September 9th 214   \n",
       "\n",
       "      publication_date_clean  \n",
       "2271                     NaN  \n",
       "2989                     NaN  \n",
       "3138                     NaN  \n",
       "3160                     NaN  \n",
       "4359                     NaN  \n",
       "4508                     NaN  \n",
       "7869                     NaN  \n",
       "8409                     NaN  \n",
       "9054                     NaN  \n",
       "11231                    NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where the unified publication date is missing\n",
    "total = len(bbe)\n",
    "bbe_missing_dates = bbe.loc[bbe['publication_date_clean'].isna()]\n",
    "missing_count = len(bbe_missing_dates)\n",
    "\n",
    "print(f\"Missing publication dates: {missing_count} of {total} ({missing_count/total:.2%})\")\n",
    "\n",
    "# Preview key columns\n",
    "bbe_missing_dates[['title', 'author', 'firstPublishDate', 'publishDate', 'publication_date_clean']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
