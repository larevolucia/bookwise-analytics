{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9f0c5c",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "## Objectives\n",
    "The goal of this notebook is to **collect, consolidate, and prepare datasets** that will be used to build data-driven insights for the *Book Subscription Optimization* project.  \n",
    "This aligns with the **Data Collection and Understanding** stages of the CRISP-DM process, ensuring that the data foundation supports later stages of modeling and evaluation.\n",
    "\n",
    "Specifically, this notebook aims to:\n",
    "- Retrieve and load multiple book-related datasets from open sources.  \n",
    "- Perform initial validation to assess structure, completeness, and consistency. \n",
    "- Note any data quality issues for future cleaning steps.\n",
    "\n",
    "## Inputs\n",
    "- **Goodbooks-10k Dataset:** User-book interactions and ratings, used to simulate subscription platform interactions.  \n",
    "- **Best Books Ever Dataset:** Global book metadata and ratings, used for cross-platform popularity validation and content catalogue proxy.  \n",
    "\n",
    "Each dataset contributes unique dimensions: reader behavior, book features, and market data. This structure allows for a holistic analysis of book engagement and satisfaction.\n",
    "\n",
    "## Outputs\n",
    "- Metadata summary of dataset structure, completeness, and variable distributions.  \n",
    "- Preliminary insights into data coverage for later CRISP-DM stages (Data Understanding & Preparation).\n",
    "- Original datasets saved in CSV format for reproducibility and future use.\n",
    "\n",
    "> **Note:** This notebook focuses on data collection and initial assessment. Detailed cleaning and transformation will be addressed in subsequent notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93184b07",
   "metadata": {},
   "source": [
    "## Navigate to the Parent Directory\n",
    "\n",
    "Before combining and saving datasets, it’s often helpful to move to a parent directory so that file operations (like loading or saving data) are easier and more organized. \n",
    "\n",
    "Before using the Python’s built-in os module to move one level up from the current working directory, it is advisable to inspect the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aa873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e187eca",
   "metadata": {},
   "source": [
    "To change to parent directory (root folder), run the code below. If you are already in the root folder, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31486d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to its parent\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Changed directory to parent.')\n",
    "\n",
    "# Get the new current working directory (the parent directory)\n",
    "current_dir = os.getcwd()\n",
    "print(f'New current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79fa32",
   "metadata": {},
   "source": [
    "## Fetch data from various sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0cece",
   "metadata": {},
   "source": [
    "In this section, we will fetch data from multiple open datasets and inspect their basic properties to understand their structure and content. Since the datasets are all hosted in GitHub repositories, we will use pandas to read them directly from their raw URLs.\n",
    "To streamline the process, we will define a function that loads a dataset from a given URL and prints its shape, columns, and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def load_and_inspect(path, name, show_head=False):\n",
    "    \"\"\"\n",
    "    Load a dataset and perform initial structure validation.\n",
    "    - Structure and type overview\n",
    "    - Missing value summary\n",
    "    - Duplicate count\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        File path to the dataset (CSV format expected).\n",
    "    name : str\n",
    "        Readable name for reporting purposes.\n",
    "    show_head : bool, optional\n",
    "        If True, displays the first five rows for preview. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Loaded dataset for further exploration.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"\\n{name} loaded successfully.\")\n",
    "        print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        \n",
    "        # Structural Overview\n",
    "        print(\"\\nData Overview:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(df.info())\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Missing value summary\n",
    "        missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "        if missing_cols:\n",
    "            print(\"\\nColumns with Missing Data:\", \", \".join(missing_cols))\n",
    "        else:\n",
    "            print(\"\\nNo missing data detected\")\n",
    "\n",
    "        # Duplicate check\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        print(f\"\\nDuplicate Rows: {duplicate_count}\")\n",
    "\n",
    "        if show_head:\n",
    "            display(df.head(3))\n",
    "\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08994d1d",
   "metadata": {},
   "source": [
    "### Goodbooks-10k Dataset\n",
    "In this step, we load two datasets from the **Goodbooks-10k** project, hosted on GitHub.\n",
    "This dataset will simulate user-book interactions on a book subscription platform.\n",
    "\n",
    "These datasets contain:\n",
    "\n",
    "- **Books**: metadata about 10,000 books (e.g. title, authors, publication year, ratings).\n",
    "- **Ratings**: over 5 million individual ratings given by readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of the Goodbooks-10k datasets (hosted on GitHub)\n",
    "books_url   = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv\"\n",
    "\n",
    "# Load the ratings and books data into Pandas DataFrames\n",
    "books = load_and_inspect(books_url, 'Books')      # Contains detailed book metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 rows of the books dataset\n",
    "print(\"Books Data:\")\n",
    "display(books.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5bc811",
   "metadata": {},
   "source": [
    "The dataset includes 10,000 records and 23 attributes describing book metadata, publication details, and aggregated rating statistics. Core fields such as `title`, `author`, and `average_rating` are complete and well-defined, supporting reliability for downstream recommendation modeling.\n",
    "A few metadata fields (`ISBN`, `ISBN13`, `original_title`, `language_code`, and `original_publication_year`) contain missing values, mainly related to identification or translation details. No duplicate records were detected. Overall, the dataset is clean, compact, and suitable for integrating with user rating data to form the analytical base of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46624901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of the Goodbooks-10k datasets (hosted on GitHub)\n",
    "ratings_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv\"\n",
    "\n",
    "# Load the ratings and books data into Pandas DataFrames\n",
    "ratings = load_and_inspect(ratings_url, 'Ratings')  # Contains user_id, book_id, and rating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 rows of the ratings dataset\n",
    "print(\"Ratings Data:\")\n",
    "display(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88fc98d",
   "metadata": {},
   "source": [
    "This dataset comprises 5.97 million user–book interaction records across three fields: `user_id`, `book_id`, and `rating`. There are no missing values or duplicate entries, indicating excellent data integrity.\n",
    "The structure and completeness make it highly suitable for collaborative filtering and user engagement modeling. Combined with the book metadata, it provides a robust foundation for analyzing reading preferences and predicting personalized selections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99402bfa",
   "metadata": {},
   "source": [
    "### Best Books Ever Dataset\n",
    "In this step, we load the **Best Books Ever** dataset, which contains metadata and ratings for a wider range of books. We can reuse the same function defined earlier to load and inspect this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db66426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bbe_url = 'https://raw.githubusercontent.com/scostap/goodreads_bbe_dataset/refs/heads/main/Best_Books_Ever_dataset/books_1.Best_Books_Ever.csv'\n",
    "bbe = load_and_inspect(bbe_url, 'Best Books Ever', show_head=True)\n",
    "# We'll preview the first few rows of the dataset to get an initial understanding of their structure and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa85b42",
   "metadata": {},
   "source": [
    "The dataset contains 52,478 records and 25 features, providing extensive coverage of book metadata, author details, and reader engagement metrics. Most core fields (title, author, rating, ISBN, genres) are complete and well-structured, indicating strong potential for content-based analysis.\n",
    "\n",
    "However, 12 columns exhibit missing data, mainly in auxiliary attributes such as series, book format, publisher, publication dates, and price, which may require selective imputation or exclusion in later cleaning. The presence of 50 duplicate rows suggests minor redundancy that should be addressed during the Data Preparation phase. Overall, the dataset is rich and comprehensive, with data quality issues confined to non-critical metadata fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600a6dd",
   "metadata": {},
   "source": [
    "## Overlap Inspection\n",
    "After loading the datasets, it is important to inspect the overlap between them to ensure consistency and identify potential integration points for analysis. We will check for common `book_id` values between the Goodbooks-10k and Best Books Ever datasets.\n",
    "\n",
    "This will ensure that we are able to simulate user interactions on a subscription platform while validating book popularity across a broader market context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b2d6b",
   "metadata": {},
   "source": [
    "### Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric identifiers from the 'bookId' string column in the Best Books Ever dataset\n",
    "bbe['bookId_num'] = (\n",
    "    bbe['bookId']\n",
    "    .astype(str)\n",
    "    .str.extract(r'^(\\d+)')    # Extract leading digits whether or not followed by '.' or '-'\n",
    "    .astype(float)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc9341",
   "metadata": {},
   "source": [
    "We will run a check to identify any missing or inconsistency after splitting the numerical book Ids from the Best Books Ever dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41403202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values\n",
    "missing_count = bbe['bookId_num'].isnull().sum()\n",
    "print(f\"Missing bookId_num entries: {missing_count}\")\n",
    "\n",
    "# Display all rows where bookId_num is null\n",
    "bbe_missing_bookId_num = bbe[bbe['bookId_num'].isnull()]\n",
    "\n",
    "# Inspect them\n",
    "bbe_missing_bookId_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aecc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent numeric data types for key identifier columns in both datasets\n",
    "bbe['bookId_num'] = bbe['bookId_num'].astype(float)\n",
    "books['goodreads_book_id'] = books['goodreads_book_id'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf675f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask to identify overlapping book entries between the two datasets\n",
    "overlap_mask = bbe['bookId_num'].isin(books['goodreads_book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a963982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number and percentage of overlapping book IDs between the two datasets\n",
    "overlap_count = overlap_mask.sum()\n",
    "\n",
    "# Percentage of overlap relative to Best Books Ever (bbe)\n",
    "overlap_pct_bbe = overlap_count / len(bbe) * 100\n",
    "\n",
    "# Percentage of overlap relative to Goodbooks-10k (books)\n",
    "overlap_pct_books = overlap_count / len(books) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of overlapping IDs: {overlap_count}\")\n",
    "print(f\"Percentage overlap (relative to Best Books Ever): {overlap_pct_bbe:.2f}%\")\n",
    "print(f\"Percentage overlap (relative to Goodbooks-10k): {overlap_pct_books:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d097d0",
   "metadata": {},
   "source": [
    "The overlap analysis reveals 8,039 shared book IDs between the **Best Books Ever** and **Goodbooks-10k datasets**, representing approximately 80% coverage of the **Goodbooks-10k** catalog and 15% coverage of the larger **Best Books Ever** collection. \n",
    "This represents a strong and realistic overlap for modeling purposes: the high proportion on the **Goodbooks** side ensures reliable alignment for simulating member-book interactions, while the lower proportion on the **BBE** side indicates a broader untapped catalog. \n",
    "This balance mirrors real-world dynamics in subscription platforms, where temporary licensing deals or curated partnerships cover a subset of available titles, leaving a substantial pool of additional books for potential recommendation expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e849e9",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "Data collection and initial inspection were successfully completed. The datasets together provide a strong foundation for analyzing book popularity, reader engagement, and cross-platform catalog alignment.\n",
    "\n",
    "- **Data Quality:** Most core fields (IDs, titles, authors, ratings) are complete and consistent.  \n",
    "  Missing data is mainly confined to secondary metadata such as publication details, ISBNs, and languages.  \n",
    "  Duplicate records were minimal and limited to the Best Books Ever dataset (50 entries).\n",
    "\n",
    "- **Schema Harmonization:** Book identifiers were standardized into numeric format to ensure compatibility across sources.  \n",
    "  This enables future merging of metadata and rating data into a unified analytical dataset.\n",
    "\n",
    "- **Cross-Dataset Overlap:** The overlap analysis revealed **8,039 shared titles**, covering **80% of Goodbooks-10k** and **15% of Best Books Ever**.  This reflects a realistic representation of shared catalog licensing, sufficient for simulation while leaving room for novel recommendations.\n",
    "\n",
    "- **Next Steps:**  \n",
    "  The upcoming **02_Data_Cleaning** notebook will focus on cleaning and transforming the data:\n",
    "  - Handling missing values and duplicates  \n",
    "  - Normalizing column types and naming conventions  \n",
    "  - (If needed) merging datasets based on books IDs to create a consolidated dataset for analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e0185",
   "metadata": {},
   "source": [
    "## Save Collected Data\n",
    "In this final section, we will save the collected datasets to CSV files for reproducibility and traceability in future steps including analysis and modeling stages of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9dfb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "raw_path = Path(\"data/raw\")\n",
    "raw_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "books.to_csv(raw_path / \"books.csv\", index=False)\n",
    "ratings.to_csv(raw_path / \"ratings.csv\", index=False)\n",
    "bbe.to_csv(raw_path / \"bbe_books.csv\", index=False)\n",
    "\n",
    "print(\"Datasets saved successfully in data/raw/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec976a1",
   "metadata": {},
   "source": [
    "**Data Sample**  \n",
    "> This step creates small representative samples of the full datasets (books, ratings, and Best Books Ever) to document the data structure.  \n",
    "> The full raw files are stored locally (not committed to the repository) to comply with size limits, while the sample files in `data/sample/` allow evaluators to inspect dataset content and metadata consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data folder if not exists\n",
    "sample_path = Path(\"data/sample\")\n",
    "sample_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use random sampling\n",
    "books_sample = books.sample(n=1000, random_state=42)\n",
    "ratings_sample = ratings.sample(n=5000, random_state=42)\n",
    "bbe_sample = bbe.sample(n=1000, random_state=42)\n",
    "\n",
    "# Save sampled datasets\n",
    "books_sample.to_csv(sample_path / \"books_sample.csv\", index=False)\n",
    "ratings_sample.to_csv(sample_path / \"ratings_sample.csv\", index=False)\n",
    "bbe_sample.to_csv(sample_path / \"bbe_books_sample.csv\", index=False)\n",
    "\n",
    "print(\"Sample datasets saved successfully in data/sample/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
