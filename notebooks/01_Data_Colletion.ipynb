{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9f0c5c",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "## Objectives\n",
    "The goal of this notebook is to **collect, consolidate, and prepare datasets** that will be used to build data-driven insights for the *Book Subscription Optimization* project.  \n",
    "This aligns with the **Data Collection and Understanding** stages of the CRISP-DM process, ensuring that the data foundation supports later stages of modeling and evaluation.\n",
    "\n",
    "Specifically, this notebook aims to:\n",
    "- Retrieve and load multiple book-related datasets from open sources.  \n",
    "- Perform initial validation to assess structure, completeness, and consistency. \n",
    "- Note any data quality issues for future cleaning steps.\n",
    "\n",
    "## Inputs\n",
    "- **Goodbooks-10k Dataset:** User-book interactions and ratings, used to simulate subscription platform interactions.  \n",
    "- **Best Books Ever Dataset:** Global book metadata and ratings, used for cross-platform popularity validation and content catalogue proxy.  \n",
    "\n",
    "Each dataset contributes unique dimensions: reader behavior, book features, and market data. This structure allows for a holistic analysis of book engagement and satisfaction.\n",
    "\n",
    "## Outputs\n",
    "- Metadata summary of dataset structure, completeness, and variable distributions.  \n",
    "- Preliminary insights into data coverage for later CRISP-DM stages (Data Understanding & Preparation).\n",
    "- Original datasets saved in CSV format for reproducibility and future use.\n",
    "\n",
    "> **Note:** This notebook focuses on data collection and initial assessment. Detailed cleaning and transformation will be addressed in subsequent notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93184b07",
   "metadata": {},
   "source": [
    "## Navigate to the Parent Directory\n",
    "\n",
    "Before combining and saving datasets, it’s often helpful to move to a parent directory so that file operations (like loading or saving data) are easier and more organized. \n",
    "\n",
    "Before using the Python’s built-in os module to move one level up from the current working directory, it is advisable to inspect the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85aa873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e187eca",
   "metadata": {},
   "source": [
    "To change to parent directory (root folder), run the code below. If you are already in the root folder, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31486d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to parent.\n",
      "New current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to its parent\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Changed directory to parent.')\n",
    "\n",
    "# Get the new current working directory (the parent directory)\n",
    "current_dir = os.getcwd()\n",
    "print(f'New current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79fa32",
   "metadata": {},
   "source": [
    "## Fetch data from various sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0cece",
   "metadata": {},
   "source": [
    "In this section, we will fetch data from multiple open datasets and inspect their basic properties to understand their structure and content. Since the datasets are all hosted in GitHub repositories, we will use pandas to read them directly from their raw URLs.\n",
    "To streamline the process, we will define a function that loads a dataset from a given URL and prints its shape, columns, and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def load_and_inspect(path, name, show_head=False):\n",
    "    \"\"\"\n",
    "    Load a dataset and perform initial structure validation.\n",
    "    - Structure and type overview\n",
    "    - Missing value summary\n",
    "    - Duplicate count\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        File path to the dataset (CSV format expected).\n",
    "    name : str\n",
    "        Readable name for reporting purposes.\n",
    "    show_head : bool, optional\n",
    "        If True, displays the first five rows for preview. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Loaded dataset for further exploration.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"\\n{name} loaded successfully.\")\n",
    "        print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        \n",
    "        # Structural Overview\n",
    "        print(\"\\nData Overview:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(df.info())\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Missing value summary\n",
    "        missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "        if missing_cols:\n",
    "            print(\"\\nColumns with Missing Data:\", \", \".join(missing_cols))\n",
    "        else:\n",
    "            print(\"\\nNo missing data detected\")\n",
    "\n",
    "        # Duplicate check\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        print(f\"\\nDuplicate Rows: {duplicate_count}\")\n",
    "\n",
    "        if show_head:\n",
    "            display(df.head(3))\n",
    "\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08994d1d",
   "metadata": {},
   "source": [
    "### Goodbooks-10k Dataset\n",
    "In this step, we load two datasets from the **Goodbooks-10k** project, hosted on GitHub.\n",
    "This dataset will simulate user-book interactions on a book subscription platform.\n",
    "\n",
    "These datasets contain:\n",
    "\n",
    "- **Books**: metadata about 10,000 books (e.g. title, authors, publication year, ratings).\n",
    "- **Ratings**: over 5 million individual ratings given by readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb8e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Books loaded successfully.\n",
      "Shape: 10000 rows × 23 columns\n",
      "\n",
      "Data Overview:\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   book_id                    10000 non-null  int64  \n",
      " 1   goodreads_book_id          10000 non-null  int64  \n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(3), int64(13), object(7)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "------------------------------------------------------------\n",
      "\n",
      "Columns with Missing Data: isbn, isbn13, original_publication_year, original_title, language_code\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# URLs of the Goodbooks-10k datasets (hosted on GitHub)\n",
    "books_url   = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv\"\n",
    "\n",
    "# Load the ratings and books data into Pandas DataFrames\n",
    "books = load_and_inspect(books_url, 'Books')      # Contains detailed book metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e58923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "1        2                  3             3  4640799          491  439554934   \n",
       "2        3              41865         41865  3212258          226  316015849   \n",
       "3        4               2657          2657  3275794          487   61120081   \n",
       "4        5               4671          4671   245494         1356  743273567   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
       "3  9.780061e+12                   Harper Lee                     1960.0   \n",
       "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the first 5 rows of the books dataset\n",
    "print(\"Books Data:\")\n",
    "display(books.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5bc811",
   "metadata": {},
   "source": [
    "The dataset includes 10,000 records and 23 attributes describing book metadata, publication details, and aggregated rating statistics. Core fields such as `title`, `author`, and `average_rating` are complete and well-defined, supporting reliability for downstream recommendation modeling.\n",
    "A few metadata fields (`ISBN`, `ISBN13`, `original_title`, `language_code`, and `original_publication_year`) contain missing values, mainly related to identification or translation details. No duplicate records were detected. Overall, the dataset is clean, compact, and suitable for integrating with user rating data to form the analytical base of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46624901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings loaded successfully.\n",
      "Shape: 5976479 rows × 3 columns\n",
      "\n",
      "Data Overview:\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5976479 entries, 0 to 5976478\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype\n",
      "---  ------   -----\n",
      " 0   user_id  int64\n",
      " 1   book_id  int64\n",
      " 2   rating   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 136.8 MB\n",
      "None\n",
      "------------------------------------------------------------\n",
      "\n",
      "No missing data detected\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# URLs of the Goodbooks-10k datasets (hosted on GitHub)\n",
    "ratings_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv\"\n",
    "\n",
    "# Load the ratings and books data into Pandas DataFrames\n",
    "ratings = load_and_inspect(ratings_url, 'Ratings')  # Contains user_id, book_id, and rating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb16a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the first 5 rows of the ratings dataset\n",
    "print(\"Ratings Data:\")\n",
    "display(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88fc98d",
   "metadata": {},
   "source": [
    "This dataset comprises 5.97 million user–book interaction records across three fields: `user_id`, `book_id`, and `rating`. There are no missing values or duplicate entries, indicating excellent data integrity.\n",
    "The structure and completeness make it highly suitable for collaborative filtering and user engagement modeling. Combined with the book metadata, it provides a robust foundation for analyzing reading preferences and predicting personalized selections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99402bfa",
   "metadata": {},
   "source": [
    "### Best Books Ever Dataset\n",
    "In this step, we load the **Best Books Ever** dataset, which contains metadata and ratings for a wider range of books. We can reuse the same function defined earlier to load and inspect this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db66426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Books Ever loaded successfully.\n",
      "Shape: 52478 rows × 25 columns\n",
      "\n",
      "Data Overview:\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bookId            52478 non-null  object \n",
      " 1   title             52478 non-null  object \n",
      " 2   series            23470 non-null  object \n",
      " 3   author            52478 non-null  object \n",
      " 4   rating            52478 non-null  float64\n",
      " 5   description       51140 non-null  object \n",
      " 6   language          48672 non-null  object \n",
      " 7   isbn              52478 non-null  object \n",
      " 8   genres            52478 non-null  object \n",
      " 9   characters        52478 non-null  object \n",
      " 10  bookFormat        51005 non-null  object \n",
      " 11  edition           4955 non-null   object \n",
      " 12  pages             50131 non-null  object \n",
      " 13  publisher         48782 non-null  object \n",
      " 14  publishDate       51598 non-null  object \n",
      " 15  firstPublishDate  31152 non-null  object \n",
      " 16  awards            52478 non-null  object \n",
      " 17  numRatings        52478 non-null  int64  \n",
      " 18  ratingsByStars    52478 non-null  object \n",
      " 19  likedPercent      51856 non-null  float64\n",
      " 20  setting           52478 non-null  object \n",
      " 21  coverImg          51873 non-null  object \n",
      " 22  bbeScore          52478 non-null  int64  \n",
      " 23  bbeVotes          52478 non-null  int64  \n",
      " 24  price             38113 non-null  object \n",
      "dtypes: float64(2), int64(3), object(20)\n",
      "memory usage: 10.0+ MB\n",
      "None\n",
      "------------------------------------------------------------\n",
      "\n",
      "Columns with Missing Data: series, description, language, bookFormat, edition, pages, publisher, publishDate, firstPublishDate, likedPercent, coverImg, price\n",
      "\n",
      "Duplicate Rows: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>isbn</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>...</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052-the-hunger-games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2993816</td>\n",
       "      <td>30516</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>4.50</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n",
       "      <td>...</td>\n",
       "      <td>06/21/03</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98.0</td>\n",
       "      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2632233</td>\n",
       "      <td>26923</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>07/11/60</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>['Maycomb, Alabama (United States)']</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2269402</td>\n",
       "      <td>23328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        bookId  \\\n",
       "0                     2767052-the-hunger-games   \n",
       "1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n",
       "2                   2657.To_Kill_a_Mockingbird   \n",
       "\n",
       "                                       title                 series  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "\n",
       "                                      author  rating  \\\n",
       "0                            Suzanne Collins    4.33   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)    4.50   \n",
       "2                                 Harper Lee    4.28   \n",
       "\n",
       "                                         description language           isbn  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...  English  9780439023481   \n",
       "1  There is a door at the end of a silent corrido...  English  9780439358071   \n",
       "2  The unforgettable novel of a childhood in a sl...  English  9999999999999   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n",
       "2  ['Classics', 'Fiction', 'Historical Fiction', ...   \n",
       "\n",
       "                                          characters  ... firstPublishDate  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  ...              NaN   \n",
       "1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  ...         06/21/03   \n",
       "2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  ...         07/11/60   \n",
       "\n",
       "                                              awards numRatings  \\\n",
       "0  ['Locus Award Nominee for Best Young Adult Boo...    6376780   \n",
       "1  ['Bram Stoker Award for Works for Young Reader...    2507623   \n",
       "2  ['Pulitzer Prize for Fiction (1961)', 'Audie A...    4501075   \n",
       "\n",
       "                                      ratingsByStars likedPercent  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...         96.0   \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']         98.0   \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...         95.0   \n",
       "\n",
       "                                             setting  \\\n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...   \n",
       "1  ['Hogwarts School of Witchcraft and Wizardry (...   \n",
       "2               ['Maycomb, Alabama (United States)']   \n",
       "\n",
       "                                            coverImg  bbeScore bbeVotes  price  \n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...   2993816    30516   5.09  \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...   2632233    26923   7.38  \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...   2269402    23328    NaN  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bbe_url = 'https://raw.githubusercontent.com/scostap/goodreads_bbe_dataset/refs/heads/main/Best_Books_Ever_dataset/books_1.Best_Books_Ever.csv'\n",
    "bbe = load_and_inspect(bbe_url, 'Best Books Ever', show_head=True)\n",
    "# We'll preview the first few rows of the dataset to get an initial understanding of their structure and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa85b42",
   "metadata": {},
   "source": [
    "The dataset contains 52,478 records and 25 features, providing extensive coverage of book metadata, author details, and reader engagement metrics. Most core fields (title, author, rating, ISBN, genres) are complete and well-structured, indicating strong potential for content-based analysis.\n",
    "\n",
    "However, 12 columns exhibit missing data, mainly in auxiliary attributes such as series, book format, publisher, publication dates, and price, which may require selective imputation or exclusion in later cleaning. The presence of 50 duplicate rows suggests minor redundancy that should be addressed during the Data Preparation phase. Overall, the dataset is rich and comprehensive, with data quality issues confined to non-critical metadata fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600a6dd",
   "metadata": {},
   "source": [
    "## Overlap Inspection\n",
    "After loading the datasets, it is important to inspect the overlap between them to ensure consistency and identify potential integration points for analysis. We will check for common `book_id` values between the Goodbooks-10k and Best Books Ever datasets.\n",
    "\n",
    "This will ensure that we are able to simulate user interactions on a subscription platform while validating book popularity across a broader market context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b2d6b",
   "metadata": {},
   "source": [
    "### Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b416c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric identifiers from the 'bookId' string column in the Best Books Ever dataset\n",
    "bbe['bookId_num'] = (\n",
    "    bbe['bookId']                   # Access the bookId column\n",
    "    .astype(str)                    # Ensure the data is treated as strings\n",
    "    .str.extract(r'^(\\d+)[\\.-]')    # Extract leading digits before '.' or '-' using regex\n",
    "    .astype(float)                  # Convert the extracted strings to float \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97aecc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent numeric data types for key identifier columns in both datasets\n",
    "bbe['bookId_num'] = bbe['bookId_num'].astype(float)\n",
    "books['goodreads_book_id'] = books['goodreads_book_id'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf675f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask to identify overlapping book entries between the two datasets\n",
    "overlap_mask = bbe['bookId_num'].isin(books['goodreads_book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a963982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping IDs: 8039\n",
      "Percentage overlap (relative to Best Books Ever): 15.32%\n",
      "Percentage overlap (relative to Goodbooks-10k): 80.39%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number and percentage of overlapping book IDs between the two datasets\n",
    "overlap_count = overlap_mask.sum()\n",
    "\n",
    "# Percentage of overlap relative to Best Books Ever (bbe)\n",
    "overlap_pct_bbe = overlap_count / len(bbe) * 100\n",
    "\n",
    "# Percentage of overlap relative to Goodbooks-10k (books)\n",
    "overlap_pct_books = overlap_count / len(books) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of overlapping IDs: {overlap_count}\")\n",
    "print(f\"Percentage overlap (relative to Best Books Ever): {overlap_pct_bbe:.2f}%\")\n",
    "print(f\"Percentage overlap (relative to Goodbooks-10k): {overlap_pct_books:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d097d0",
   "metadata": {},
   "source": [
    "The overlap analysis reveals 8,039 shared book IDs between the **Best Books Ever** and **Goodbooks-10k datasets**, representing approximately 80% coverage of the **Goodbooks-10k** catalog and 15% coverage of the larger **Best Books Ever** collection. \n",
    "This represents a strong and realistic overlap for modeling purposes: the high proportion on the **Goodbooks** side ensures reliable alignment for simulating member-book interactions, while the lower proportion on the **BBE** side indicates a broader untapped catalog. \n",
    "This balance mirrors real-world dynamics in subscription platforms, where temporary licensing deals or curated partnerships cover a subset of available titles, leaving a substantial pool of additional books for potential recommendation expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e849e9",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "Data collection and initial inspection were successfully completed. The datasets together provide a strong foundation for analyzing book popularity, reader engagement, and cross-platform catalog alignment.\n",
    "\n",
    "- **Data Quality:** Most core fields (IDs, titles, authors, ratings) are complete and consistent.  \n",
    "  Missing data is mainly confined to secondary metadata such as publication details, ISBNs, and languages.  \n",
    "  Duplicate records were minimal and limited to the Best Books Ever dataset (50 entries).\n",
    "\n",
    "- **Schema Harmonization:** Book identifiers were standardized into numeric format to ensure compatibility across sources.  \n",
    "  This enables future merging of metadata and rating data into a unified analytical dataset.\n",
    "\n",
    "- **Cross-Dataset Overlap:** The overlap analysis revealed **8,039 shared titles**, covering **80% of Goodbooks-10k** and **15% of Best Books Ever**.  This reflects a realistic representation of shared catalog licensing, sufficient for simulation while leaving room for novel recommendations.\n",
    "\n",
    "- **Next Steps:**  \n",
    "  The upcoming **02_Data_Cleaning** notebook will focus on cleaning and transforming the data:\n",
    "  - Handling missing values and duplicates  \n",
    "  - Normalizing column types and naming conventions  \n",
    "  - (If needed) merging datasets based on books IDs to create a consolidated dataset for analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e0185",
   "metadata": {},
   "source": [
    "## Save Collected Data\n",
    "In this final section, we will save the collected datasets to CSV files for reproducibility and traceability in future steps including analysis and modeling stages of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9dfb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('data/books.csv', index=False)\n",
    "ratings.to_csv('data/ratings.csv', index=False)\n",
    "bbe.to_csv('data/bbe_books.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
