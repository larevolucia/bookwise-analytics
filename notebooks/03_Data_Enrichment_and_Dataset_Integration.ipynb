{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d6a58f",
   "metadata": {},
   "source": [
    "# Data Enrichment & Dataset Integration\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The purpose of this notebook is to **enrich, align, and integrate the cleaned datasets** to create a unified analytical foundation for modelling book satisfaction and evaluating catalogue diversity.\n",
    "\n",
    "This notebook expands upon prior cleaning work by **adding missing metadata, linking overlapping records across datasets, filtering the dataset to English-language titles, and preparing a model-ready dataset** that combines catalog-level information (BBE) with user-behavioral data (Goodbooks).\n",
    "\n",
    "Ultimately, this notebook enables insights that neither dataset could provide independently, most critically, **genre diversity analysis**, **language-based consistency**, **metadata-enhanced prediction modeling**.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "| Dataset                             | Source                     | Description                                                                                         | Format |\n",
    "| ----------------------------------- | -------------------------- | --------------------------------------------------------------------------------------------------- | ------ |\n",
    "| `bbe_clean_v13.csv`                  | Output from Notebook 02    | Cleaned *Best Books Ever* metadata including title, authors, genres, rating, description, and more. | CSV    |\n",
    "| `books_clean_v7.csv`      | Output from Notebook 02    | Cleaned Goodbooks-10k metadata lacking genre data but containing structural identifiers.            | CSV    |\n",
    "| `ratings_clean_v1.csv`    | Output from Notebook 02    | User–book interaction and aggregated rating data for behavioral modeling.                           | CSV    |\n",
    "| *(Optional)* External API responses | OpenLibrary / Google Books | Supplemental metadata (genres, languages, subjects) for non-overlapping titles.                     | JSON   |\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks in This Notebook\n",
    "\n",
    "This notebook will execute the following enrichment and integration steps:\n",
    "\n",
    "1. **Standardize linking identifiers**\n",
    "   Normalize `isbn_clean`, `goodreads_id`, `title_clean`, and `author_clean` across datasets to ensure reliable cross-dataset merging.\n",
    "\n",
    "2. **Identify overlap between BBE and Goodbooks**\n",
    "   Detect books present in both datasets using multi-key matching and evaluate match quality.\n",
    "\n",
    "3. **Enrich Goodbooks metadata with missing genres**\n",
    "\n",
    "   * Use BBE genre fields for overlapping titles.\n",
    "   * Query external APIs for non-overlapping titles.\n",
    "   * Normalize all genre outputs into a unified taxonomy.\n",
    "\n",
    "4. **Complete and standardize language metadata**\n",
    "   Fill missing values using BBE, APIs, or text-based heuristics, then harmonize language labels and codes.\n",
    "\n",
    "5. **Filter the enriched datasets to English-language books**\n",
    "   Restrict the unified dataset to titles identified as **English-language**, ensuring consistency for:\n",
    "\n",
    "   * genre diversity comparisons\n",
    "   * ratings behavior\n",
    "   * regression modeling\n",
    "\n",
    "   *(Non-English titles will be kept only in the enriched BBE/Goodbooks outputs, but excluded from the model dataset.)*\n",
    "\n",
    "6. **Integrate datasets into a unified model-ready schema**\n",
    "   Combine BBE metadata with Goodbooks behavioral features for all overlapping **English-language** books.\n",
    "\n",
    "7. **Validate enrichment and filtering results**\n",
    "\n",
    "   * Assess genre and language fill rates\n",
    "   * Review API match and success metrics\n",
    "   * Log all imputation and filtering decisions for reproducibility\n",
    "\n",
    "8. **Export enriched and unified datasets**\n",
    "   Produce final English-filtered datasets ready for modeling and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* **BBE_clean_enriched.csv** — enriched metadata for all BBE books\n",
    "* **Goodbooks_books_clean_enriched.csv** — enriched metadata for all Goodbooks books\n",
    "* **model_dataset_overlap_en_only.csv** — unified metadata + behavioral dataset filtered to English-language books\n",
    "* **Enrichment and filtering logs** — documenting imputation sources, API usage, and filtering decisions\n",
    "\n",
    "> **Note:** This notebook focuses on **metadata enrichment, English-language filtering, and dataset integration**. Model development and feature engineering will be performed in later notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09815b66",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "## Navigate to the Parent Directory\n",
    "\n",
    "Before combining and saving datasets, it’s often helpful to move to a parent directory so that file operations (like loading or saving data) are easier and more organized. \n",
    "\n",
    "Before using the Python’s built-in os module to move one level up from the current working directory, it is advisable to inspect the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19d6dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f'Current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2117d",
   "metadata": {},
   "source": [
    "To change to parent directory (root folder), run the code below. If you are already in the root folder, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fc58fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to parent.\n",
      "New current directory: c:\\Users\\reisl\\OneDrive\\Documents\\GitHub\\bookwise-analytics\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to its parent\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Changed directory to parent.')\n",
    "\n",
    "# Get the new current working directory (the parent directory)\n",
    "current_dir = os.getcwd()\n",
    "print(f'New current directory: {current_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee7f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cleaning.utils.categories import (\n",
    "    map_subjects_to_genres\n",
    ")\n",
    "from src.cleaning.utils.pipeline import apply_cleaners_selectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b908b97",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install additional packages for this notebook\n",
    "! pip install requests python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4cc03",
   "metadata": {},
   "source": [
    "## Load and Inspect Datasets\n",
    "\n",
    "In this step, we load the previously cleaned datasets: **Goodbooks-10k** (books, ratings) and **Best Books Ever**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770d789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBE dataset columns:\n",
      "['goodreads_id_clean', 'authors_list', 'author_clean', 'title_clean', 'isbn_clean', 'language_clean', 'publication_date_clean', 'publisher_clean', 'is_major_publisher', 'bookFormat_clean', 'rating_clean', 'numRatings_clean', 'numRatings_log', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'ratings_1_share', 'ratings_2_share', 'ratings_3_share', 'ratings_4_share', 'ratings_5_share', 'has_award', 'genres_clean', 'genres_simplified', 'description_clean', 'description_nlp', 'series_clean', 'pages_clean', 'bbeVotes_clean', 'bbeScore_clean', 'likedPercent_clean', 'has_likedPercent', 'price_clean', 'price_flag']\n",
      "BBE dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52424 entries, 0 to 52423\n",
      "Data columns (total 36 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   goodreads_id_clean      52424 non-null  string \n",
      " 1   authors_list            52424 non-null  object \n",
      " 2   author_clean            52424 non-null  object \n",
      " 3   title_clean             52424 non-null  object \n",
      " 4   isbn_clean              43338 non-null  string \n",
      " 5   language_clean          48413 non-null  object \n",
      " 6   publication_date_clean  46983 non-null  object \n",
      " 7   publisher_clean         48725 non-null  object \n",
      " 8   is_major_publisher      52424 non-null  bool   \n",
      " 9   bookFormat_clean        52424 non-null  object \n",
      " 10  rating_clean            52353 non-null  float64\n",
      " 11  numRatings_clean        52424 non-null  int64  \n",
      " 12  numRatings_log          52424 non-null  float64\n",
      " 13  ratings_1               52353 non-null  float64\n",
      " 14  ratings_2               52353 non-null  float64\n",
      " 15  ratings_3               52353 non-null  float64\n",
      " 16  ratings_4               52353 non-null  float64\n",
      " 17  ratings_5               52353 non-null  float64\n",
      " 18  ratings_1_share         52353 non-null  float64\n",
      " 19  ratings_2_share         52353 non-null  float64\n",
      " 20  ratings_3_share         52353 non-null  float64\n",
      " 21  ratings_4_share         52353 non-null  float64\n",
      " 22  ratings_5_share         52353 non-null  float64\n",
      " 23  has_award               52424 non-null  bool   \n",
      " 24  genres_clean            47804 non-null  object \n",
      " 25  genres_simplified       52424 non-null  object \n",
      " 26  description_clean       50268 non-null  object \n",
      " 27  description_nlp         50268 non-null  object \n",
      " 28  series_clean            23441 non-null  object \n",
      " 29  pages_clean             49747 non-null  float64\n",
      " 30  bbeVotes_clean          52424 non-null  int64  \n",
      " 31  bbeScore_clean          52424 non-null  int64  \n",
      " 32  likedPercent_clean      51803 non-null  float64\n",
      " 33  has_likedPercent        52424 non-null  int64  \n",
      " 34  price_clean             38068 non-null  float64\n",
      " 35  price_flag              52424 non-null  bool   \n",
      "dtypes: bool(3), float64(15), int64(4), object(12), string(2)\n",
      "memory usage: 13.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBE dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_id_clean</th>\n",
       "      <th>authors_list</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>isbn_clean</th>\n",
       "      <th>language_clean</th>\n",
       "      <th>publication_date_clean</th>\n",
       "      <th>publisher_clean</th>\n",
       "      <th>is_major_publisher</th>\n",
       "      <th>bookFormat_clean</th>\n",
       "      <th>...</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>description_nlp</th>\n",
       "      <th>series_clean</th>\n",
       "      <th>pages_clean</th>\n",
       "      <th>bbeVotes_clean</th>\n",
       "      <th>bbeScore_clean</th>\n",
       "      <th>likedPercent_clean</th>\n",
       "      <th>has_likedPercent</th>\n",
       "      <th>price_clean</th>\n",
       "      <th>price_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "      <td>['suzanne collins']</td>\n",
       "      <td>suzanne collins</td>\n",
       "      <td>the hunger games</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>en</td>\n",
       "      <td>2008-09-14</td>\n",
       "      <td>scholastic</td>\n",
       "      <td>True</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>winning means fame and fortunelosing means cer...</td>\n",
       "      <td>winning means fame and fortunelosing means cer...</td>\n",
       "      <td>the hunger games</td>\n",
       "      <td>374.0</td>\n",
       "      <td>30516</td>\n",
       "      <td>2993816</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['jk rowling', 'mary grandpre']</td>\n",
       "      <td>jk rowling, mary grandpre</td>\n",
       "      <td>harry potter and the order of the phoenix</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>en</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>scholastic</td>\n",
       "      <td>True</td>\n",
       "      <td>paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>there is a door at the end of a silent corrido...</td>\n",
       "      <td>there is a door at the end of a silent corrido...</td>\n",
       "      <td>harry potter</td>\n",
       "      <td>870.0</td>\n",
       "      <td>26923</td>\n",
       "      <td>2632233</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657</td>\n",
       "      <td>['harper lee']</td>\n",
       "      <td>harper lee</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>harpercollins</td>\n",
       "      <td>True</td>\n",
       "      <td>paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>the unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>the unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>324.0</td>\n",
       "      <td>23328</td>\n",
       "      <td>2269402</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  goodreads_id_clean                     authors_list  \\\n",
       "0            2767052              ['suzanne collins']   \n",
       "1                  2  ['jk rowling', 'mary grandpre']   \n",
       "2               2657                   ['harper lee']   \n",
       "\n",
       "                author_clean                                title_clean  \\\n",
       "0            suzanne collins                           the hunger games   \n",
       "1  jk rowling, mary grandpre  harry potter and the order of the phoenix   \n",
       "2                 harper lee                      to kill a mockingbird   \n",
       "\n",
       "      isbn_clean language_clean publication_date_clean publisher_clean  \\\n",
       "0  9780439023481             en             2008-09-14      scholastic   \n",
       "1  9780439358071             en             2003-06-21      scholastic   \n",
       "2           <NA>             en                    NaN   harpercollins   \n",
       "\n",
       "   is_major_publisher bookFormat_clean  ...  \\\n",
       "0                True        hardcover  ...   \n",
       "1                True        paperback  ...   \n",
       "2                True        paperback  ...   \n",
       "\n",
       "                                   description_clean  \\\n",
       "0  winning means fame and fortunelosing means cer...   \n",
       "1  there is a door at the end of a silent corrido...   \n",
       "2  the unforgettable novel of a childhood in a sl...   \n",
       "\n",
       "                                     description_nlp           series_clean  \\\n",
       "0  winning means fame and fortunelosing means cer...       the hunger games   \n",
       "1  there is a door at the end of a silent corrido...           harry potter   \n",
       "2  the unforgettable novel of a childhood in a sl...  to kill a mockingbird   \n",
       "\n",
       "   pages_clean  bbeVotes_clean  bbeScore_clean  likedPercent_clean  \\\n",
       "0        374.0           30516         2993816                96.0   \n",
       "1        870.0           26923         2632233                98.0   \n",
       "2        324.0           23328         2269402                95.0   \n",
       "\n",
       "   has_likedPercent  price_clean  price_flag  \n",
       "0                 1         5.09       False  \n",
       "1                 1         7.38       False  \n",
       "2                 1          NaN        True  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books dataset columns:\n",
      "['book_id', 'work_text_reviews_count', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'goodreads_id_clean', 'best_book_id_clean', 'work_id_clean', 'authors_list', 'author_clean', 'language_clean', 'publication_date_clean', 'isbn_clean', 'isbn13_clean', 'rating_clean', 'numRatings_clean', 'numRatings_log', 'ratings_1_share', 'ratings_2_share', 'ratings_3_share', 'ratings_4_share', 'ratings_5_share', 'work_text_reviews_log', 'series_clean', 'title_clean']\n",
      "Books dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   book_id                  10000 non-null  int64  \n",
      " 1   work_text_reviews_count  10000 non-null  int64  \n",
      " 2   ratings_1                10000 non-null  int64  \n",
      " 3   ratings_2                10000 non-null  int64  \n",
      " 4   ratings_3                10000 non-null  int64  \n",
      " 5   ratings_4                10000 non-null  int64  \n",
      " 6   ratings_5                10000 non-null  int64  \n",
      " 7   goodreads_id_clean       10000 non-null  string \n",
      " 8   best_book_id_clean       10000 non-null  int64  \n",
      " 9   work_id_clean            10000 non-null  int64  \n",
      " 10  authors_list             10000 non-null  object \n",
      " 11  author_clean             10000 non-null  object \n",
      " 12  language_clean           8916 non-null   object \n",
      " 13  publication_date_clean   9887 non-null   object \n",
      " 14  isbn_clean               8251 non-null   string \n",
      " 15  isbn13_clean             9415 non-null   float64\n",
      " 16  rating_clean             10000 non-null  float64\n",
      " 17  numRatings_clean         10000 non-null  int64  \n",
      " 18  numRatings_log           10000 non-null  float64\n",
      " 19  ratings_1_share          10000 non-null  float64\n",
      " 20  ratings_2_share          10000 non-null  float64\n",
      " 21  ratings_3_share          10000 non-null  float64\n",
      " 22  ratings_4_share          10000 non-null  float64\n",
      " 23  ratings_5_share          10000 non-null  float64\n",
      " 24  work_text_reviews_log    10000 non-null  float64\n",
      " 25  series_clean             3947 non-null   object \n",
      " 26  title_clean              10000 non-null  object \n",
      "dtypes: float64(9), int64(10), object(6), string(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>goodreads_id_clean</th>\n",
       "      <th>best_book_id_clean</th>\n",
       "      <th>work_id_clean</th>\n",
       "      <th>...</th>\n",
       "      <th>numRatings_clean</th>\n",
       "      <th>numRatings_log</th>\n",
       "      <th>ratings_1_share</th>\n",
       "      <th>ratings_2_share</th>\n",
       "      <th>ratings_3_share</th>\n",
       "      <th>ratings_4_share</th>\n",
       "      <th>ratings_5_share</th>\n",
       "      <th>work_text_reviews_log</th>\n",
       "      <th>series_clean</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>...</td>\n",
       "      <td>4942365</td>\n",
       "      <td>15.413355</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.113325</td>\n",
       "      <td>0.299716</td>\n",
       "      <td>0.547575</td>\n",
       "      <td>11.952824</td>\n",
       "      <td>the hunger games</td>\n",
       "      <td>the hunger games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>...</td>\n",
       "      <td>4800065</td>\n",
       "      <td>15.384140</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>0.021182</td>\n",
       "      <td>0.094795</td>\n",
       "      <td>0.240896</td>\n",
       "      <td>0.627396</td>\n",
       "      <td>11.236750</td>\n",
       "      <td>harry potter</td>\n",
       "      <td>harry potter and the sorcerer's stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>...</td>\n",
       "      <td>3916824</td>\n",
       "      <td>15.180792</td>\n",
       "      <td>0.116470</td>\n",
       "      <td>0.111519</td>\n",
       "      <td>0.202541</td>\n",
       "      <td>0.223414</td>\n",
       "      <td>0.346056</td>\n",
       "      <td>11.461737</td>\n",
       "      <td>twilight</td>\n",
       "      <td>twilight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  work_text_reviews_count  ratings_1  ratings_2  ratings_3  \\\n",
       "0        1                   155254      66715     127936     560092   \n",
       "1        2                    75867      75504     101676     455024   \n",
       "2        3                    95009     456191     436802     793319   \n",
       "\n",
       "   ratings_4  ratings_5 goodreads_id_clean  best_book_id_clean  work_id_clean  \\\n",
       "0    1481305    2706317            2767052             2767052        2792775   \n",
       "1    1156318    3011543                  3                   3        4640799   \n",
       "2     875073    1355439              41865               41865        3212258   \n",
       "\n",
       "   ... numRatings_clean numRatings_log ratings_1_share ratings_2_share  \\\n",
       "0  ...          4942365      15.413355        0.013499        0.025886   \n",
       "1  ...          4800065      15.384140        0.015730        0.021182   \n",
       "2  ...          3916824      15.180792        0.116470        0.111519   \n",
       "\n",
       "  ratings_3_share  ratings_4_share  ratings_5_share  work_text_reviews_log  \\\n",
       "0        0.113325         0.299716         0.547575              11.952824   \n",
       "1        0.094795         0.240896         0.627396              11.236750   \n",
       "2        0.202541         0.223414         0.346056              11.461737   \n",
       "\n",
       "       series_clean                            title_clean  \n",
       "0  the hunger games                       the hunger games  \n",
       "1      harry potter  harry potter and the sorcerer's stone  \n",
       "2          twilight                               twilight  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings dataset columns:\n",
      "['user_id', 'book_id', 'rating']\n",
      "Ratings dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5976479 entries, 0 to 5976478\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype\n",
      "---  ------   -----\n",
      " 0   user_id  int64\n",
      " 1   book_id  int64\n",
      " 2   rating   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 136.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# load datasets\n",
    "books_clean = pd.read_csv(\n",
    "    'data/interim/goodbooks/books_clean_v7.csv',\n",
    "    dtype={\"isbn_clean\": \"string\", \"goodreads_id_clean\": \"string\"}\n",
    "    )\n",
    "ratings_clean = pd.read_csv('data/interim/goodbooks/ratings_clean_v1.csv')\n",
    "bbe_clean = pd.read_csv(\n",
    "    \"data/interim/bbe/bbe_clean_v13.csv\",\n",
    "    dtype={\"isbn_clean\": \"string\", \"goodreads_id_clean\": \"string\"}\n",
    ")\n",
    "\n",
    "# create copies for imputation\n",
    "books_impute = books_clean.copy()\n",
    "ratings_impute = ratings_clean.copy()\n",
    "bbe_impute = bbe_clean.copy()\n",
    "\n",
    "# log samples\n",
    "print(\"BBE dataset columns:\")\n",
    "print(bbe_impute.columns.tolist())\n",
    "print(\"BBE dataset info:\")\n",
    "display(bbe_impute.info())\n",
    "print(\"BBE dataset sample:\")\n",
    "display(bbe_impute.head(3))\n",
    "\n",
    "print(\"Books dataset columns:\")\n",
    "print(books_impute.columns.tolist())\n",
    "print(\"Books dataset info:\")\n",
    "display(books_impute.info())\n",
    "print(\"Books dataset sample:\")\n",
    "display(books_impute.head(3))\n",
    "\n",
    "print(\"Ratings dataset columns:\")\n",
    "print(ratings_impute.columns.tolist())\n",
    "print(\"Ratings dataset info:\")\n",
    "display(ratings_impute.info())\n",
    "print(\"Ratings dataset sample:\")\n",
    "display(ratings_impute.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cff995",
   "metadata": {},
   "source": [
    "# Data Enrichment\n",
    "\n",
    "## Enriching Goodbooks with Genre and Page Count\n",
    "\n",
    "### From BBE overlap\n",
    "\n",
    "To improve the completeness and quality of the Goodbooks-10k dataset, we selectively merge in metadata from the Best Books Ever (BBE) dataset using the shared `goodreads_id_clean` key. Goodbooks is kept as the primary source, while BBE is used to supply additional metadata fields, such as genres and page counts, as well as to fill in missing values for shared attributes like ISBN, publication date, and series.\n",
    "\n",
    "This approach ensures we enhance Goodbooks only where necessary: adding new information where it is absent and completing incomplete entries without overwriting existing data. The resulting `gb_enriched` dataset combines both sources into a more reliable and feature-rich foundation for downstream analytics and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6d0cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ENRICHING METADATA ---\n",
      "pages_clean: filled 8053 rows from BBE\n",
      "genres_clean: filled 8082 rows from BBE\n",
      "genres_simplified: filled 8082 rows from BBE\n",
      "publisher_clean: filled 7954 rows from BBE\n",
      "is_major_publisher: filled 8082 rows from BBE\n",
      "has_award: filled 8082 rows from BBE\n",
      "description_clean: filled 8009 rows from BBE\n",
      "description_nlp: filled 8009 rows from BBE\n",
      "\n",
      "--- ENRICHING SHARED COLUMNS (GB NaN -> fill from BBE) ---\n",
      "publication_date_clean: filled 68 missing values\n",
      "series_clean: filled 1133 missing values\n",
      "isbn_clean: filled 984 missing values\n",
      "language_clean: filled 684 missing values\n",
      "\n",
      "Enrichment complete!\n",
      "Final shape: (10000, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>series_clean</th>\n",
       "      <th>genres_clean</th>\n",
       "      <th>genres_simplified</th>\n",
       "      <th>pages_clean</th>\n",
       "      <th>publication_date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0439023483</td>\n",
       "      <td>the hunger games</td>\n",
       "      <td>the hunger games</td>\n",
       "      <td>['young adult', 'fiction', 'dystopia', 'fantas...</td>\n",
       "      <td>['young adult', 'fiction', 'dystopia', 'fantas...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>2008-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439554934</td>\n",
       "      <td>harry potter and the sorcerer's stone</td>\n",
       "      <td>harry potter</td>\n",
       "      <td>['fantasy', 'fiction', 'young adult', 'magic',...</td>\n",
       "      <td>['fantasy', 'fiction', 'young adult', 'magic',...</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1997-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0316015849</td>\n",
       "      <td>twilight</td>\n",
       "      <td>twilight</td>\n",
       "      <td>['young adult', 'fantasy', 'romance', 'vampire...</td>\n",
       "      <td>['young adult', 'fantasy', 'romance', 'vampire...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>['classics', 'fiction', 'historical fiction', ...</td>\n",
       "      <td>['classics', 'fiction', 'historical fiction', ...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1960-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0743273567</td>\n",
       "      <td>the great gatsby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['classics', 'fiction', 'school', 'literature'...</td>\n",
       "      <td>['classics', 'fiction', 'school', 'literature'...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1925-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isbn_clean                            title_clean           series_clean  \\\n",
       "0  0439023483                       the hunger games       the hunger games   \n",
       "1  0439554934  harry potter and the sorcerer's stone           harry potter   \n",
       "2  0316015849                               twilight               twilight   \n",
       "3        <NA>                  to kill a mockingbird  to kill a mockingbird   \n",
       "4  0743273567                       the great gatsby                    NaN   \n",
       "\n",
       "                                        genres_clean  \\\n",
       "0  ['young adult', 'fiction', 'dystopia', 'fantas...   \n",
       "1  ['fantasy', 'fiction', 'young adult', 'magic',...   \n",
       "2  ['young adult', 'fantasy', 'romance', 'vampire...   \n",
       "3  ['classics', 'fiction', 'historical fiction', ...   \n",
       "4  ['classics', 'fiction', 'school', 'literature'...   \n",
       "\n",
       "                                   genres_simplified  pages_clean  \\\n",
       "0  ['young adult', 'fiction', 'dystopia', 'fantas...        374.0   \n",
       "1  ['fantasy', 'fiction', 'young adult', 'magic',...        309.0   \n",
       "2  ['young adult', 'fantasy', 'romance', 'vampire...        501.0   \n",
       "3  ['classics', 'fiction', 'historical fiction', ...        324.0   \n",
       "4  ['classics', 'fiction', 'school', 'literature'...        200.0   \n",
       "\n",
       "  publication_date_clean  \n",
       "0             2008-01-01  \n",
       "1             1997-01-01  \n",
       "2             2005-01-01  \n",
       "3             1960-01-01  \n",
       "4             1925-01-01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# ENRICH GOODBOOKS (books_impute) WITH BBE DATA\n",
    "# ---------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# columns to enrich ONLY when GB has NaN\n",
    "columns_to_enrich = [\n",
    "    \"publication_date_clean\",\n",
    "    \"series_clean\",\n",
    "    \"isbn_clean\",\n",
    "    \"language_clean\"\n",
    "    ]\n",
    "\n",
    "# columns existent only in BBE\n",
    "bbe_only_columns = [\n",
    "    \"pages_clean\",\n",
    "    \"genres_clean\",\n",
    "    \"genres_simplified\",\n",
    "    \"publisher_clean\",\n",
    "    \"is_major_publisher\",\n",
    "    \"has_award\",\n",
    "    \"description_clean\",\n",
    "    \"description_nlp\"\n",
    "]\n",
    "\n",
    "# merge Goodbooks with the needed BBE columns\n",
    "merge_cols = [\"goodreads_id_clean\"] + columns_to_enrich + bbe_only_columns\n",
    "\n",
    "gb_enriched = books_impute.merge(\n",
    "    bbe_impute[merge_cols].add_suffix(\"_bbe\"),\n",
    "    left_on=\"goodreads_id_clean\",\n",
    "    right_on=\"goodreads_id_clean_bbe\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ENRICH GENRE COLUMNS\n",
    "# ---------------------------------------------\n",
    "print(\"\\n--- ENRICHING METADATA ---\")\n",
    "for col in bbe_only_columns:\n",
    "    gb_enriched[col] = gb_enriched[col + \"_bbe\"]\n",
    "    filled = gb_enriched[col].notna().sum()\n",
    "    print(f\"{col}: filled {filled} rows from BBE\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ENRICH SHARED COLUMNS ONLY WHERE GB IS NaN\n",
    "# ---------------------------------------------\n",
    "print(\"\\n--- ENRICHING SHARED COLUMNS (GB NaN -> fill from BBE) ---\")\n",
    "for col in columns_to_enrich:\n",
    "    before = gb_enriched[col].isna().sum()\n",
    "    gb_enriched[col] = gb_enriched[col].fillna(gb_enriched[col + \"_bbe\"])\n",
    "    after = gb_enriched[col].isna().sum()\n",
    "    print(f\"{col}: filled {before - after} missing values\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# CLEANUP\n",
    "# ---------------------------------------------\n",
    "gb_enriched = gb_enriched.drop(columns=[c for c in gb_enriched.columns if c.endswith(\"_bbe\")])\n",
    "\n",
    "print(\"\\nEnrichment complete!\")\n",
    "print(\"Final shape:\", gb_enriched.shape)\n",
    "gb_enriched[['isbn_clean','title_clean', 'series_clean', 'genres_clean', 'genres_simplified', 'pages_clean', 'publication_date_clean']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d474378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb_enriched v1 saved successfully in data/interim/merge directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "file_name = 'gb_enriched'\n",
    "clean_merge_path = Path(\"data/cleaned/merge\")\n",
    "clean_merge_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "version = 1\n",
    "\n",
    "gb_enriched.to_csv(clean_merge_path / f\"{file_name}_v{version}.csv\", index=False)\n",
    "\n",
    "print(f\"{file_name} v{version} saved successfully in data/interim/merge directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ead17c",
   "metadata": {},
   "source": [
    "### From external APIs\n",
    "\n",
    "To further enrich the Goodbooks-10k dataset, we leverage external APIs such as OpenLibrary and Google Books to fill in missing metadata for titles not covered by the BBE overlap. This process involves querying these APIs using available identifiers (like ISBN or title/author combinations) to retrieve additional information such as genres, page counts, and publication details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977a465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_isbn(isbn):\n",
    "    if not isinstance(isbn, str):\n",
    "        return None\n",
    "    isbn = re.sub(r'[^0-9Xx]', '', isbn)\n",
    "    if len(isbn) in [10, 13]:\n",
    "        return isbn\n",
    "    return None\n",
    "\n",
    "gb_enriched['isbn_query'] = gb_enriched['isbn_clean'].apply(clean_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee431a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books needing external enrichment: 2249\n"
     ]
    }
   ],
   "source": [
    "missing_mask = (\n",
    "    gb_enriched['language_clean'].isna() |\n",
    "    gb_enriched['language_clean'].isin(['unknown', '', 'None']) |\n",
    "    gb_enriched['pages_clean'].isna() |\n",
    "    gb_enriched['publication_date_clean'].isna()  |\n",
    "    gb_enriched['publisher_clean'].isna() |\n",
    "    gb_enriched['description_clean'].isna()\n",
    ")\n",
    "\n",
    "to_impute = gb_enriched[missing_mask].copy()\n",
    "print(\"Books needing external enrichment:\", len(to_impute))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ab95c",
   "metadata": {},
   "source": [
    "#### Querying OpenLibrary API\n",
    "\n",
    "After enriching Goodbooks with BBE overlap data, we identify **2,249** books still missing critical metadata (ISBN, language, pages, publication date, publisher). We query **OpenLibrary first** because it has no rate limits or API key requirements, making it ideal for bulk enrichment. We create a boolean mask to identify books needing enrichment, then query OpenLibrary's ISBN endpoint for each book, collecting results in a structured format.\n",
    "\n",
    "The results are merged back into `gb_enriched` and saved as **version 2**. This incremental saving strategy ensures we don't lose progress if subsequent API calls fail or exceed quotas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b963e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing cache found, starting fresh\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# cache path for OpenLibrary in data/raw\n",
    "OL_CACHE_PATH = Path(\"data/raw/openlibrary_api_cache.json\")\n",
    "\n",
    "# create directory if it doesn't exist\n",
    "OL_CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# load existing cache if it exists\n",
    "if OL_CACHE_PATH.exists():\n",
    "    with open(OL_CACHE_PATH, \"r\") as f:\n",
    "        ol_cache = json.load(f)\n",
    "    print(f\"Loaded {len(ol_cache)} cached OpenLibrary entries\")\n",
    "else:\n",
    "    ol_cache = {}\n",
    "    print(\"No existing cache found, starting fresh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5278cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def query_openlibrary(isbn):\n",
    "    \"\"\"Return OL metadata in a consistent dict format.\"\"\"\n",
    "\n",
    "    isbn_str = str(isbn)\n",
    "    \n",
    "    if isbn_str in ol_cache:\n",
    "        return ol_cache[isbn_str]\n",
    "    \n",
    "    # Default structure to guarantee stable DataFrame columns\n",
    "    result = {\n",
    "        \"pages_openlib\": None,\n",
    "        \"publication_date_openlib\": None,\n",
    "        \"language_openlib\": None,\n",
    "        \"subjects_openlib\": None,\n",
    "        \"publisher_openlib\": None, \n",
    "        \"description_openlib\": None, \n",
    "    }\n",
    "\n",
    "    if isbn is None or pd.isna(isbn) or isbn == \"\":\n",
    "        return result\n",
    "    \n",
    "    url = f\"https://openlibrary.org/isbn/{isbn}.json\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            return result\n",
    "\n",
    "        data = r.json()\n",
    "\n",
    "        # Pages\n",
    "        result[\"pages_openlib\"] = data.get(\"number_of_pages\")\n",
    "\n",
    "        # Publication date\n",
    "        result[\"publication_date_openlib\"] = data.get(\"publish_date\")\n",
    "\n",
    "        # Language\n",
    "        if \"languages\" in data and isinstance(data[\"languages\"], list):\n",
    "            key = data[\"languages\"][0].get(\"key\", \"\").split(\"/\")[-1]\n",
    "            result[\"language_openlib\"] = key\n",
    "\n",
    "        # Subjects\n",
    "        if \"subjects\" in data:\n",
    "            result[\"subjects_openlib\"] = [s.lower() for s in data[\"subjects\"]]\n",
    "        \n",
    "        # Publisher\n",
    "        if \"publishers\" in data and isinstance(data[\"publishers\"], list):\n",
    "            result[\"publisher_openlib\"] = data[\"publishers\"][0]\n",
    "        \n",
    "        # Description\n",
    "        desc = data.get(\"description\")\n",
    "        if isinstance(desc, dict):\n",
    "            result[\"description_openlib\"] = desc.get(\"value\")\n",
    "        elif isinstance(desc, str):\n",
    "            result[\"description_openlib\"] = desc\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        pass  # keep the default result structure\n",
    "\n",
    "    # Save to cache\n",
    "    ol_cache[isbn_str] = result\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ff9328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying OpenLibrary: 100%|██████████| 2249/2249 [42:47<00:00,  1.14s/it] \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for isbn in tqdm(to_impute['isbn_query'], desc=\"Querying OpenLibrary\"):\n",
    "    results.append(query_openlibrary(isbn))\n",
    "    time.sleep(0.2)   # safe rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API results summary:\n",
      "pages_openlib               1399\n",
      "publication_date_openlib    1737\n",
      "language_openlib            1472\n",
      "subjects_openlib            1046\n",
      "publisher_openlib           1689\n",
      "description_openlib          526\n",
      "dtype: int64\n",
      "\n",
      "After merge:\n",
      "pages_openlib               1399\n",
      "publication_date_openlib    1737\n",
      "language_openlib            1472\n",
      "subjects_openlib            1046\n",
      "publisher_openlib           1689\n",
      "description_openlib          526\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save OpenLibrary cache after queries\n",
    "with open(OL_CACHE_PATH, \"w\") as f:\n",
    "    json.dump(ol_cache, f, indent=2)\n",
    "print(f\"OpenLibrary cache saved with {len(ol_cache)} entries\")\n",
    "\n",
    "# convert results to dataframe\n",
    "ol_df = pd.DataFrame(results, index=to_impute.index)\n",
    "print(\"API results summary:\")\n",
    "print(ol_df.notna().sum())\n",
    "\n",
    "# merge back into gb_enriched\n",
    "for col in ol_df.columns:\n",
    "    if col not in gb_enriched.columns:\n",
    "        gb_enriched[col] = None\n",
    "    gb_enriched.loc[ol_df.index, col] = ol_df[col]\n",
    "\n",
    "# verify the merge\n",
    "print(\"\\nAfter merge:\")\n",
    "print(gb_enriched[ol_df.columns].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "156b39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb_enriched v2 saved successfully in data/interim/merge directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "file_name = 'gb_enriched'\n",
    "clean_merge_path = Path(\"data/cleaned/merge\")\n",
    "clean_merge_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "version = 2\n",
    "\n",
    "gb_enriched.to_csv(clean_merge_path / f\"{file_name}_v{version}.csv\", index=False)\n",
    "\n",
    "print(f\"{file_name} v{version} saved successfully in data/interim/merge directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a12d1a",
   "metadata": {},
   "source": [
    "#### Cleaning and Processing OpenLibrary Data\n",
    "\n",
    "We apply the same cleaning steps used in Notebook 02, compiled into a pipeline, to standardize OpenLibrary API responses. The `apply_cleaners_selectively()` function ensures consistent data types, formats, and validation across all metadata fields. After cleaning, we fill missing values in `gb_enriched` using the cleaned OpenLibrary data.\n",
    "\n",
    "For genre enrichment, we map OpenLibrary subjects to our standardized genre taxonomy using `map_subjects_to_genres()`. This populates `genres_simplified` for books that had subjects but no genre data, significantly improving genre coverage. The enriched dataset is saved as **version 3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a19072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of cleaned OpenLibrary data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>pages_clean</th>\n",
       "      <th>pages_openlib</th>\n",
       "      <th>pages_openlib_clean</th>\n",
       "      <th>publication_date_clean</th>\n",
       "      <th>publication_date_openlib</th>\n",
       "      <th>publication_date_openlib_clean</th>\n",
       "      <th>language_clean</th>\n",
       "      <th>language_openlib</th>\n",
       "      <th>language_openlib_clean</th>\n",
       "      <th>genres_clean</th>\n",
       "      <th>genres_simplified</th>\n",
       "      <th>subjects_openlib</th>\n",
       "      <th>subjects_openlib_clean</th>\n",
       "      <th>publisher_clean</th>\n",
       "      <th>description_openlib</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>description_openlib</th>\n",
       "      <th>description_openlib_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>scion of ikshvaku</td>\n",
       "      <td>354.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mythology', 'fiction', 'fantasy', 'indian li...</td>\n",
       "      <td>['mythology', 'fiction', 'fantasy', 'other', '...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>westland publication</td>\n",
       "      <td>None</td>\n",
       "      <td>ram rajya the perfect land but perfection has ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>canada</td>\n",
       "      <td>420.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['fiction', 'canada', 'literary fiction', 'con...</td>\n",
       "      <td>['fiction', 'other', 'literary fiction', 'cont...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>harpercollins</td>\n",
       "      <td>None</td>\n",
       "      <td>first i'll tell about the robbery our parents ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>the man in the brown suit</td>\n",
       "      <td>381.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1924-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mystery', 'fiction', 'crime', 'classics', 'm...</td>\n",
       "      <td>['mystery', 'fiction', 'crime', 'classics', 'm...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>harpercollins</td>\n",
       "      <td>None</td>\n",
       "      <td>newly-orphaned anne beddingfeld is a nice engl...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>twilight and philosophy vampires vegetarians a...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philosophy', 'nonfiction', 'vampires', 'essa...</td>\n",
       "      <td>['philosophy', 'nonfiction', 'vampires', 'essa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>wiley</td>\n",
       "      <td>None</td>\n",
       "      <td>the first look at the philosophy behind stephe...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>saga vol 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>September 15, 2015</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>en</td>\n",
       "      <td>eng</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[military deserters, parents of exceptional ch...</td>\n",
       "      <td>[military deserters, parents of exceptional ch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>asterix the gaul</td>\n",
       "      <td>48.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['comics', 'graphic novels', 'bande dessine', ...</td>\n",
       "      <td>['comics', 'graphic novels', 'other', 'fiction...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>orion books ltd, london</td>\n",
       "      <td>None</td>\n",
       "      <td>the year is 50 bc and all gaul is occupied onl...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>tuck everlasting</td>\n",
       "      <td>148.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['fantasy', 'young adult', 'classics', 'fictio...</td>\n",
       "      <td>['fantasy', 'young adult', 'classics', 'fictio...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>macmillan</td>\n",
       "      <td>None</td>\n",
       "      <td>doomed to - or blessed with - eternal life aft...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>domes of fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>May 29, 1993</td>\n",
       "      <td>1993-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eng</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[fiction - fantasy, fiction, fantasy, fantasy ...</td>\n",
       "      <td>[fiction - fantasy, fiction, fantasy, fantasy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>when we were orphans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>March 3, 2005</td>\n",
       "      <td>2005-03-03</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[modern fiction, fiction]</td>\n",
       "      <td>[modern fiction, fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>fall of giants</td>\n",
       "      <td>985.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['historical fiction', 'fiction', 'historical'...</td>\n",
       "      <td>['historical fiction', 'fiction', 'historical'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>penguin random house</td>\n",
       "      <td>None</td>\n",
       "      <td>this is an epic of love hatred war and revolut...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>trunk music</td>\n",
       "      <td>448.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mystery', 'fiction', 'crime', 'thriller', 'd...</td>\n",
       "      <td>['mystery', 'fiction', 'crime', 'thriller', 'd...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>st martins paperbacks</td>\n",
       "      <td>None</td>\n",
       "      <td>back on the job after an involuntary leave of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>maid for love</td>\n",
       "      <td>236.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['romance', 'contemporary romance', 'contempor...</td>\n",
       "      <td>['romance', 'contemporary romance', 'contempor...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>htjb, inc</td>\n",
       "      <td>None</td>\n",
       "      <td>maddie chester is determined to leave her home...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>the bloody chamber and other stories</td>\n",
       "      <td>128.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['short stories', 'fantasy', 'fiction', 'horro...</td>\n",
       "      <td>['short stories', 'fantasy', 'fiction', 'horro...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>penguin random house</td>\n",
       "      <td>None</td>\n",
       "      <td>in the bloody chamber - which includes the sto...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>criminal</td>\n",
       "      <td>448.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mystery', 'thriller', 'crime', 'fiction', 'm...</td>\n",
       "      <td>['mystery', 'thriller', 'crime', 'fiction', 'm...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dell</td>\n",
       "      <td>None</td>\n",
       "      <td>will trent is a brilliant agent with the georg...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>the kings of clonmel</td>\n",
       "      <td>320.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['fantasy', 'young adult', 'adventure', 'ficti...</td>\n",
       "      <td>['fantasy', 'young adult', 'adventure', 'ficti...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>penguin random house</td>\n",
       "      <td>None</td>\n",
       "      <td>when a cult springs up in neighboring clonmel ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_clean  pages_clean  \\\n",
       "6252                                  scion of ikshvaku        354.0   \n",
       "4684                                             canada        420.0   \n",
       "1731                          the man in the brown suit        381.0   \n",
       "4742  twilight and philosophy vampires vegetarians a...        259.0   \n",
       "4521                                         saga vol 5          NaN   \n",
       "6340                                   asterix the gaul         48.0   \n",
       "576                                    tuck everlasting        148.0   \n",
       "5202                                      domes of fire          NaN   \n",
       "6363                               when we were orphans          NaN   \n",
       "439                                      fall of giants        985.0   \n",
       "2750                                        trunk music        448.0   \n",
       "7487                                      maid for love        236.0   \n",
       "5272               the bloody chamber and other stories        128.0   \n",
       "5653                                           criminal        448.0   \n",
       "3999                               the kings of clonmel        320.0   \n",
       "\n",
       "     pages_openlib  pages_openlib_clean publication_date_clean  \\\n",
       "6252          None                  NaN             2015-01-01   \n",
       "4684          None                  NaN             2012-01-01   \n",
       "1731          None                  NaN             1924-01-01   \n",
       "4742          None                  NaN             2009-01-01   \n",
       "4521         152.0                152.0             2015-01-01   \n",
       "6340          None                  NaN             1960-01-01   \n",
       "576           None                  NaN             1975-01-01   \n",
       "5202         480.0                480.0             1992-01-01   \n",
       "6363         320.0                320.0             2000-01-01   \n",
       "439           None                  NaN             2010-01-01   \n",
       "2750          None                  NaN             1997-01-01   \n",
       "7487          None                  NaN             2011-01-01   \n",
       "5272          None                  NaN             1979-01-01   \n",
       "5653          None                  NaN             2012-01-01   \n",
       "3999          None                  NaN             2008-01-01   \n",
       "\n",
       "     publication_date_openlib publication_date_openlib_clean language_clean  \\\n",
       "6252                     None                            NaN             en   \n",
       "4684                     None                            NaN             en   \n",
       "1731                     None                            NaN             en   \n",
       "4742                     None                            NaN             en   \n",
       "4521       September 15, 2015                     2015-09-15             en   \n",
       "6340                     None                            NaN             en   \n",
       "576                      None                            NaN             en   \n",
       "5202             May 29, 1993                     1993-05-29            NaN   \n",
       "6363            March 3, 2005                     2005-03-03             en   \n",
       "439                      None                            NaN             en   \n",
       "2750                     None                            NaN             en   \n",
       "7487                     None                            NaN             en   \n",
       "5272                     None                            NaN             en   \n",
       "5653                     None                            NaN             en   \n",
       "3999                     None                            NaN             en   \n",
       "\n",
       "     language_openlib language_openlib_clean  \\\n",
       "6252             None                    NaN   \n",
       "4684             None                    NaN   \n",
       "1731             None                    NaN   \n",
       "4742             None                    NaN   \n",
       "4521              eng                     en   \n",
       "6340             None                    NaN   \n",
       "576              None                    NaN   \n",
       "5202              eng                     en   \n",
       "6363             None                    NaN   \n",
       "439              None                    NaN   \n",
       "2750             None                    NaN   \n",
       "7487             None                    NaN   \n",
       "5272             None                    NaN   \n",
       "5653             None                    NaN   \n",
       "3999             None                    NaN   \n",
       "\n",
       "                                           genres_clean  \\\n",
       "6252  ['mythology', 'fiction', 'fantasy', 'indian li...   \n",
       "4684  ['fiction', 'canada', 'literary fiction', 'con...   \n",
       "1731  ['mystery', 'fiction', 'crime', 'classics', 'm...   \n",
       "4742  ['philosophy', 'nonfiction', 'vampires', 'essa...   \n",
       "4521                                                NaN   \n",
       "6340  ['comics', 'graphic novels', 'bande dessine', ...   \n",
       "576   ['fantasy', 'young adult', 'classics', 'fictio...   \n",
       "5202                                                NaN   \n",
       "6363                                                NaN   \n",
       "439   ['historical fiction', 'fiction', 'historical'...   \n",
       "2750  ['mystery', 'fiction', 'crime', 'thriller', 'd...   \n",
       "7487  ['romance', 'contemporary romance', 'contempor...   \n",
       "5272  ['short stories', 'fantasy', 'fiction', 'horro...   \n",
       "5653  ['mystery', 'thriller', 'crime', 'fiction', 'm...   \n",
       "3999  ['fantasy', 'young adult', 'adventure', 'ficti...   \n",
       "\n",
       "                                      genres_simplified  \\\n",
       "6252  ['mythology', 'fiction', 'fantasy', 'other', '...   \n",
       "4684  ['fiction', 'other', 'literary fiction', 'cont...   \n",
       "1731  ['mystery', 'fiction', 'crime', 'classics', 'm...   \n",
       "4742  ['philosophy', 'nonfiction', 'vampires', 'essa...   \n",
       "4521                                                NaN   \n",
       "6340  ['comics', 'graphic novels', 'other', 'fiction...   \n",
       "576   ['fantasy', 'young adult', 'classics', 'fictio...   \n",
       "5202                                                NaN   \n",
       "6363                                                NaN   \n",
       "439   ['historical fiction', 'fiction', 'historical'...   \n",
       "2750  ['mystery', 'fiction', 'crime', 'thriller', 'd...   \n",
       "7487  ['romance', 'contemporary romance', 'contempor...   \n",
       "5272  ['short stories', 'fantasy', 'fiction', 'horro...   \n",
       "5653  ['mystery', 'thriller', 'crime', 'fiction', 'm...   \n",
       "3999  ['fantasy', 'young adult', 'adventure', 'ficti...   \n",
       "\n",
       "                                       subjects_openlib  \\\n",
       "6252                                               None   \n",
       "4684                                               None   \n",
       "1731                                               None   \n",
       "4742                                               None   \n",
       "4521  [military deserters, parents of exceptional ch...   \n",
       "6340                                               None   \n",
       "576                                                None   \n",
       "5202  [fiction - fantasy, fiction, fantasy, fantasy ...   \n",
       "6363                          [modern fiction, fiction]   \n",
       "439                                                None   \n",
       "2750                                               None   \n",
       "7487                                               None   \n",
       "5272                                               None   \n",
       "5653                                               None   \n",
       "3999                                               None   \n",
       "\n",
       "                                 subjects_openlib_clean  \\\n",
       "6252                                               None   \n",
       "4684                                               None   \n",
       "1731                                               None   \n",
       "4742                                               None   \n",
       "4521  [military deserters, parents of exceptional ch...   \n",
       "6340                                               None   \n",
       "576                                                None   \n",
       "5202  [fiction - fantasy, fiction, fantasy, fantasy ...   \n",
       "6363                          [modern fiction, fiction]   \n",
       "439                                                None   \n",
       "2750                                               None   \n",
       "7487                                               None   \n",
       "5272                                               None   \n",
       "5653                                               None   \n",
       "3999                                               None   \n",
       "\n",
       "              publisher_clean description_openlib  \\\n",
       "6252     westland publication                None   \n",
       "4684            harpercollins                None   \n",
       "1731            harpercollins                None   \n",
       "4742                    wiley                None   \n",
       "4521                      NaN                None   \n",
       "6340  orion books ltd, london                None   \n",
       "576                 macmillan                None   \n",
       "5202                      NaN                None   \n",
       "6363                      NaN                None   \n",
       "439      penguin random house                None   \n",
       "2750    st martins paperbacks                None   \n",
       "7487                htjb, inc                None   \n",
       "5272     penguin random house                None   \n",
       "5653                     dell                None   \n",
       "3999     penguin random house                None   \n",
       "\n",
       "                                      description_clean description_openlib  \\\n",
       "6252  ram rajya the perfect land but perfection has ...                None   \n",
       "4684  first i'll tell about the robbery our parents ...                None   \n",
       "1731  newly-orphaned anne beddingfeld is a nice engl...                None   \n",
       "4742  the first look at the philosophy behind stephe...                None   \n",
       "4521                                                NaN                None   \n",
       "6340  the year is 50 bc and all gaul is occupied onl...                None   \n",
       "576   doomed to - or blessed with - eternal life aft...                None   \n",
       "5202                                                NaN                None   \n",
       "6363                                                NaN                None   \n",
       "439   this is an epic of love hatred war and revolut...                None   \n",
       "2750  back on the job after an involuntary leave of ...                None   \n",
       "7487  maddie chester is determined to leave her home...                None   \n",
       "5272  in the bloody chamber - which includes the sto...                None   \n",
       "5653  will trent is a brilliant agent with the georg...                None   \n",
       "3999  when a cult springs up in neighboring clonmel ...                None   \n",
       "\n",
       "     description_openlib_clean  \n",
       "6252                      None  \n",
       "4684                      None  \n",
       "1731                      None  \n",
       "4742                      None  \n",
       "4521                      None  \n",
       "6340                      None  \n",
       "576                       None  \n",
       "5202                      None  \n",
       "6363                      None  \n",
       "439                       None  \n",
       "2750                      None  \n",
       "7487                      None  \n",
       "5272                      None  \n",
       "5653                      None  \n",
       "3999                      None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean OpenLibrary API data\n",
    "gb_enriched = apply_cleaners_selectively(\n",
    "    gb_enriched,\n",
    "    fields_to_clean=[\n",
    "        'pages',\n",
    "        'publication_date',\n",
    "        'language',\n",
    "        'subjects',\n",
    "        'publisher',\n",
    "        'description'\n",
    "        ],\n",
    "    source_suffix='_openlib',\n",
    "    target_suffix='_openlib_clean',\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "# verify cleaning\n",
    "print(\"\\nSample of cleaned OpenLibrary data:\")\n",
    "gb_enriched[[\n",
    "    'title_clean',\n",
    "    'pages_clean',\n",
    "    'pages_openlib',\n",
    "    'pages_openlib_clean',\n",
    "    'publication_date_clean',\n",
    "    'publication_date_openlib',\n",
    "    'publication_date_openlib_clean',\n",
    "    'language_clean',\n",
    "    'language_openlib',\n",
    "    'language_openlib_clean',\n",
    "    'genres_clean',\n",
    "    'genres_simplified',\n",
    "    'subjects_openlib',\n",
    "    'subjects_openlib_clean',\n",
    "    'publisher_clean',\n",
    "    'description_openlib',\n",
    "    'description_clean',\n",
    "    'description_openlib',\n",
    "    'description_openlib_clean'\n",
    "    ]].sample(15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71ee7be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Filling missing values with cleaned OpenLibrary data ---\n",
      "pages_clean: filled 1257 values\n",
      "publication_date_clean: filled 42 values\n",
      "language_clean: filled 305 values\n",
      "\n",
      "--- Filling missing publisher_clean using OpenLibrary data ---\n",
      "publisher_clean: filled 1515 values\n",
      "\n",
      "--- Filling missing description_clean using OpenLibrary data ---\n",
      "description_clean: filled 507 values\n",
      "\n",
      "--- Generating genres_simplified from OpenLibrary subjects ---\n",
      "Books with subjects but no genres_simplified: 951\n",
      "genres_simplified: mapped 796 values from OpenLibrary subjects\n",
      "\n",
      "Sample of newly mapped genres:\n",
      "            title_clean                             subjects_openlib_clean  \\\n",
      "29            gone girl  [fiction suspense, fiction mystery detective g...   \n",
      "32  memoirs of a geisha  [geishas -- fiction, women -- japan -- fiction...   \n",
      "43         the notebook                          [modern fiction, fiction]   \n",
      "47       fahrenheit 451  [bradbury ray - prose criticism, spanishcontem...   \n",
      "70         frankenstein  [frankenstein-- fiction, scientists -- fiction...   \n",
      "\n",
      "                          genres_simplified  \n",
      "29                       [fiction, mystery]  \n",
      "32            [fiction, historical fiction]  \n",
      "43                                [fiction]  \n",
      "47  [fiction, science fiction, non-fiction]  \n",
      "70                                [fiction]  \n"
     ]
    }
   ],
   "source": [
    "# fill missing values with cleaned OpenLibrary data\n",
    "print(\"\\n--- Filling missing values with cleaned OpenLibrary data ---\")\n",
    "\n",
    "# fill pages_clean\n",
    "before_pages = gb_enriched['pages_clean'].isna().sum()\n",
    "gb_enriched['pages_clean'] = gb_enriched['pages_clean'].fillna(gb_enriched['pages_openlib_clean'])\n",
    "after_pages = gb_enriched['pages_clean'].isna().sum()\n",
    "print(f\"pages_clean: filled {before_pages - after_pages} values\")\n",
    "\n",
    "# fill publication_date_clean\n",
    "before_date = gb_enriched['publication_date_clean'].isna().sum()\n",
    "gb_enriched['publication_date_clean'] = gb_enriched['publication_date_clean'].fillna(gb_enriched['publication_date_openlib_clean'])\n",
    "after_date = gb_enriched['publication_date_clean'].isna().sum()\n",
    "print(f\"publication_date_clean: filled {before_date - after_date} values\")\n",
    "\n",
    "# fill language_clean\n",
    "# Create mask that catches both NaN and invalid string values\n",
    "before_lang = (gb_enriched['language_clean'].isna() | \n",
    "               gb_enriched['language_clean'].isin(['unknown', '', 'None'])).sum()\n",
    "\n",
    "mask = (gb_enriched['language_clean'].isna() | \n",
    "        gb_enriched['language_clean'].isin(['unknown', '', 'None']))\n",
    "\n",
    "gb_enriched.loc[mask, 'language_clean'] = gb_enriched.loc[mask, 'language_openlib_clean']\n",
    "\n",
    "after_lang = (gb_enriched['language_clean'].isna() | \n",
    "              gb_enriched['language_clean'].isin(['unknown', '', 'None'])).sum()\n",
    "\n",
    "print(f\"language_clean: filled {before_lang - after_lang} values\")\n",
    "\n",
    "# fill publisher_clean\n",
    "print(\"\\n--- Filling missing publisher_clean using OpenLibrary data ---\")\n",
    "before_publisher = gb_enriched['publisher_clean'].isna().sum()\n",
    "gb_enriched['publisher_clean'] = gb_enriched['publisher_clean'].fillna(\n",
    "    gb_enriched['publisher_openlib_clean']\n",
    ")\n",
    "after_publisher = gb_enriched['publisher_clean'].isna().sum()\n",
    "print(f\"publisher_clean: filled {before_publisher - after_publisher} values\")\n",
    "\n",
    "# fill description_clean\n",
    "print(\"\\n--- Filling missing description_clean using OpenLibrary data ---\")\n",
    "\n",
    "before_desc = gb_enriched['description_clean'].isna().sum()\n",
    "gb_enriched['description_clean'] = gb_enriched['description_clean'].fillna(\n",
    "    gb_enriched['description_openlib_clean']\n",
    ")\n",
    "after_desc = gb_enriched['description_clean'].isna().sum()\n",
    "print(f\"description_clean: filled {before_desc - after_desc} values\")\n",
    "\n",
    "# generate genres_simplified from subjects_openlib_clean\n",
    "print(\"\\n--- Generating genres_simplified from OpenLibrary subjects ---\")\n",
    "\n",
    "# Import genre mapping utilities\n",
    "\n",
    "# Fill genres_simplified for books that have subjects but no genres\n",
    "books_needing_genre_mapping = (\n",
    "    (gb_enriched['genres_simplified'].isna()) & \n",
    "    (gb_enriched['subjects_openlib_clean'].notna())\n",
    ")\n",
    "\n",
    "print(f\"Books with subjects but no genres_simplified: {books_needing_genre_mapping.sum()}\")\n",
    "\n",
    "if books_needing_genre_mapping.sum() > 0:\n",
    "    # Apply genre mapping to subjects\n",
    "    gb_enriched.loc[books_needing_genre_mapping, 'genres_simplified'] = (\n",
    "        gb_enriched.loc[books_needing_genre_mapping, 'subjects_openlib_clean']\n",
    "        .apply(lambda x: map_subjects_to_genres(x) if isinstance(x, list) else None)\n",
    "    )\n",
    "    \n",
    "    filled_genres = (\n",
    "        gb_enriched.loc[books_needing_genre_mapping, 'genres_simplified'].notna().sum()\n",
    "    )\n",
    "    print(f\"genres_simplified: mapped {filled_genres} values from OpenLibrary subjects\")\n",
    "    \n",
    "    # Show sample of newly mapped genres\n",
    "    newly_mapped = gb_enriched[books_needing_genre_mapping & gb_enriched['genres_simplified'].notna()]\n",
    "    if len(newly_mapped) > 0:\n",
    "        print(\"\\nSample of newly mapped genres:\")\n",
    "        print(newly_mapped[['title_clean', 'subjects_openlib_clean', 'genres_simplified']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e72318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ENRICHMENT SUMMARY ---\n",
      "\n",
      "Total books enriched with OpenLibrary data: 1046\n",
      "\n",
      "Sample of books enriched from OpenLibrary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>pages_openlib_clean</th>\n",
       "      <th>publication_date_openlib_clean</th>\n",
       "      <th>language_openlib_clean</th>\n",
       "      <th>subjects_openlib_clean</th>\n",
       "      <th>genres_simplified</th>\n",
       "      <th>publisher_clean</th>\n",
       "      <th>description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gone girl</td>\n",
       "      <td>gillian flynn</td>\n",
       "      <td>399.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>[fiction suspense, fiction mystery detective g...</td>\n",
       "      <td>[fiction, mystery]</td>\n",
       "      <td>weidenfeld nicolson</td>\n",
       "      <td>just how well can you ever know the person you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>memoirs of a geisha</td>\n",
       "      <td>arthur golden</td>\n",
       "      <td>758.0</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>[geishas -- fiction, women -- japan -- fiction...</td>\n",
       "      <td>[fiction, historical fiction]</td>\n",
       "      <td>penguin random house</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>the notebook</td>\n",
       "      <td>nicholas sparks</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2004-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[modern fiction, fiction]</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>penguin random house</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>fahrenheit 451</td>\n",
       "      <td>ray bradbury</td>\n",
       "      <td>176.0</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>es</td>\n",
       "      <td>[bradbury ray - prose criticism, spanishcontem...</td>\n",
       "      <td>[fiction, science fiction, non-fiction]</td>\n",
       "      <td>plaza y janes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>frankenstein</td>\n",
       "      <td>mary wollstonecraft shelley, percy bysshe shel...</td>\n",
       "      <td>273.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>[frankenstein-- fiction, scientists -- fiction...</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>penguin random house</td>\n",
       "      <td>presents the story of dr frankenstein and his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>jurassic park</td>\n",
       "      <td>michael crichton</td>\n",
       "      <td>467.0</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>es</td>\n",
       "      <td>[suspense, fiction, fiction - general, spanish...</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>debolsillo</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>thirteen reasons why</td>\n",
       "      <td>jay asher</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>[suicide -- fiction, high schools -- fiction, ...</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>razorbill</td>\n",
       "      <td>when high school student clay jenkins receives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>american gods</td>\n",
       "      <td>neil gaiman</td>\n",
       "      <td>672.0</td>\n",
       "      <td>2002-03-04</td>\n",
       "      <td>en</td>\n",
       "      <td>[science fiction]</td>\n",
       "      <td>[fiction, science fiction]</td>\n",
       "      <td>headline book publishing</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>the shack</td>\n",
       "      <td>william paul young</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>[life change events -- fiction, missing childr...</td>\n",
       "      <td>[fiction, children]</td>\n",
       "      <td>windblown media</td>\n",
       "      <td>mackenzie allen phillips' youngest daughter mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>the guernsey literary and potato peel pie society</td>\n",
       "      <td>mary ann shaffer, annie barrows</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>[literary, fiction literary, fiction, fiction ...</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>the dial press</td>\n",
       "      <td>i wonder how the book got to guernsey perhaps ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title_clean  \\\n",
       "29                                           gone girl   \n",
       "32                                 memoirs of a geisha   \n",
       "43                                        the notebook   \n",
       "47                                      fahrenheit 451   \n",
       "70                                        frankenstein   \n",
       "83                                       jurassic park   \n",
       "146                               thirteen reasons why   \n",
       "166                                      american gods   \n",
       "173                                          the shack   \n",
       "194  the guernsey literary and potato peel pie society   \n",
       "\n",
       "                                          author_clean  pages_openlib_clean  \\\n",
       "29                                       gillian flynn                399.0   \n",
       "32                                       arthur golden                758.0   \n",
       "43                                     nicholas sparks                272.0   \n",
       "47                                        ray bradbury                176.0   \n",
       "70   mary wollstonecraft shelley, percy bysshe shel...                273.0   \n",
       "83                                    michael crichton                467.0   \n",
       "146                                          jay asher                288.0   \n",
       "166                                        neil gaiman                672.0   \n",
       "173                                 william paul young                252.0   \n",
       "194                    mary ann shaffer, annie barrows                288.0   \n",
       "\n",
       "    publication_date_openlib_clean language_openlib_clean  \\\n",
       "29                      2012-01-01                     en   \n",
       "32                      2005-01-01                     en   \n",
       "43                      2004-07-05                    NaN   \n",
       "47                      2006-01-03                     es   \n",
       "70                      2003-01-01                     en   \n",
       "83                      2006-01-01                     es   \n",
       "146                     2008-01-01                     en   \n",
       "166                     2002-03-04                     en   \n",
       "173                     2007-01-01                     en   \n",
       "194                     2008-01-01                     en   \n",
       "\n",
       "                                subjects_openlib_clean  \\\n",
       "29   [fiction suspense, fiction mystery detective g...   \n",
       "32   [geishas -- fiction, women -- japan -- fiction...   \n",
       "43                           [modern fiction, fiction]   \n",
       "47   [bradbury ray - prose criticism, spanishcontem...   \n",
       "70   [frankenstein-- fiction, scientists -- fiction...   \n",
       "83   [suspense, fiction, fiction - general, spanish...   \n",
       "146  [suicide -- fiction, high schools -- fiction, ...   \n",
       "166                                  [science fiction]   \n",
       "173  [life change events -- fiction, missing childr...   \n",
       "194  [literary, fiction literary, fiction, fiction ...   \n",
       "\n",
       "                           genres_simplified           publisher_clean  \\\n",
       "29                        [fiction, mystery]       weidenfeld nicolson   \n",
       "32             [fiction, historical fiction]      penguin random house   \n",
       "43                                 [fiction]      penguin random house   \n",
       "47   [fiction, science fiction, non-fiction]             plaza y janes   \n",
       "70                                 [fiction]      penguin random house   \n",
       "83                                 [fiction]                debolsillo   \n",
       "146                                [fiction]                 razorbill   \n",
       "166               [fiction, science fiction]  headline book publishing   \n",
       "173                      [fiction, children]           windblown media   \n",
       "194                                [fiction]            the dial press   \n",
       "\n",
       "                                     description_clean  \n",
       "29   just how well can you ever know the person you...  \n",
       "32                                                None  \n",
       "43                                                None  \n",
       "47                                                None  \n",
       "70   presents the story of dr frankenstein and his ...  \n",
       "83                                                None  \n",
       "146  when high school student clay jenkins receives...  \n",
       "166                                               None  \n",
       "173  mackenzie allen phillips' youngest daughter mi...  \n",
       "194  i wonder how the book got to guernsey perhaps ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GENRE COVERAGE AFTER ENRICHMENT ---\n",
      "Books with genres_clean: 8082\n",
      "Books without genres_clean: 1918\n",
      "Genre coverage: 80.8%\n",
      "\n",
      "Books with genres_simplified: 8878\n",
      "Books without genres_simplified: 1122\n",
      "Genre simplified coverage: 88.8%\n",
      "Books with description_clean: 8516\n",
      "Books without description_clean: 1484\n",
      "Books description coverage: 85.2%\n",
      "Books with publisher_clean: 9469\n",
      "Books without publisher_clean: 531\n",
      "Books publisher coverage: 94.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- ENRICHMENT SUMMARY ---\")\n",
    "\n",
    "# Show books that received OpenLibrary data\n",
    "books_with_ol_data = gb_enriched[\n",
    "    gb_enriched['subjects_openlib_clean'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nTotal books enriched with OpenLibrary data: {len(books_with_ol_data)}\")\n",
    "\n",
    "if len(books_with_ol_data) > 0:\n",
    "    print(\"\\nSample of books enriched from OpenLibrary:\")\n",
    "    display(books_with_ol_data[[\n",
    "        'title_clean',\n",
    "        'author_clean',\n",
    "        'pages_openlib_clean',\n",
    "        'publication_date_openlib_clean',\n",
    "        'language_openlib_clean',\n",
    "        'subjects_openlib_clean',\n",
    "        'genres_simplified',\n",
    "        'publisher_clean',\n",
    "        'description_clean'\n",
    "    ]].head(10))\n",
    "\n",
    "# Show overall genre coverage\n",
    "print(f\"\\n--- GENRE COVERAGE AFTER ENRICHMENT ---\")\n",
    "print(f\"Books with genres_clean: {gb_enriched['genres_clean'].notna().sum()}\")\n",
    "print(f\"Books without genres_clean: {gb_enriched['genres_clean'].isna().sum()}\")\n",
    "print(f\"Genre coverage: {gb_enriched['genres_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%\\n\")\n",
    "print(f\"Books with genres_simplified: {gb_enriched['genres_simplified'].notna().sum()}\")\n",
    "print(f\"Books without genres_simplified: {gb_enriched['genres_simplified'].isna().sum()}\")\n",
    "print(f\"Genre simplified coverage: {gb_enriched['genres_simplified'].notna().sum() / len(gb_enriched) * 100:.1f}%\")\n",
    "# Show overall description and publisher coverage\n",
    "print(f\"Books with description_clean: {gb_enriched['description_clean'].notna().sum()}\")\n",
    "print(f\"Books without description_clean: {gb_enriched['description_clean'].isna().sum()}\")\n",
    "print(f\"Books description coverage: {gb_enriched['description_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%\")\n",
    "print(f\"Books with publisher_clean: {gb_enriched['publisher_clean'].notna().sum()}\")\n",
    "print(f\"Books without publisher_clean: {gb_enriched['publisher_clean'].isna().sum()}\")\n",
    "print(f\"Books publisher coverage: {gb_enriched['publisher_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e647000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb_enriched v3 saved successfully in data/interim/merge directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "file_name = 'gb_enriched'\n",
    "clean_merge_path = Path(\"data/cleaned/merge\")\n",
    "clean_merge_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "version = 3\n",
    "\n",
    "gb_enriched.to_csv(clean_merge_path / f\"{file_name}_v{version}.csv\", index=False)\n",
    "\n",
    "print(f\"{file_name} v{version} saved successfully in data/interim/merge directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab0e7c",
   "metadata": {},
   "source": [
    "#### Querying Google Books API (with Quota Management)\n",
    "\n",
    "After OpenLibrary enrichment, we create a new mask to identify remaining gaps: **1,730** books. Google Books API requires an API key and has daily quota limits (1,000 requests/day for free tier), so we implement several strategies: **(1)** process ISBNs in chunks of 1,000, **(2)** add sleep delays between requests, **(3)** cache all results to avoid re-querying, and **(4)** save progress incrementally.\n",
    "\n",
    "We load existing cache if available, query only uncached ISBNs, and update the cache after each session. This approach allows us to spread queries across multiple days if needed while preserving all previous work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3991bae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books still needing external enrichment: 1730\n",
      "\n",
      "Breakdown of remaining missing values:\n",
      "  - Missing pages: 690\n",
      "  - Missing publication_date: 3\n",
      "  - Missing/invalid language: 95\n",
      "  - Missing publisher: 531\n",
      "  - Missing description: 1484\n"
     ]
    }
   ],
   "source": [
    "# Check how many books still need enrichment\n",
    "new_missing_mask = (\n",
    "    gb_enriched['language_clean'].isna() |\n",
    "    gb_enriched['language_clean'].isin(['unknown', '', 'None']) |\n",
    "    gb_enriched['pages_clean'].isna() |\n",
    "    gb_enriched['publication_date_clean'].isna() | \n",
    "    gb_enriched['publisher_clean'].isna() |\n",
    "    gb_enriched['description_clean'].isna()\n",
    ")\n",
    "\n",
    "new_to_impute = gb_enriched[new_missing_mask].copy()\n",
    "print(\"Books still needing external enrichment:\", len(new_to_impute))\n",
    "\n",
    "# Show breakdown by field\n",
    "print(\"\\nBreakdown of remaining missing values:\")\n",
    "print(f\"  - Missing pages: {gb_enriched['pages_clean'].isna().sum()}\")\n",
    "print(f\"  - Missing publication_date: {gb_enriched['publication_date_clean'].isna().sum()}\")\n",
    "print(f\"  - Missing/invalid language: {(gb_enriched['language_clean'].isna() | gb_enriched['language_clean'].isin(['unknown', '', 'None'])).sum()}\")\n",
    "print(f\"  - Missing publisher: {gb_enriched['publisher_clean'].isna().sum()}\")\n",
    "print(f\"  - Missing description: {gb_enriched['description_clean'].isna().sum()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "761ed215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_list(data, size=1000):\n",
    "    for i in range(0, len(data), size):\n",
    "        yield data[i:i+size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d16623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define cache path for Google Books in data/raw\n",
    "CACHE_PATH = Path(\"data/raw/google_api_cache.json\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load existing cache if it exists\n",
    "if CACHE_PATH.exists():\n",
    "    with open(CACHE_PATH, \"r\") as f:\n",
    "        google_cache = json.load(f)\n",
    "else:\n",
    "    google_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44817fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_BOOKS_API_KEY\")\n",
    "\n",
    "def query_google_books(isbn):\n",
    "    isbn = str(isbn)\n",
    "\n",
    "    # Check cache\n",
    "    if isbn in google_cache:\n",
    "        return google_cache[isbn]\n",
    "\n",
    "    # Query Google Books with API key\n",
    "    url = (\n",
    "        f\"https://www.googleapis.com/books/v1/volumes?\"\n",
    "        f\"q=isbn:{isbn}&key={GOOGLE_API_KEY}\"\n",
    "    )\n",
    "\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        result = {\"isbn\": isbn, \"error\": f\"HTTP {r.status_code}\"}\n",
    "    else:\n",
    "        data = r.json()\n",
    "        if \"items\" in data and data[\"items\"]:\n",
    "            volume = data[\"items\"][0][\"volumeInfo\"]\n",
    "            result = {\n",
    "                \"isbn\": isbn,\n",
    "                \"title\": volume.get(\"title\"),\n",
    "                \"authors\": volume.get(\"authors\"),\n",
    "                \"publisher\": volume.get(\"publisher\"),\n",
    "                \"publishedDate\": volume.get(\"publishedDate\"),\n",
    "                \"pageCount\": volume.get(\"pageCount\"),\n",
    "                \"categories\": volume.get(\"categories\"),\n",
    "                \"language\": volume.get(\"language\"),\n",
    "                \"description\": volume.get(\"description\"),\n",
    "            }\n",
    "        else:\n",
    "            result = {\"isbn\": isbn, \"error\": \"No results\"}\n",
    "\n",
    "    # Save to cache\n",
    "    google_cache[isbn] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ISBNs to query: 1278\n"
     ]
    }
   ],
   "source": [
    "list_of_isbns = (\n",
    "    new_to_impute['isbn_query']\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "print(f\"Unique ISBNs to query: {len(list_of_isbns)}\")\n",
    "chunks = list(chunk_list(list_of_isbns, size=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff9d7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying Google Books: 100%|██████████| 278/278 [02:44<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Choose which chunk you want to process today\n",
    "chunk_to_process = chunks[1]   # run chunk 0 today, 1 tomorrow, etc.\n",
    "results = []\n",
    "for isbn in tqdm(chunk_to_process, desc=\"Querying Google Books\"):\n",
    "    results.append(query_google_books(isbn))\n",
    "    time.sleep(0.1)   # be nice to the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f955d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache updated with 1730 entries after ISBN queries\n"
     ]
    }
   ],
   "source": [
    "# Save cache after ISBN queries\n",
    "with open(CACHE_PATH, \"w\") as f:\n",
    "    json.dump(google_cache, f, indent=2)\n",
    "print(f\"Cache updated with {len(google_cache)} entries after ISBN queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d7361",
   "metadata": {},
   "source": [
    "#### Handling Books Without ISBNs\n",
    "\n",
    "Some books lack valid ISBNs but can still be enriched using **title and author search**. Google Books API supports `intitle:` and `inauthor:` query parameters, allowing us to find books by bibliographic metadata instead of identifiers. We create cache keys in `\"title|author\"` format to distinguish these from ISBN-based queries.\n",
    "\n",
    "This fallback strategy significantly increases our enrichment coverage, especially for older books, special editions, or records with ISBN errors. Results are cached alongside ISBN queries to maintain a unified enrichment workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fad912ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books without ISBN to query by title/author: 452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying Google Books by title/author: 100%|██████████| 452/452 [05:41<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def query_google_books_by_title(title, author):\n",
    "    \"\"\"Query Google Books API using title and author when ISBN is unavailable.\"\"\"\n",
    "    \n",
    "    # Create cache key\n",
    "    cache_key = f\"{title}|{author}\"\n",
    "    \n",
    "    if cache_key in google_cache:\n",
    "        return google_cache[cache_key]\n",
    "    \n",
    "    # Build query string\n",
    "    query_parts = []\n",
    "    if pd.notna(title):\n",
    "        query_parts.append(f'intitle:\"{title}\"')\n",
    "    if pd.notna(author):\n",
    "        query_parts.append(f'inauthor:\"{author}\"')\n",
    "    \n",
    "    query_string = \"+\".join(query_parts)\n",
    "    \n",
    "    url = (\n",
    "        f\"https://www.googleapis.com/books/v1/volumes?\"\n",
    "        f\"q={query_string}&key={GOOGLE_API_KEY}\"\n",
    "    )\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        result = {\"title\": title, \"author\": author, \"error\": f\"HTTP {r.status_code}\"}\n",
    "    else:\n",
    "        data = r.json()\n",
    "        if \"items\" in data and data[\"items\"]:\n",
    "            volume = data[\"items\"][0][\"volumeInfo\"]\n",
    "            result = {\n",
    "                \"title\": title,\n",
    "                \"author\": author,\n",
    "                \"pageCount\": volume.get(\"pageCount\"),\n",
    "                \"publisher\": volume.get(\"publisher\"),  \n",
    "                \"publishedDate\": volume.get(\"publishedDate\"),\n",
    "                \"categories\": volume.get(\"categories\"),\n",
    "                \"language\": volume.get(\"language\"),\n",
    "                \"description\": volume.get(\"description\"),\n",
    "            }\n",
    "        else:\n",
    "            result = {\"title\": title, \"author\": author, \"error\": \"No results\"}\n",
    "    \n",
    "    google_cache[cache_key] = result\n",
    "    return result\n",
    "\n",
    "# Process books without ISBN separately\n",
    "books_without_isbn = new_to_impute[new_to_impute['isbn_query'].isna()].copy()\n",
    "print(f\"Books without ISBN to query by title/author: {len(books_without_isbn)}\")\n",
    "\n",
    "results_by_title = []\n",
    "for idx, row in tqdm(books_without_isbn.iterrows(), \n",
    "                     total=len(books_without_isbn),\n",
    "                     desc=\"Querying Google Books by title/author\"):\n",
    "    results_by_title.append(query_google_books_by_title(\n",
    "        row['title_clean'], \n",
    "        row['author_clean']\n",
    "    ))\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c3590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache updated with 1452 entries after title/author queries\n"
     ]
    }
   ],
   "source": [
    "# Save cache after title/author queries\n",
    "with open(CACHE_PATH, \"w\") as f:\n",
    "    json.dump(google_cache, f, indent=2)\n",
    "print(f\"Cache updated with {len(google_cache)} entries after title/author queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cd3f8",
   "metadata": {},
   "source": [
    "#### Loading and Applying Cached Results\n",
    "\n",
    "The Google Books cache contains results from multiple query sessions, potentially across different days. We load the complete cache and separate ISBN-based results from title/author-based results by checking for the `\"|\"` delimiter in cache keys. This allows us to apply different matching logic for each result type.\n",
    "\n",
    "We then merge cached data back into `gb_enriched`, apply the cleaning pipeline to standardize formats, and fill remaining metadata gaps. The `map_subjects_to_genres()` function maps Google Books categories to our genre taxonomy, further increasing genre coverage. This completes our multi-source enrichment strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25ff711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1864 cached entries\n",
      "Found 1099 ISBN-based results\n",
      "Found 765 title/author-based results\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the cache\n",
    "CACHE_PATH = Path(\"google_api_cache.json\")\n",
    "\n",
    "with open(CACHE_PATH, \"r\") as f:\n",
    "    google_cache = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(google_cache)} cached entries\")\n",
    "\n",
    "# Separate ISBN-based results from title/author-based results\n",
    "isbn_results = []\n",
    "title_author_results = []\n",
    "\n",
    "for key, value in google_cache.items():\n",
    "    if \"|\" in key:  # Title|Author format\n",
    "        title_author_results.append(value)\n",
    "    else:  # ISBN format\n",
    "        isbn_results.append(value)\n",
    "\n",
    "print(f\"Found {len(isbn_results)} ISBN-based results\")\n",
    "print(f\"Found {len(title_author_results)} title/author-based results\")\n",
    "\n",
    "# add google books data to dataframe\n",
    "google_columns = [\n",
    "    'pageCount_google',\n",
    "    'publishedDate_google',\n",
    "    'categories_google',\n",
    "    'language_google',\n",
    "    'publisher_google',\n",
    "    'description_google'\n",
    "]\n",
    "for col in google_columns:\n",
    "    if col not in gb_enriched.columns:\n",
    "        gb_enriched[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "741eb6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ISBN results preview:\n",
      "            isbn                      title                      authors  \\\n",
      "0  9780451524940  A Midsummer Night's Dream        [William Shakespeare]   \n",
      "1  9780452284240                Animal Farm              [George Orwell]   \n",
      "2  9780618346260      The Lord of the Rings  [John Ronald Reuel Tolkien]   \n",
      "3  9780297859380                        NaN                          NaN   \n",
      "4  9780061122420        The Monk Downstairs             [Tim Farrington]   \n",
      "\n",
      "         publisher publishedDate  pageCount  \\\n",
      "0  Signet Classics          1987      212.0   \n",
      "1          Penguin    2003-05-06      129.0   \n",
      "2             None          1994     1137.0   \n",
      "3              NaN           NaN        NaN   \n",
      "4        HarperOne    2006-05-23        0.0   \n",
      "\n",
      "                                categories language       error  \n",
      "0                                  [Drama]       en         NaN  \n",
      "1                                [Fiction]       en         NaN  \n",
      "2  [Baggins, Frodo (Fictitious character)]       en         NaN  \n",
      "3                                      NaN      NaN  No results  \n",
      "4                                [Fiction]       en         NaN  \n",
      "✓ Merged ISBN-based results for 1099 books\n",
      "\n",
      "Title/Author results preview:\n",
      "                                 title  \\\n",
      "0                to kill a mockingbird   \n",
      "1                        the alchemist   \n",
      "2  the lion the witch and the wardrobe   \n",
      "3        one hundred years of solitude   \n",
      "4                           bossypants   \n",
      "\n",
      "                                    author  pageCount publishedDate  \\\n",
      "0                               harper lee      296.0          1960   \n",
      "1              paulo coelho, alan r clarke        NaN           NaN   \n",
      "2                                 cs lewis      259.0       2005-06   \n",
      "3  gabriel garcia marquez, gregory rabassa        NaN           NaN   \n",
      "4                                 tina fey      183.0    2011-04-18   \n",
      "\n",
      "                    categories language       error  \n",
      "0                    [Fiction]       en         NaN  \n",
      "1                          NaN      NaN  No results  \n",
      "2                    [Fiction]       en         NaN  \n",
      "3                          NaN      NaN  No results  \n",
      "4  [Biography & Autobiography]       en         NaN  \n",
      "✓ Merged title/author-based results for 452 books\n",
      "\n",
      "Google Books data merged:\n",
      "  - pageCount_google: 353 values\n",
      "  - publishedDate_google: 363 values\n",
      "  - categories_google: 341 values\n",
      "  - language_google: 364 values\n",
      "  - publisher_google: 62 values\n",
      "  - description_google: 0 values\n",
      "\n",
      "Sample of cleaned Google Books data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>pages_clean</th>\n",
       "      <th>pageCount_google</th>\n",
       "      <th>pageCount_google_clean</th>\n",
       "      <th>publication_date_clean</th>\n",
       "      <th>publishedDate_google</th>\n",
       "      <th>publishedDate_google_clean</th>\n",
       "      <th>language_clean</th>\n",
       "      <th>language_google</th>\n",
       "      <th>language_google_clean</th>\n",
       "      <th>genres_clean</th>\n",
       "      <th>categories_google</th>\n",
       "      <th>categories_google_clean</th>\n",
       "      <th>genres_simplified</th>\n",
       "      <th>publisher_google</th>\n",
       "      <th>publisher_clean</th>\n",
       "      <th>description_google</th>\n",
       "      <th>description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>the scarecrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2014-05-22</td>\n",
       "      <td>2014-05-22</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Fiction]</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>the witch of portobello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2011-04-28</td>\n",
       "      <td>2011-04-28</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Fiction]</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>the hundred-year-old man who climbed out of th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Fiction]</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hesperus Press</td>\n",
       "      <td>hesperus press ltd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589</th>\n",
       "      <td>this body of death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620</td>\n",
       "      <td>620.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2011-05-26</td>\n",
       "      <td>2011-05-26</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Fiction]</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>the good neighbor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>a cook's tour global adventures in extreme cui...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2002-11-05</td>\n",
       "      <td>2002-11-05</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Cooking]</td>\n",
       "      <td>[cooking]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>i too had a love story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>srishti publishers distributors</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>panda bear panda bear what do you see</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>2003-08</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Juvenile Fiction]</td>\n",
       "      <td>[juvenile fiction]</td>\n",
       "      <td>[fiction, young adult, children]</td>\n",
       "      <td>Macmillan</td>\n",
       "      <td>h holt</td>\n",
       "      <td>None</td>\n",
       "      <td>illustrations and rhyming text present ten dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>the perfect son</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Children with disabilities]</td>\n",
       "      <td>[children with disabilities]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>anne mccaffrey's dragonflight 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Fantasy comic books, strips, etc]</td>\n",
       "      <td>[fantasy comic books strips etc]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>eclipse books</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>wave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Biography &amp; Autobiography]</td>\n",
       "      <td>[biography autobiography]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>reason to breathe</td>\n",
       "      <td>377.0</td>\n",
       "      <td>468</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2012-11-08</td>\n",
       "      <td>2012-11-08</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>['romance', 'young adult', 'contemporary', 'ne...</td>\n",
       "      <td>[Young Adult Fiction]</td>\n",
       "      <td>[young adult fiction]</td>\n",
       "      <td>['romance', 'young adult', 'contemporary', 'ne...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no one tried to get involved with me and i kep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>a hidden fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414</td>\n",
       "      <td>414.0</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Fiction]</td>\n",
       "      <td>[fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>broken harbour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>544.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-06</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Detective and mystery stories]</td>\n",
       "      <td>[detective and mystery stories]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>hodder headline ireland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>frog and toad all year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Friendship]</td>\n",
       "      <td>[friendship]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_clean  pages_clean  \\\n",
       "4672                                      the scarecrow          NaN   \n",
       "1528                            the witch of portobello          NaN   \n",
       "701   the hundred-year-old man who climbed out of th...          NaN   \n",
       "8589                                 this body of death          NaN   \n",
       "2242                                  the good neighbor          NaN   \n",
       "5273  a cook's tour global adventures in extreme cui...          NaN   \n",
       "2748                             i too had a love story          NaN   \n",
       "3739              panda bear panda bear what do you see          NaN   \n",
       "7431                                    the perfect son          NaN   \n",
       "3764                    anne mccaffrey's dragonflight 1          NaN   \n",
       "7272                                               wave          NaN   \n",
       "1752                                  reason to breathe        377.0   \n",
       "6702                                      a hidden fire          NaN   \n",
       "2206                                     broken harbour          NaN   \n",
       "3987                             frog and toad all year          NaN   \n",
       "\n",
       "     pageCount_google  pageCount_google_clean publication_date_clean  \\\n",
       "4672              285                   285.0             2009-01-01   \n",
       "1528               33                    33.0             2006-01-01   \n",
       "701             396.0                   396.0             2009-01-01   \n",
       "8589              620                   620.0             2010-01-01   \n",
       "2242             None                     NaN             2015-01-01   \n",
       "5273              290                   290.0             2001-01-01   \n",
       "2748              0.0                     NaN             2007-01-01   \n",
       "3739             36.0                    36.0             2003-01-01   \n",
       "7431                0                     NaN             2015-01-01   \n",
       "3764            134.0                   134.0             1991-01-01   \n",
       "7272              187                   187.0             2013-01-01   \n",
       "1752              468                   468.0             2011-01-01   \n",
       "6702              414                   414.0             2011-01-01   \n",
       "2206            544.0                   544.0             2012-01-01   \n",
       "3987               68                    68.0             1976-01-01   \n",
       "\n",
       "     publishedDate_google publishedDate_google_clean language_clean  \\\n",
       "4672           2014-05-22                 2014-05-22             en   \n",
       "1528           2011-04-28                 2011-04-28             en   \n",
       "701                  2012                 2012-01-01             en   \n",
       "8589           2011-05-26                 2011-05-26             en   \n",
       "2242                 2013                 2013-01-01             en   \n",
       "5273           2002-11-05                 2002-11-05             en   \n",
       "2748                 2009                 2009-01-01             en   \n",
       "3739              2003-08                 2003-08-01             en   \n",
       "7431              2015-07                 2015-07-01             en   \n",
       "3764                 1993                 1993-01-01             en   \n",
       "7272           2013-03-05                 2013-03-05             en   \n",
       "1752           2012-11-08                 2012-11-08             en   \n",
       "6702           2023-03-09                 2023-03-09            NaN   \n",
       "2206              2012-06                 2012-06-01             en   \n",
       "3987                 1976                 1976-01-01             en   \n",
       "\n",
       "     language_google language_google_clean  \\\n",
       "4672              en                    en   \n",
       "1528              en                    en   \n",
       "701               en                    en   \n",
       "8589              en                    en   \n",
       "2242              en                    en   \n",
       "5273              en                    en   \n",
       "2748              en                    en   \n",
       "3739              en                    en   \n",
       "7431              en                    en   \n",
       "3764              en                    en   \n",
       "7272              en                    en   \n",
       "1752              en                    en   \n",
       "6702              en                    en   \n",
       "2206              en                    en   \n",
       "3987              en                    en   \n",
       "\n",
       "                                           genres_clean  \\\n",
       "4672                                                NaN   \n",
       "1528                                                NaN   \n",
       "701                                                 NaN   \n",
       "8589                                                NaN   \n",
       "2242                                                NaN   \n",
       "5273                                                NaN   \n",
       "2748                                                NaN   \n",
       "3739                                                NaN   \n",
       "7431                                                NaN   \n",
       "3764                                                NaN   \n",
       "7272                                                NaN   \n",
       "1752  ['romance', 'young adult', 'contemporary', 'ne...   \n",
       "6702                                                NaN   \n",
       "2206                                                NaN   \n",
       "3987                                                NaN   \n",
       "\n",
       "                       categories_google           categories_google_clean  \\\n",
       "4672                           [Fiction]                         [fiction]   \n",
       "1528                           [Fiction]                         [fiction]   \n",
       "701                            [Fiction]                         [fiction]   \n",
       "8589                           [Fiction]                         [fiction]   \n",
       "2242                                None                              None   \n",
       "5273                           [Cooking]                         [cooking]   \n",
       "2748                                None                              None   \n",
       "3739                  [Juvenile Fiction]                [juvenile fiction]   \n",
       "7431        [Children with disabilities]      [children with disabilities]   \n",
       "3764  [Fantasy comic books, strips, etc]  [fantasy comic books strips etc]   \n",
       "7272         [Biography & Autobiography]         [biography autobiography]   \n",
       "1752               [Young Adult Fiction]             [young adult fiction]   \n",
       "6702                           [Fiction]                         [fiction]   \n",
       "2206     [Detective and mystery stories]   [detective and mystery stories]   \n",
       "3987                        [Friendship]                      [friendship]   \n",
       "\n",
       "                                      genres_simplified publisher_google  \\\n",
       "4672                                                NaN             None   \n",
       "1528                                                NaN             None   \n",
       "701                                                 NaN   Hesperus Press   \n",
       "8589                                                NaN             None   \n",
       "2242                                                NaN             None   \n",
       "5273                                                NaN             None   \n",
       "2748                                                NaN             None   \n",
       "3739                   [fiction, young adult, children]        Macmillan   \n",
       "7431                                                NaN             None   \n",
       "3764                                                NaN             None   \n",
       "7272                                                NaN             None   \n",
       "1752  ['romance', 'young adult', 'contemporary', 'ne...             None   \n",
       "6702                                                NaN             None   \n",
       "2206                                                NaN             None   \n",
       "3987                                                NaN             None   \n",
       "\n",
       "                      publisher_clean description_google  \\\n",
       "4672                             None               None   \n",
       "1528                             None               None   \n",
       "701                hesperus press ltd               None   \n",
       "8589                             None               None   \n",
       "2242                             None               None   \n",
       "5273                             None               None   \n",
       "2748  srishti publishers distributors               None   \n",
       "3739                           h holt               None   \n",
       "7431                             None               None   \n",
       "3764                    eclipse books               None   \n",
       "7272                             None               None   \n",
       "1752                             None               None   \n",
       "6702                             None               None   \n",
       "2206          hodder headline ireland               None   \n",
       "3987                             None               None   \n",
       "\n",
       "                                      description_clean  \n",
       "4672                                               None  \n",
       "1528                                               None  \n",
       "701                                                None  \n",
       "8589                                               None  \n",
       "2242                                               None  \n",
       "5273                                               None  \n",
       "2748                                               None  \n",
       "3739  illustrations and rhyming text present ten dif...  \n",
       "7431                                               None  \n",
       "3764                                               None  \n",
       "7272                                               None  \n",
       "1752  no one tried to get involved with me and i kep...  \n",
       "6702                                               None  \n",
       "2206                                               None  \n",
       "3987                                               None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merge isbn_results back to gb_enriched\n",
    "if isbn_results:\n",
    "    google_isbn_df = pd.DataFrame(isbn_results)\n",
    "    print(\"\\nISBN results preview:\")\n",
    "    print(google_isbn_df.head())\n",
    "    \n",
    "    # Create ISBN mapping\n",
    "    isbn_to_data = {str(row['isbn']): row for _, row in google_isbn_df.iterrows() \n",
    "                    if 'isbn' in row and pd.notna(row.get('isbn'))}\n",
    "    \n",
    "    # Update gb_enriched\n",
    "    books_with_isbn = new_to_impute[new_to_impute['isbn_query'].notna()].copy()\n",
    "    \n",
    "    for idx in books_with_isbn.index:\n",
    "        isbn = str(books_with_isbn.loc[idx, 'isbn_query'])\n",
    "        if isbn in isbn_to_data:\n",
    "            result = isbn_to_data[isbn]\n",
    "            if pd.isna(result.get('error')):\n",
    "                gb_enriched.loc[idx, 'pageCount_google'] = result.get('pageCount')\n",
    "                gb_enriched.loc[idx, 'publishedDate_google'] = result.get('publishedDate')\n",
    "                gb_enriched.loc[idx, 'categories_google'] = result.get('categories')\n",
    "                gb_enriched.loc[idx, 'language_google'] = result.get('language')\n",
    "                gb_enriched.loc[idx, 'publisher_google'] = result.get('publisher')\n",
    "                gb_enriched.loc[idx, 'description_google'] = result.get('description')\n",
    "    \n",
    "    print(f\"✓ Merged ISBN-based results for {len(isbn_to_data)} books\")\n",
    "\n",
    "\n",
    "# merge title/author results back to gb_enriched\n",
    "\n",
    "if title_author_results:\n",
    "    google_title_df = pd.DataFrame(title_author_results)\n",
    "    print(\"\\nTitle/Author results preview:\")\n",
    "    print(google_title_df.head())\n",
    "    \n",
    "    # Recreate books_without_isbn from new_to_impute\n",
    "    books_without_isbn = new_to_impute[new_to_impute['isbn_query'].isna()].copy()\n",
    "    \n",
    "    # Create title|author key mapping\n",
    "    for i, (idx, row) in enumerate(books_without_isbn.iterrows()):\n",
    "        if i < len(google_title_df):\n",
    "            title_author_key = f\"{row['title_clean']}|{row['author_clean']}\"\n",
    "            if title_author_key in google_cache:\n",
    "                result = google_cache[title_author_key]\n",
    "                if pd.isna(result.get('error')):\n",
    "                    gb_enriched.loc[idx, 'pageCount_google'] = result.get('pageCount')\n",
    "                    gb_enriched.loc[idx, 'publishedDate_google'] = result.get('publishedDate')\n",
    "                    gb_enriched.loc[idx, 'categories_google'] = result.get('categories')\n",
    "                    gb_enriched.loc[idx, 'language_google'] = result.get('language')\n",
    "                    gb_enriched.loc[idx, 'publisher_google'] = result.get('publisher')\n",
    "                    gb_enriched.loc[idx, 'description_google'] = result.get('description')\n",
    "    \n",
    "    print(f\"✓ Merged title/author-based results for {len(books_without_isbn)} books\")\n",
    "\n",
    "# Verify merge\n",
    "print(\"\\nGoogle Books data merged:\")\n",
    "for col in google_columns:\n",
    "    count = gb_enriched[col].notna().sum()\n",
    "    print(f\"  - {col}: {count} values\")\n",
    "\n",
    "# clean Google Books API data\n",
    "from src.cleaning.utils.pipeline import apply_cleaners_selectively\n",
    "\n",
    "gb_enriched = apply_cleaners_selectively(\n",
    "    gb_enriched,\n",
    "    fields_to_clean=[\n",
    "        'pageCount',\n",
    "        'publishedDate',\n",
    "        'language',\n",
    "        'categories',\n",
    "        'publisher',\n",
    "        'description'\n",
    "        ],\n",
    "    source_suffix='_google',\n",
    "    target_suffix='_google_clean',\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "# Verify cleaning\n",
    "print(\"\\nSample of cleaned Google Books data:\")\n",
    "display(gb_enriched[[\n",
    "    'title_clean',\n",
    "    'pages_clean',\n",
    "    'pageCount_google',\n",
    "    'pageCount_google_clean',\n",
    "    'publication_date_clean',\n",
    "    'publishedDate_google',\n",
    "    'publishedDate_google_clean',\n",
    "    'language_clean',\n",
    "    'language_google',\n",
    "    'language_google_clean',\n",
    "    'genres_clean',\n",
    "    'categories_google',\n",
    "    'categories_google_clean',\n",
    "    'genres_simplified',\n",
    "    'publisher_google',\n",
    "    'publisher_clean',\n",
    "    'description_google',\n",
    "    'description_clean',\n",
    "]].dropna(subset=['pageCount_google_clean', 'language_google_clean'], how='all').sample(min(15, len(gb_enriched)), random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76157a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating genres_simplified from Google Books categories ---\n",
      "Books with Google categories but no genres_simplified: 257\n",
      "genres_simplified: mapped 194 values from Google Books categories\n",
      "\n",
      "--- Filling missing values with cleaned Google Books data ---\n",
      "\n",
      "--- Filling remaining page_clean using Google Books data ---\n",
      "pages_clean: filled 202 values from Google Books\n",
      "\n",
      "--- Filling remaining publication_date_clean using Google Books data ---\n",
      "publication_date_clean: filled 0 values from Google Books\n",
      "\n",
      "--- Filling remaining language_clean using Google Books data ---\n",
      "language_clean: filled 32 values from Google Books\n",
      "\n",
      "--- Filling remaining publisher_clean using Google Books data ---\n",
      "publisher_clean: filled 4 values from Google Books\n",
      "\n",
      "--- Filling remaining description_clean using Google Books data ---\n",
      "description_clean (Google): filled 0 values\n",
      "\n",
      "--- FINAL ENRICHMENT SUMMARY (ALL SOURCES) ---\n",
      "\n",
      "Total books enriched with Google Books data: 341\n",
      "\n",
      "--- FINAL METADATA COVERAGE ---\n",
      "Books with pages_clean: 9512 / 10000 (95.1%)\n",
      "Books with publication_date_clean: 9997 / 10000 (100.0%)\n",
      "Books with publisher_clean: 9473 / 10000 (94.7%)\n",
      "Books with description_clean: 8516 / 10000 (85.2%)\n",
      "Books with valid language_clean: 9937 / 10000 (99.4%)\n",
      "\n",
      "--- FINAL GENRE COVERAGE ---\n",
      "Books with genres_clean: 8082 / 10000 (80.8%)\n",
      "Books with genres_simplified: 9072 / 10000 (90.7%)\n"
     ]
    }
   ],
   "source": [
    "# after cleaning Google Books data, we'll add genre mapping\n",
    "print(\"\\n--- Generating genres_simplified from Google Books categories ---\")\n",
    "\n",
    "books_needing_google_genre_mapping = (\n",
    "    (gb_enriched['genres_simplified'].isna()) & \n",
    "    (gb_enriched['categories_google_clean'].notna())\n",
    ")\n",
    "\n",
    "print(f\"Books with Google categories but no genres_simplified: {books_needing_google_genre_mapping.sum()}\")\n",
    "\n",
    "if books_needing_google_genre_mapping.sum() > 0:\n",
    "    gb_enriched.loc[books_needing_google_genre_mapping, 'genres_simplified'] = (\n",
    "        gb_enriched.loc[books_needing_google_genre_mapping, 'categories_google_clean']\n",
    "        .apply(lambda x: map_subjects_to_genres(x) if isinstance(x, list) else None)\n",
    "    )\n",
    "    \n",
    "    filled_genres = (\n",
    "        gb_enriched.loc[books_needing_google_genre_mapping, 'genres_simplified'].notna().sum()\n",
    "    )\n",
    "    print(f\"genres_simplified: mapped {filled_genres} values from Google Books categories\")\n",
    "\n",
    "\n",
    "# fill missing values with cleaned Google Books data\n",
    "print(\"\\n--- Filling missing values with cleaned Google Books data ---\")\n",
    "\n",
    "# Fill pages_clean\n",
    "print(\"\\n--- Filling remaining page_clean using Google Books data ---\")\n",
    "before_pages = gb_enriched['pages_clean'].isna().sum()\n",
    "gb_enriched['pages_clean'] = gb_enriched['pages_clean'].fillna(gb_enriched['pageCount_google_clean'])\n",
    "after_pages = gb_enriched['pages_clean'].isna().sum()\n",
    "print(f\"pages_clean: filled {before_pages - after_pages} values from Google Books\")\n",
    "\n",
    "# Fill publication_date_clean\n",
    "print(\"\\n--- Filling remaining publication_date_clean using Google Books data ---\")\n",
    "before_date = gb_enriched['publication_date_clean'].isna().sum()\n",
    "gb_enriched['publication_date_clean'] = gb_enriched['publication_date_clean'].fillna(gb_enriched['publishedDate_google_clean'])\n",
    "after_date = gb_enriched['publication_date_clean'].isna().sum()\n",
    "print(f\"publication_date_clean: filled {before_date - after_date} values from Google Books\")\n",
    "\n",
    "# Fill language_clean\n",
    "print(\"\\n--- Filling remaining language_clean using Google Books data ---\")\n",
    "before_lang = (gb_enriched['language_clean'].isna() | \n",
    "               gb_enriched['language_clean'].isin(['unknown', '', 'None'])).sum()\n",
    "mask = (gb_enriched['language_clean'].isna() | \n",
    "        gb_enriched['language_clean'].isin(['unknown', '', 'None']))\n",
    "gb_enriched.loc[mask, 'language_clean'] = gb_enriched.loc[mask, 'language_google_clean']\n",
    "after_lang = (gb_enriched['language_clean'].isna() | \n",
    "              gb_enriched['language_clean'].isin(['unknown', '', 'None'])).sum()\n",
    "\n",
    "print(f\"language_clean: filled {before_lang - after_lang} values from Google Books\")\n",
    "\n",
    "# Fill publisher_clean\n",
    "print(\"\\n--- Filling remaining publisher_clean using Google Books data ---\")\n",
    "before_publisher = gb_enriched['publisher_clean'].isna().sum()\n",
    "gb_enriched['publisher_clean'] = gb_enriched['publisher_clean'].fillna(\n",
    "    gb_enriched['publisher_google_clean']\n",
    ")\n",
    "after_publisher = gb_enriched['publisher_clean'].isna().sum()\n",
    "print(f\"publisher_clean: filled {before_publisher - after_publisher} values from Google Books\")\n",
    "\n",
    "\n",
    "# Fill description_clean\n",
    "print(\"\\n--- Filling remaining description_clean using Google Books data ---\")\n",
    "before_desc_google = gb_enriched['description_clean'].isna().sum()\n",
    "gb_enriched['description_clean'] = gb_enriched['description_clean'].fillna(\n",
    "    gb_enriched['description_google_clean']\n",
    ")\n",
    "after_desc_google = gb_enriched['description_clean'].isna().sum()\n",
    "\n",
    "print(f\"description_clean (Google): filled {before_desc_google - after_desc_google} values\")\n",
    "\n",
    "# final enrichment summary\n",
    "print(\"\\n--- FINAL ENRICHMENT SUMMARY (ALL SOURCES) ---\")\n",
    "\n",
    "print(f\"\\nTotal books enriched with Google Books data: {gb_enriched[gb_enriched['categories_google_clean'].notna()].shape[0]}\")\n",
    "\n",
    "print(\"\\n--- FINAL METADATA COVERAGE ---\")\n",
    "print(f\"Books with pages_clean: {gb_enriched['pages_clean'].notna().sum()} / {len(gb_enriched)} ({gb_enriched['pages_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%)\")\n",
    "print(f\"Books with publication_date_clean: {gb_enriched['publication_date_clean'].notna().sum()} / {len(gb_enriched)} ({gb_enriched['publication_date_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%)\")\n",
    "print(f\"Books with publisher_clean: {gb_enriched['publisher_clean'].notna().sum()} / {len(gb_enriched)} ({gb_enriched['publisher_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%)\")\n",
    "print(f\"Books with description_clean: {gb_enriched['description_clean'].notna().sum()} / {len(gb_enriched)} ({gb_enriched['description_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%)\")\n",
    "valid_language = gb_enriched['language_clean'].notna() & ~gb_enriched['language_clean'].isin(['unknown', '', 'None'])\n",
    "print(f\"Books with valid language_clean: {valid_language.sum()} / {len(gb_enriched)} ({valid_language.sum() / len(gb_enriched) * 100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n--- FINAL GENRE COVERAGE ---\")\n",
    "print(f\"Books with genres_clean: {gb_enriched['genres_clean'].notna().sum()} / {len(gb_enriched)} ({gb_enriched['genres_clean'].notna().sum() / len(gb_enriched) * 100:.1f}%)\")\n",
    "print(f\"Books with genres_simplified: {gb_enriched['genres_simplified'].notna().sum()} / {len(gb_enriched)} ({gb_enriched['genres_simplified'].notna().sum() / len(gb_enriched) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9c6fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb_enriched v4 saved successfully in data/interim/merge directory.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data folder if not exists\n",
    "file_name = 'gb_enriched'\n",
    "clean_merge_path = Path(\"data/cleaned/merge\")\n",
    "clean_merge_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "version = 4\n",
    "\n",
    "gb_enriched.to_csv(clean_merge_path / f\"{file_name}_v{version}.csv\", index=False)\n",
    "\n",
    "print(f\"{file_name} v{version} saved successfully in data/interim/merge directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14412823",
   "metadata": {},
   "source": [
    "#### Final Enrichment Summary\n",
    "\n",
    "Our multi-source enrichment strategy (BBE → OpenLibrary → Google Books) achieved excellent metadata coverage: **95.1%** for page counts, **100%** for publication dates, **99.4%** for valid language codes, **94.7%** publishers and **85.2%** descriptions. Genre coverage reached **80.8%** for `genres_clean` and **90.7** for `genres_simplified`, a significant improvement from the original Goodbooks dataset which lacked genre information entirely.\n",
    "\n",
    "This enriched dataset now provides a comprehensive foundation for modeling and analysis. The combination of catalog metadata from BBE, behavioral data from Goodbooks ratings, and API-sourced supplemental information creates a unified dataset that supports both predictive modeling and catalog diversity analysis. The next step is filtering to English-language titles and preparing the final model-ready dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
